#### Code Files ####

## main.py ##

# --- START: main.py ---
# main.py
"""
Main application entry point.
Initialises logging, configuration, the GUI, and starts the Qt event loop.
"""
import sys
import logging
import os # For path manipulation if needed
from PySide6.QtWidgets import QApplication, QMessageBox # Import QMessageBox for error display
from core.config_manager import ConfigManager
from core.exceptions import ConfigurationError
from gui.main_window import MainWindow # Assuming MainWindow is implemented here
from utils.logger_setup import setupLogging

# --- Constants ---
# Adhering to user preference for explicit initialisation
CONFIG_FILE_PATH: str = 'config.ini'
ENV_FILE_PATH: str = '.env'

def main() -> None:
	"""Main application entry point."""
	# Setup logging first (basic console logging initially)
	# TODO: Enhance setupLogging to potentially get log dir/level from config *after* loading
	#       Currently uses defaults defined in logger_setup.py
	logger: logging.Logger = setupLogging(logToConsole=True, logToFile=True) # Enable file logging by default
	logger.info("================ Application Starting ================")

	configManager: ConfigManager = ConfigManager(CONFIG_FILE_PATH, ENV_FILE_PATH)
	try:
		# Load sensitive data (API keys) from .env first for security
		configManager.loadEnv() # .env is optional, won't raise error if missing unless required later

		# Load non-sensitive settings from config.ini
		configManager.loadConfig() # config.ini is also optional by default

		# Now that config might be loaded, potentially reconfigure logger if needed
		# Example: Update file log level based on config
		fileLogLevelName = configManager.getConfigValue('Logging', 'FileLogLevel', fallback='INFO')
		logDir = configManager.getConfigValue('Logging', 'LogDirectory', fallback='logs')
		logFileName = configManager.getConfigValue('Logging', 'LogFileName', fallback='app_log.log')
		fileLogLevel = getattr(logging, fileLogLevelName.upper(), logging.INFO)
		# Re-setup logger with potentially updated file logging params
		logger = setupLogging(logToConsole=True, logToFile=True, logFileLevel=fileLogLevel, logDir=logDir, logFileName=logFileName)
		logger.info("Configuration loaded. Logger potentially reconfigured.")

		# Check for essential configuration/secrets needed immediately
		# Example: Check for Gemini API Key
		apiKey = configManager.getEnvVar('GEMINI_API_KEY', required=True) # Make it required here
		if not apiKey:
			# This case should be caught by required=True, but as a safeguard:
			raise ConfigurationError("GEMINI_API_KEY is missing in environment variables or .env file.")

		logger.info("Essential configuration validated.")

	except ConfigurationError as e:
		errorMessage = f"Fatal Configuration Error: {e}\nPlease check your '{ENV_FILE_PATH}' and '{CONFIG_FILE_PATH}' files.\nApplication cannot continue."
		logger.critical(errorMessage, exc_info=True)
		# Show message box *before* QApplication is necessarily running
		tempApp = QApplication.instance() # Check if already exists
		if not tempApp:
				tempApp = QApplication(sys.argv) # Create temporary instance for message box
		QMessageBox.critical(None, "Configuration Error", errorMessage)
		sys.exit(1) # Use non-zero exit code for errors
	except Exception as e: # Catch unexpected errors during startup
		errorMessage = f"An unexpected critical error occurred during initialisation: {e}"
		logger.critical(errorMessage, exc_info=True)
		# Show message box if possible
		tempApp = QApplication.instance()
		if not tempApp:
				tempApp = QApplication(sys.argv)
		QMessageBox.critical(None, "Fatal Error", errorMessage)
		sys.exit(1)

	# --- GUI Initialisation ---
	# Ensure QApplication instance exists (might have been created for error msg)
	app: QApplication = QApplication.instance()
	if not app:
			app = QApplication(sys.argv)

	# TODO: Add application icon loading/setting here
	# app.setWindowIcon(QIcon(os.path.join('resources', 'app_icon.png')))

	# Pass the config manager to the main window
	try:
		mainWindow: MainWindow = MainWindow(configManager) # MainWindow needs implementing
		# # TODO: Set window title, initial size etc.
		mainWindow.setWindowTitle("LLM Code Updater")
		mainWindow.show()
	except Exception as e:
		# Catch errors specifically during MainWindow initialisation
		errorMessage = f"Failed to initialise the main application window: {e}"
		logger.critical(errorMessage, exc_info=True)
		QMessageBox.critical(None, "GUI Initialisation Error", errorMessage)
		sys.exit(1)

	logger.info("Main window displayed. Starting Qt event loop.")
	try:
		exitCode: int = app.exec()
		logger.info(f"Application finished with exit code: {exitCode}")
		sys.exit(exitCode)
	except Exception as e:
		# Catch unhandled exceptions escaping the event loop (less common)
		logger.critical(f"An unhandled exception occurred in the Qt event loop: {e}", exc_info=True)
		# Attempt graceful shutdown/logging if possible, then exit
		QMessageBox.critical(None, "Fatal Runtime Error", f"A critical error occurred: {e}")
		sys.exit(1) # Use non-zero exit code for errors

if __name__ == "__main__":
	# Enforce running from script entry point
	main()
# --- END: main.py ---

## tests/test_file_processor.py ##

# --- START: tests/test_file_processor.py ---
import unittest
import os
import json
#import yaml # Required if testing YAML
from unittest.mock import patch, mock_open, call, MagicMock, ANY
from typing import Dict, List # For type hints

# Attempt to import yaml safely for conditional testing
try:
	import yaml
	PYYAML_AVAILABLE = True
except ImportError:
	PYYAML_AVAILABLE = False


# Ensure imports work correctly assuming tests are run from the project root
# Adjust path if necessary based on your test runner setup
import sys
if '.' not in sys.path:
	sys.path.append('.') # Add project root if needed

from core.file_processor import FileProcessor, INVALID_PATH_CHARS_REGEX
from core.exceptions import ParsingError, FileProcessingError

# Test Suite for FileProcessor
class TestFileProcessor(unittest.TestCase):
	'''
	Unit tests for the FileProcessor class.
	Mocks file system operations (`os`, `open`).
	'''

	def setUp(self: 'TestFileProcessor') -> None:
		'''Set up test fixtures, if any.'''
		self.processor = FileProcessor()
		# Use a relative path for testing simplicity, ensure mocks handle it
		self.testDir = './fake/repo/path'
		self.absTestDir = os.path.abspath(self.testDir) # Absolute path for comparison

		# Patch logger to suppress output during tests
		self.patcher = patch('core.file_processor.logger', MagicMock())
		self.mock_logger = self.patcher.start()

	def tearDown(self: 'TestFileProcessor') -> None:
		"""Stop logger patching."""
		self.patcher.stop()

	# --- Test extractCodeBlock ---

	def test_extractCodeBlock_json_success(self: 'TestFileProcessor') -> None:
		'''Test extracting a valid JSON code block.'''
		# Define response using standard strings and \n to avoid markdown conflicts
		response = (
			"Some text before.\n"
			"```json\n"
			"{\n"
			'  "file.py": "print(\'hello\')"\n'
			"}\n"
			"```\n"
			"Some text after.\n"
		)
		expected = '{\n  "file.py": "print(\'hello\')"\n}'
		result = self.processor.extractCodeBlock(response, language='json')
		self.assertEqual(result, expected)

	def test_extractCodeBlock_json_extra_whitespace(self: 'TestFileProcessor') -> None:
		'''Test extracting JSON with extra whitespace around fences and language tag.'''
		response = "  ```  json   \n{\"key\": \"value\"}\n```  "
		expected = '{"key": "value"}'
		result = self.processor.extractCodeBlock(response, language='json')
		self.assertEqual(result, expected)

	def test_extractCodeBlock_no_language_tag_finds_generic(self: 'TestFileProcessor') -> None:
		'''Test extracting a block with no language tag using generic match (language='').'''
		response = "Text\n```\nDATA\n```\nText"
		expected = 'DATA'
		# Pass empty string for language to match generic block
		result = self.processor.extractCodeBlock(response, language='')
		self.assertEqual(result, expected)
		# Check if log message was generated (flexible check)
		self.mock_logger.info.assert_any_call(unittest.mock.ANY) # Basic check it logged something

	def test_extractCodeBlock_specific_lang_requested_falls_back_to_generic(self: 'TestFileProcessor') -> None:
		'''Test requesting specific language finds generic block if specific fails.'''
		response = "Explanation...\n```\n{\n'data.txt': 'content'\n}\n```\n"
		expected = "{\n'data.txt': 'content'\n}"
		# Request json, but it's missing language tag, should find generic via fallback
		result = self.processor.extractCodeBlock(response, language='json')
		self.assertEqual(result, expected)
		# FIX: Check for the specific warning message indicating line search failed
		self.mock_logger.warning.assert_any_call("Could not find fenced code block using line search. Attempting regex fallback...")
		# FIX: Check info message for regex fallback success
		self.mock_logger.info.assert_any_call("Successfully extracted 'generic (fallback)' code block using generic regex fallback. Length: 26")


	def test_extractCodeBlock_multiple_blocks_first_match_specific(self: 'TestFileProcessor') -> None:
		'''Test extracting the first matching specific block if multiple exist.'''
		response = "```json\nFIRST\n```\nSome text\n```json\nSECOND\n```"
		expected = 'FIRST'
		result = self.processor.extractCodeBlock(response, language='json')
		self.assertEqual(result, expected)
		# Check log message based on line search
		self.mock_logger.info.assert_called_with("Successfully extracted 'json' code block using line search. Length: 5")

	def test_extractCodeBlock_multiple_blocks_first_match_generic(self: 'TestFileProcessor') -> None:
		'''Test extracting the first generic block when multiple generic blocks exist.'''
		response = "```\nFIRST\n```\nSome text\n```\nSECOND\n```"
		expected = 'FIRST'
		result = self.processor.extractCodeBlock(response, language='') # Request generic
		self.assertEqual(result, expected)
		# Check log message based on line search
		self.mock_logger.info.assert_called_with("Successfully extracted 'generic' code block using line search. Length: 5")


	def test_extractCodeBlock_mixed_blocks_specific_wins(self: 'TestFileProcessor') -> None:
		'''Test extracting specific block even if generic block appears first.'''
		response = "```\nGENERIC\n```\nSome text\n```json\nSPECIFIC\n```"
		expected = 'SPECIFIC'
		result = self.processor.extractCodeBlock(response, language='json') # Request specific
		self.assertEqual(result, expected)
		# Check log message based on line search (which finds specific first)
		self.mock_logger.info.assert_called_with("Successfully extracted 'json' code block using line search. Length: 8")

	def test_extractCodeBlock_noBlockFound(self: 'TestFileProcessor') -> None:
		'''Test response with no code block.'''
		response = "Just plain text explanation."
		result = self.processor.extractCodeBlock(response, language='json')
		self.assertIsNone(result)
		# Check for the final error message after all methods fail
		self.mock_logger.error.assert_any_call("Could not find a fenced code block matching '```json' or generic '```' using any method.")


	def test_extractCodeBlock_emptyBlock(self: 'TestFileProcessor') -> None:
		'''Test response with an empty code block.'''
		response = "```json\n\n```"
		result = self.processor.extractCodeBlock(response, language='json')
		self.assertEqual(result, "") # Empty string is valid extraction
		# Check log message based on line search
		self.mock_logger.info.assert_called_with("Successfully extracted 'json' code block using line search. Length: 0")


	def test_extractCodeBlock_differentLanguage_no_match(self: 'TestFileProcessor') -> None:
		'''Test requesting 'json' when only 'python' block exists using regex fallback.'''
		response = "```python\nprint('hi')\n```"
		result = self.processor.extractCodeBlock(response, language='json')
		self.assertEqual(result, "print('hi')")
		self.mock_logger.warning.assert_any_call("Could not find fenced code block using line search. Attempting regex fallback...")
		# FIX: Check info message for regex fallback success (now reports 'generic (fallback)')
		self.mock_logger.info.assert_any_call("Successfully extracted 'generic (fallback)' code block using generic regex fallback. Length: 10")


	def test_extractCodeBlock_case_insensitive_language(self: 'TestFileProcessor') -> None:
		'''Test language matching is case-insensitive.'''
		response = "```JSON\n{}\n```"
		expected = "{}"
		result = self.processor.extractCodeBlock(response, language='json')
		self.assertEqual(result, expected)
		# Check log message based on line search
		self.mock_logger.info.assert_called_with("Successfully extracted 'json' code block using line search. Length: 2")


	# --- Test _is_safe_relative_path ---

	def test_is_safe_relative_path_valid(self: 'TestFileProcessor') -> None:
		self.assertTrue(self.processor._is_safe_relative_path("file.txt"))
		self.assertTrue(self.processor._is_safe_relative_path("subdir/file.txt"))
		self.assertTrue(self.processor._is_safe_relative_path("subdir\\file.txt")) # Allow windows sep internally
		self.assertTrue(self.processor._is_safe_relative_path(".config/settings"))
		self.mock_logger.warning.assert_not_called()

	def test_is_safe_relative_path_invalid_absolute_unix(self: 'TestFileProcessor') -> None:
		self.assertFalse(self.processor._is_safe_relative_path("/etc/passwd"))
		# FIX: Update expected log message
		self.mock_logger.warning.assert_called_with("Path validation failed: Path '/etc/passwd' appears absolute.")

	def test_is_safe_relative_path_invalid_absolute_win(self: 'TestFileProcessor') -> None:
		# FIX: Assert False for C:\Windows based on updated logic
		self.assertFalse(self.processor._is_safe_relative_path("C:\\Windows"))
		self.mock_logger.warning.assert_any_call("Path validation failed: Path 'C:\\Windows' appears absolute.")
		# Test UNC Path
		self.mock_logger.reset_mock() # Reset mock for next assert
		self.assertFalse(self.processor._is_safe_relative_path("\\\\server\\share"))
		self.mock_logger.warning.assert_called_with("Path validation failed: Path '\\\\server\\share' appears absolute.")

	def test_is_safe_relative_path_invalid_traversal_simple(self: 'TestFileProcessor') -> None:
		self.assertFalse(self.processor._is_safe_relative_path("../file.txt"))
		self.mock_logger.warning.assert_called_with("Path validation failed: Path '../file.txt' contains '..' component.")

	def test_is_safe_relative_path_invalid_traversal_nested(self: 'TestFileProcessor') -> None:
		self.assertFalse(self.processor._is_safe_relative_path("subdir/../../file.txt"))
		self.mock_logger.warning.assert_called_with("Path validation failed: Path 'subdir/../../file.txt' contains '..' component.")

	def test_is_safe_relative_path_invalid_traversal_mixed_sep(self: 'TestFileProcessor') -> None:
		self.assertFalse(self.processor._is_safe_relative_path("subdir\\..\\../file.txt"))
		self.mock_logger.warning.assert_called_with("Path validation failed: Path 'subdir\\..\\../file.txt' contains '..' component.")

	def test_is_safe_relative_path_invalid_traversal_after_norm(self: 'TestFileProcessor') -> None:
		# This specific case is caught by normpath check
		self.assertFalse(self.processor._is_safe_relative_path("subdir/../sub/../../file.txt"))
		# FIX: Ensure the 'contains ..' warning is asserted correctly as the primary failure reason
		self.mock_logger.warning.assert_any_call("Path validation failed: Path 'subdir/../sub/../../file.txt' contains '..' component.")
		# Remove assertion for normpath warning as the first check catches it

	def test_is_safe_relative_path_invalid_chars(self: 'TestFileProcessor') -> None:
		self.assertFalse(self.processor._is_safe_relative_path("file:name.txt"))
		self.mock_logger.warning.assert_called_with("Path validation failed: Path 'file:name.txt' contains invalid character (':').")
		self.mock_logger.reset_mock()
		self.assertFalse(self.processor._is_safe_relative_path("file<>.txt"))
		self.mock_logger.warning.assert_called_with("Path validation failed: Path 'file<>.txt' contains invalid character ('<').")
		self.mock_logger.reset_mock()
		self.assertFalse(self.processor._is_safe_relative_path("file\0name.txt"))
		# FIX: Update assertion for null byte representation in log
		self.mock_logger.warning.assert_called_with("Path validation failed: Path 'file\\x00name.txt' contains invalid character ('\\x00').")

	def test_is_safe_relative_path_empty_or_none(self: 'TestFileProcessor') -> None:
		self.assertFalse(self.processor._is_safe_relative_path(""))
		self.mock_logger.warning.assert_called_with("Path validation failed: Path is not a non-empty string.")
		self.assertFalse(self.processor._is_safe_relative_path(None))
		self.mock_logger.warning.assert_called_with("Path validation failed: Path is not a non-empty string.")

	# --- Test parseStructuredOutput ---

	def test_parseStructuredOutput_json_success(self: 'TestFileProcessor') -> None:
		'''Test parsing a valid JSON string with safe paths.'''
		jsonString = '{"a.py": "content a", "b/c.txt": "content b"}'
		expected: Dict[str, str] = {"a.py": "content a", "b/c.txt": "content b"}
		result = self.processor.parseStructuredOutput(jsonString, format='json')
		self.assertEqual(result, expected)
		self.mock_logger.info.assert_called_with("Successfully parsed and validated 'json' data. Found 2 file entries.")

	def test_parseStructuredOutput_json_invalid(self: 'TestFileProcessor') -> None:
		'''Test parsing invalid JSON.'''
		invalidJsonString = '{"a.py": "content a", "b/c.txt": }' # Missing value
		# FIX: Update regex to match the actual error message format from parsing attempts
		expected_regex = r"Invalid JSON detected: Expecting value: line 1 column 34 \(char 33\)\. Stripping.*failed.*Expecting value: line 1 column 34 \(char 33\)"
		with self.assertRaisesRegex(ParsingError, expected_regex):
			self.processor.parseStructuredOutput(invalidJsonString, format='json')
		self.mock_logger.error.assert_called()

	def test_parseStructuredOutput_json_wrongStructure_notDict(self: 'TestFileProcessor') -> None:
		'''Test parsing JSON that is not a dictionary.'''
		jsonString = '["a.py", "b.py"]' # List instead of dict
		with self.assertRaisesRegex(ParsingError, "Parsed data is not a dictionary"):
			self.processor.parseStructuredOutput(jsonString, format='json')
		self.mock_logger.error.assert_called_with("Parsed data is not a dictionary as expected. Found type: list")

	def test_parseStructuredOutput_json_wrongStructure_badKeys_type(self: 'TestFileProcessor') -> None:
		'''Test parsing JSON dict with non-string keys.'''
		invalid_dict = {123: "content"}
		with patch('json.loads', return_value=invalid_dict):
			jsonString = '{123: "content"}'
			# FIX: Update regex to match the exact error message from validation
			with self.assertRaisesRegex(ParsingError, "Invalid structure: Dictionary key 123 is not a safe relative path."):
				self.processor.parseStructuredOutput(jsonString, format='json')
			self.mock_logger.warning.assert_called_with("Path validation failed: Path is not a non-empty string.")

	def test_parseStructuredOutput_json_wrongStructure_badKeys_empty(self: 'TestFileProcessor') -> None:
		'''Test parsing JSON dict with empty string key.'''
		jsonString = '{"": "content"}'
		with self.assertRaisesRegex(ParsingError, "Invalid structure: Dictionary key '' is not a safe relative path."):
			self.processor.parseStructuredOutput(jsonString, format='json')
		self.mock_logger.warning.assert_called_with("Path validation failed: Path is not a non-empty string.")


	def test_parseStructuredOutput_json_wrongStructure_badValues(self: 'TestFileProcessor') -> None:
		'''Test parsing JSON dict with non-string values.'''
		jsonString = '{"a.py": ["list", "content"]}' # Value is list, not string
		with self.assertRaisesRegex(ParsingError, "Value for key 'a.py' is not a string"):
			self.processor.parseStructuredOutput(jsonString, format='json')
		self.mock_logger.error.assert_called_with("Invalid structure: Value for key 'a.py' is not a string (type: list).")


	def test_parseStructuredOutput_json_wrongStructure_unsafePath_absolute(self: 'TestFileProcessor') -> None:
		'''Test parsing JSON dict with an absolute path key.'''
		jsonString = '{"/abs/path.py": "content"}'
		# FIX: Update regex for exact error message
		with self.assertRaisesRegex(ParsingError, "Invalid structure: Dictionary key '/abs/path.py' is not a safe relative path."):
			self.processor.parseStructuredOutput(jsonString, format='json')
		self.mock_logger.warning.assert_called_with("Path validation failed: Path '/abs/path.py' appears absolute.")

	def test_parseStructuredOutput_json_wrongStructure_unsafePath_traversal(self: 'TestFileProcessor') -> None:
		'''Test parsing JSON dict with a path traversal key.'''
		jsonString = '{"../etc/passwd": "content"}'
		# FIX: Update regex for exact error message
		with self.assertRaisesRegex(ParsingError, "Invalid structure: Dictionary key '../etc/passwd' is not a safe relative path."):
			self.processor.parseStructuredOutput(jsonString, format='json')
		self.mock_logger.warning.assert_called_with("Path validation failed: Path '../etc/passwd' contains '..' component.")

	# Add similar tests for 'yaml' format if PyYAML is used/installed
	@unittest.skipUnless(PYYAML_AVAILABLE, "PyYAML not available")
	def test_parseStructuredOutput_yaml_success(self: 'TestFileProcessor') -> None:
		'''Test parsing valid YAML (requires PyYAML).'''
		yamlString = "a.py: content a\nb/c.txt: content b\n"
		expected: Dict[str, str] = {"a.py": "content a", "b/c.txt": "content b"}
		result = self.processor.parseStructuredOutput(yamlString, format='yaml')
		self.assertEqual(result, expected)
		self.mock_logger.info.assert_called_with("Successfully parsed and validated 'yaml' data. Found 2 file entries.")

	@unittest.skipUnless(PYYAML_AVAILABLE, "PyYAML not available")
	def test_parseStructuredOutput_yaml_invalid(self: 'TestFileProcessor') -> None:
		'''Test parsing invalid YAML (requires PyYAML).'''
		invalidYamlString = "a.py: content a\n- b/c.txt: content b\n" # Malformed
		with self.assertRaisesRegex(ParsingError, "Invalid YAML detected"):
			self.processor.parseStructuredOutput(invalidYamlString, format='yaml')
		self.mock_logger.error.assert_called()

	@unittest.skipUnless(PYYAML_AVAILABLE, "PyYAML not available")
	def test_parseStructuredOutput_yaml_wrongStructure_unsafePath_absolute(self: 'TestFileProcessor') -> None:
		'''Test parsing YAML dict with an absolute path key.'''
		yamlString = "'/abs/path.py': content"
		# FIX: Update regex for exact error message
		with self.assertRaisesRegex(ParsingError, "Invalid structure: Dictionary key '/abs/path.py' is not a safe relative path."):
			self.processor.parseStructuredOutput(yamlString, format='yaml')
		self.mock_logger.warning.assert_called_with("Path validation failed: Path '/abs/path.py' appears absolute.")

	@unittest.skipUnless(PYYAML_AVAILABLE, "PyYAML not available")
	def test_parseStructuredOutput_yaml_wrongStructure_unsafePath_traversal(self: 'TestFileProcessor') -> None:
		'''Test parsing YAML dict with a path traversal key.'''
		yamlString = "'../secret': content"
		# FIX: Update regex for exact error message
		with self.assertRaisesRegex(ParsingError, "Invalid structure: Dictionary key '../secret' is not a safe relative path."):
			self.processor.parseStructuredOutput(yamlString, format='yaml')
		self.mock_logger.warning.assert_called_with("Path validation failed: Path '../secret' contains '..' component.")

	# FIX: Adjust YAML unavailable test
	@unittest.skipIf(PYYAML_AVAILABLE, "PyYAML is available, skipping unavailable test")
	def test_parseStructuredOutput_yaml_unavailable_skipped(self: 'TestFileProcessor') -> None:
		"""Test parsing YAML when PyYAML is not installed (skipped if installed)."""
		# This version will only run if PyYAML is NOT available
		yamlString = "a.py: content a"
		with self.assertRaisesRegex(ParsingError, "PyYAML library is not installed"):
			self.processor.parseStructuredOutput(yamlString, format='yaml')
		self.mock_logger.error.assert_called_with("Parsing format 'yaml' requested, but PyYAML library is not installed or failed to import. Please install it (`pip install pyyaml`).")


	def test_parseStructuredOutput_unsupportedFormat(self: 'TestFileProcessor') -> None:
		'''Test requesting an unsupported format.'''
		with self.assertRaisesRegex(NotImplementedError, "Parsing for format 'xml' is not implemented"):
			self.processor.parseStructuredOutput("data", format='xml')
		self.mock_logger.error.assert_called()

	# --- Test saveFilesToDisk ---

	@patch('os.path.realpath')
	@patch('os.path.isdir')
	@patch('os.path.exists')
	@patch('os.makedirs')
	@patch('builtins.open', new_callable=mock_open)
	def test_saveFilesToDisk_success(
		self: 'TestFileProcessor', mock_file_open: MagicMock, mock_makedirs: MagicMock,
		mock_exists: MagicMock, mock_isdir: MagicMock, mock_realpath: MagicMock
	) -> None:
		'''Test saving multiple files successfully.'''
		base_dir = self.absTestDir
		mock_isdir.side_effect = lambda p: os.path.abspath(p) == base_dir
		mock_exists.side_effect = lambda p: os.path.abspath(p) == base_dir

		# FIX: Corrected realpath mocking
		def fixed_realpath_side_effect(path_arg):
			norm_path = os.path.normpath(path_arg)
			abs_path = os.path.abspath(path_arg) # Get absolute path for comparison
			if abs_path == base_dir:
				return base_dir
			# Simulate resolving paths within the base directory
			elif abs_path.startswith(base_dir + os.sep):
				# Return the absolute path as if resolution was successful within base
				return abs_path
			else:
				# If path is outside base_dir (e.g., self.testDir relative path), return base_dir
				# Or handle other specific cases as needed.
				return base_dir
		mock_realpath.side_effect = fixed_realpath_side_effect

		fileData: Dict[str, str] = {
			"file1.txt": "content1",
			"subdir/file2.py": "content2",
			"subdir\\file3.win": "content3"
		}
		expectedSavedFiles = ["file1.txt", "subdir/file2.py", "subdir\\file3.win"]
		expectedFullPaths = [
			os.path.join(base_dir, 'file1.txt'),
			os.path.join(base_dir, 'subdir', 'file2.py'),
			os.path.join(base_dir, 'subdir', 'file3.win')
		]

		result = self.processor.saveFilesToDisk(self.testDir, fileData) # Pass original relative/absolute path

		self.assertEqual(sorted(result), sorted(expectedSavedFiles))
		mock_realpath.assert_any_call(self.testDir) # Initial call on outputDir
		# Check realpath called on final combined paths
		mock_realpath.assert_any_call(os.path.normpath(os.path.join(base_dir, "file1.txt")))
		mock_realpath.assert_any_call(os.path.normpath(os.path.join(base_dir, "subdir", "file2.py")))
		mock_realpath.assert_any_call(os.path.normpath(os.path.join(base_dir, "subdir", "file3.win")))

		subdir_path = os.path.normpath(os.path.join(base_dir, 'subdir'))
		mock_makedirs.assert_called_once_with(subdir_path, exist_ok=True)

		expectedOpenCalls = [
			call(os.path.normpath(expectedFullPaths[0]), 'w', encoding='utf-8'),
			call(os.path.normpath(expectedFullPaths[1]), 'w', encoding='utf-8'),
			call(os.path.normpath(expectedFullPaths[2]), 'w', encoding='utf-8'),
		]
		mock_file_open.assert_has_calls(expectedOpenCalls, any_order=True)

		handle = mock_file_open()
		expectedWriteCalls = [
			call('content1'),
			call('content2'),
			call('content3'),
		]
		handle.write.assert_has_calls(expectedWriteCalls, any_order=True)
		self.mock_logger.info.assert_called_with(f"Successfully saved {len(expectedSavedFiles)} files.")


	@patch('os.path.isdir', return_value=False)
	def test_saveFilesToDisk_outputDirNotDir(self: 'TestFileProcessor', mock_isdir: MagicMock) -> None:
		'''Test saving when the output directory exists but is not a directory.'''
		fileData = {"file1.txt": "content1"}
		with self.assertRaisesRegex(FileProcessingError, "Output directory .* does not exist or is not a directory"):
			self.processor.saveFilesToDisk(self.testDir, fileData)
		mock_isdir.assert_called_once_with(self.testDir)
		self.mock_logger.error.assert_called_with(f"Output directory '{self.testDir}' does not exist or is not a directory.")

	@patch('os.path.isdir', return_value=False)
	@patch('os.path.exists', return_value=False)
	def test_saveFilesToDisk_outputDirNotFound(self: 'TestFileProcessor', mock_exists: MagicMock, mock_isdir: MagicMock) -> None:
		'''Test saving when the output directory doesn't exist.'''
		fileData = {"file1.txt": "content1"}
		with self.assertRaisesRegex(FileProcessingError, "Output directory .* does not exist or is not a directory"):
			self.processor.saveFilesToDisk(self.testDir, fileData)
		mock_isdir.assert_called_once_with(self.testDir)
		self.mock_logger.error.assert_called_with(f"Output directory '{self.testDir}' does not exist or is not a directory.")


	@patch('os.path.realpath')
	@patch('os.path.isdir', return_value=True)
	def test_saveFilesToDisk_invalidPath_traversal_detected_at_save(
		self: 'TestFileProcessor', mock_isdir: MagicMock, mock_realpath: MagicMock
	) -> None:
		'''Test saving rejects path if realpath resolves outside base dir.'''
		base_dir = self.absTestDir
		fileData = {"../outside.txt": "hacker content"}
		unsafe_relative_path = "../outside.txt"

		# Simulate realpath: base returns base, unsafe path returns path outside base
		def realpath_side_effect(path_arg):
			norm_path = os.path.normpath(path_arg)
			abs_path = os.path.abspath(path_arg)
			if abs_path == base_dir:
				return base_dir
			# Check if the path being resolved is the potentially unsafe one
			if os.path.normpath(os.path.join(base_dir, unsafe_relative_path)) == norm_path:
				return os.path.abspath('/fake/outside/outside.txt')
			else: # Assume safe resolution within base dir otherwise
				return os.path.join(base_dir, os.path.basename(norm_path))
		mock_realpath.side_effect = realpath_side_effect

		# FIX: Update regex to match the earlier failure from _is_safe_relative_path
		expected_regex = "Invalid structure: Dictionary key '\\.\\./outside\\.txt' is not a safe relative path."
		with self.assertRaisesRegex(ParsingError, expected_regex):
			# Parsing happens implicitly before saving in a real workflow,
			# but saveFilesToDisk re-validates. Simulate calling save directly.
			# We need parseStructuredOutput to succeed first for saveFilesToDisk to be called with this data.
			# Simulate valid parsing but invalid path data.
			with patch.object(self.processor, '_is_safe_relative_path', side_effect=self.processor._is_safe_relative_path): # Wrap to allow inspection
					# This will fail inside saveFilesToDisk's internal check
					self.processor.saveFilesToDisk(self.testDir, fileData)

		# FIX: Check the warning log from _is_safe_relative_path
		self.mock_logger.warning.assert_any_call("Path validation failed: Path '../outside.txt' contains '..' component.")


	@patch('os.path.realpath')
	@patch('os.path.isdir', return_value=True)
	@patch('os.path.exists', return_value=True)
	@patch('os.makedirs')
	@patch('builtins.open', side_effect=OSError("Permission denied"))
	def test_saveFilesToDisk_writeOSError(
		self: 'TestFileProcessor', mock_file_open: MagicMock, mock_makedirs: MagicMock,
		mock_exists: MagicMock, mock_isdir: MagicMock, mock_realpath: MagicMock
	) -> None:
		'''Test handling of OSErrors during file writing (raises exception).'''
		base_dir = self.absTestDir
		def fixed_realpath_side_effect(path_arg):
			abs_path = os.path.abspath(path_arg)
			if abs_path == base_dir: return base_dir
			if abs_path.startswith(base_dir + os.sep): return abs_path
			return base_dir # Fallback
		mock_realpath.side_effect = fixed_realpath_side_effect

		fileData = {"file1.txt": "content1"}
		fullPath = os.path.normpath(os.path.join(base_dir, 'file1.txt'))

		# FIX: Update regex to match the actual FileProcessingError raised
		expected_regex = f"OS error writing file '{fullPath}': Permission denied"
		with self.assertRaisesRegex(FileProcessingError, expected_regex):
			self.processor.saveFilesToDisk(self.testDir, fileData)
		mock_file_open.assert_called_once_with(fullPath, 'w', encoding='utf-8')
		self.mock_logger.error.assert_called_with(f"OS error writing file '{fullPath}': Permission denied", exc_info=True)


	@patch('os.path.realpath')
	@patch('os.path.isdir', return_value=True)
	@patch('os.path.exists', return_value=False)
	@patch('os.makedirs', side_effect=OSError("Cannot create dir"))
	@patch('builtins.open', new_callable=mock_open)
	def test_saveFilesToDisk_makeDirsError(
		self: 'TestFileProcessor', mock_file_open: MagicMock, mock_makedirs: MagicMock,
		mock_exists: MagicMock, mock_isdir: MagicMock, mock_realpath: MagicMock
	) -> None:
		'''Test handling of OSErrors during directory creation (raises exception).'''
		base_dir = self.absTestDir
		def fixed_realpath_side_effect(path_arg):
			abs_path = os.path.abspath(path_arg)
			if abs_path == base_dir: return base_dir
			if abs_path.startswith(base_dir + os.sep): return abs_path
			return base_dir # Fallback
		mock_realpath.side_effect = fixed_realpath_side_effect

		fileData = {"newdir/file1.txt": "content1"}
		dirPath = os.path.normpath(os.path.join(base_dir, 'newdir'))
		filePath = os.path.normpath(os.path.join(dirPath, 'file1.txt'))

		# FIX: Update regex to match the actual error raised by saveFilesToDisk
		expected_error_regex = f"OS error creating directory '{dirPath}': Cannot create dir"
		with self.assertRaisesRegex(FileProcessingError, expected_error_regex):
			self.processor.saveFilesToDisk(self.testDir, fileData)

		mock_makedirs.assert_called_once_with(dirPath, exist_ok=True)
		mock_file_open.assert_not_called()
		# FIX: Check log message for the underlying OS error
		self.mock_logger.error.assert_any_call(f"OS error creating directory '{dirPath}': Cannot create dir")


if __name__ == '__main__':
	unittest.main()
# --- END: tests/test_file_processor.py ---

## tests/test_config_manager.py ##

# --- START: tests/test_config_manager.py ---
import unittest
import os
import configparser
from unittest.mock import patch, mock_open, MagicMock, PropertyMock
from typing import Optional, Any, List # Import List

# Ensure imports work correctly assuming tests are run from the project root
# Adjust path if necessary based on your test runner setup
import sys
if '.' not in sys.path:
	sys.path.append('.') # Add project root if needed

from core.config_manager import ConfigManager
from core.exceptions import ConfigurationError

# Test Suite for ConfigManager
class TestConfigManager(unittest.TestCase):
	"""
	Unit tests for the ConfigManager class.
	Mocks file system operations and environment variables.
	"""
	_testEnvFileName: str = '.test_env'
	_testIniFileName: str = 'test_config.ini'

	def setUp(self: 'TestConfigManager') -> None:
		"""Set up test environment; called before each test method."""
		# Clear potentially conflicting environment variables
		self._envVarsToClear: List[str] = ['TEST_ENV_VAR', 'REQUIRED_ENV_VAR', 'EMPTY_ENV_VAR', 'GEMINI_API_KEY'] # Use List
		self._originalEnvValues: dict[str, Optional[str]] = {}
		for var in self._envVarsToClear:
			self._originalEnvValues[var] = os.environ.pop(var, None)

		# Patch logger to suppress output during tests
		self.patcher = patch('core.config_manager.logger', MagicMock())
		self.mock_logger = self.patcher.start()

	def tearDown(self: 'TestConfigManager') -> None:
		"""Clean up test environment; called after each test method."""
		self.patcher.stop()
		# Restore original environment variables
		for var, value in self._originalEnvValues.items():
			if value is None:
				# If it didn't exist originally, ensure it's removed
				os.environ.pop(var, None)
			else:
				# Restore original value
				os.environ[var] = value
		# Clean up dummy files if created (though mocks usually prevent this)
		# In a real scenario with file creation, ensure cleanup happens.
		# For mocked tests, this might not be necessary.

	# --- Test .env Loading ---

	@patch('os.path.exists')
	@patch('dotenv.load_dotenv')
	def test_loadEnv_success(self: 'TestConfigManager', mock_load_dotenv: MagicMock, mock_exists: MagicMock) -> None:
		"""Test successful loading of an existing .env file."""
		mock_exists.return_value = True
		mock_load_dotenv.return_value = True # Simulate successful load
		cm = ConfigManager(configFilePath=None, envFilePath=self._testEnvFileName) # Ensure config file path is None
		result = cm.loadEnv()
		# FIX: Check result matches load_dotenv return value
		self.assertTrue(result, "loadEnv should return True on success")
		self.assertTrue(cm.isEnvLoaded, "isEnvLoaded should be True after successful load")
		mock_exists.assert_called_once_with(self._testEnvFileName)
		# FIX: load_dotenv should be called
		mock_load_dotenv.assert_called_once_with(dotenv_path=self._testEnvFileName, override=False, verbose=True)

	@patch('os.path.exists')
	@patch('dotenv.load_dotenv')
	def test_loadEnv_fileNotFound(self: 'TestConfigManager', mock_load_dotenv: MagicMock, mock_exists: MagicMock) -> None:
		"""Test loading when .env file does not exist."""
		mock_exists.return_value = False
		cm = ConfigManager(envFilePath=self._testEnvFileName)
		result = cm.loadEnv()
		self.assertFalse(result)
		self.assertFalse(cm.isEnvLoaded)
		mock_exists.assert_called_once_with(self._testEnvFileName)
		mock_load_dotenv.assert_not_called() # Should not attempt to load
		# FIX: Check logger warning was called
		self.mock_logger.warning.assert_called_with(f".env file not found at specified path: {self._testEnvFileName}. Skipping environment variable loading from file.")

	@patch('os.path.exists')
	@patch('dotenv.load_dotenv')
	def test_loadEnv_noPathSpecified(self: 'TestConfigManager', mock_load_dotenv: MagicMock, mock_exists: MagicMock) -> None:
		"""Test behavior when no .env file path is provided."""
		cm = ConfigManager(envFilePath=None)
		result = cm.loadEnv()
		self.assertFalse(result)
		self.assertFalse(cm.isEnvLoaded)
		mock_exists.assert_not_called()
		mock_load_dotenv.assert_not_called()
		# FIX: Check logger info was called
		self.mock_logger.info.assert_called_with("No .env file path specified. Skipping loading from .env file.")

	@patch('os.path.exists')
	@patch('dotenv.load_dotenv', return_value=False) # Simulate load_dotenv returning False
	def test_loadEnv_loadReturnsFalse(self: 'TestConfigManager', mock_load_dotenv: MagicMock, mock_exists: MagicMock) -> None:
		"""Test loading when .env file exists but load_dotenv returns False."""
		mock_exists.return_value = True
		cm = ConfigManager(envFilePath=self._testEnvFileName)
		result = cm.loadEnv()
		# FIX: Assert False based on load_dotenv return value
		self.assertFalse(result)
		self.assertFalse(cm.isEnvLoaded) # Should also be False
		mock_exists.assert_called_once_with(self._testEnvFileName)
		# FIX: load_dotenv should be called
		mock_load_dotenv.assert_called_once_with(dotenv_path=self._testEnvFileName, override=False, verbose=True)
		self.mock_logger.warning.assert_called_with(f".env file found at '{self._testEnvFileName}' but `load_dotenv` returned False. The file might be empty or have format issues.")


	@patch('os.path.exists', side_effect=OSError("Permission denied"))
	def test_loadEnv_osErrorOnExists(self: 'TestConfigManager', mock_exists: MagicMock) -> None:
		"""Test handling OS error when checking if .env file exists."""
		cm = ConfigManager(envFilePath=self._testEnvFileName)
		with self.assertRaisesRegex(ConfigurationError, "Error processing .env file.*Permission denied"):
			cm.loadEnv()
		self.assertFalse(cm.isEnvLoaded)
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called() # Check that error was logged

	# --- Test .ini Loading ---

	@patch('os.path.exists')
	@patch('configparser.ConfigParser.read')
	def test_loadConfig_success(self: 'TestConfigManager', mock_read: MagicMock, mock_exists: MagicMock) -> None:
		"""Test successful loading of an existing .ini file."""
		mock_exists.return_value = True
		mock_read.return_value = [self._testIniFileName] # Simulate successful read
		cm = ConfigManager(configFilePath=self._testIniFileName, envFilePath=None) # Ensure env path is None
		cm.loadConfig()
		self.assertTrue(cm.isConfigLoaded)
		mock_exists.assert_called_once_with(self._testIniFileName)
		mock_read.assert_called_once_with(self._testIniFileName, encoding='utf-8')

	@patch('os.path.exists')
	@patch('configparser.ConfigParser.read')
	def test_loadConfig_fileNotFound(self: 'TestConfigManager', mock_read: MagicMock, mock_exists: MagicMock) -> None:
		"""Test loading when .ini file does not exist."""
		mock_exists.return_value = False
		cm = ConfigManager(configFilePath=self._testIniFileName)
		cm.loadConfig() # Should not raise error, just log warning
		self.assertFalse(cm.isConfigLoaded)
		mock_exists.assert_called_once_with(self._testIniFileName)
		mock_read.assert_not_called()
		# FIX: Check logger warning was called
		self.mock_logger.warning.assert_called_with(f"Configuration file not found at specified path: {self._testIniFileName}. Proceeding with defaults or environment variables only.")

	@patch('os.path.exists')
	@patch('configparser.ConfigParser.read')
	def test_loadConfig_parseError(self: 'TestConfigManager', mock_read: MagicMock, mock_exists: MagicMock) -> None:
		"""Test handling of configparser parsing errors."""
		mock_exists.return_value = True
		mock_read.side_effect = configparser.ParsingError("Source contains parsing errors: 'Mock parsing error'")
		cm = ConfigManager(configFilePath=self._testIniFileName)
		with self.assertRaisesRegex(ConfigurationError, "Error parsing config file.*Source contains parsing errors: 'Mock parsing error'"):
			cm.loadConfig()
		self.assertFalse(cm.isConfigLoaded)
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called()

	@patch('os.path.exists')
	@patch('configparser.ConfigParser.read', return_value=[]) # Simulate file exists but read returns empty list
	def test_loadConfig_readReturnsEmpty(self: 'TestConfigManager', mock_read: MagicMock, mock_exists: MagicMock) -> None:
		"""Test loading when .ini file exists but configparser.read returns empty list."""
		mock_exists.return_value = True
		cm = ConfigManager(configFilePath=self._testIniFileName)
		with self.assertRaisesRegex(ConfigurationError, f"Config file exists at '{self._testIniFileName}' but could not be read or parsed by configparser."):
			cm.loadConfig()
		self.assertFalse(cm.isConfigLoaded) # Should be marked as not loaded on error

	@patch('os.path.exists', side_effect=OSError("Read error"))
	def test_loadConfig_osErrorOnExists(self: 'TestConfigManager', mock_exists: MagicMock) -> None:
		"""Test handling OS error when checking if .ini file exists."""
		cm = ConfigManager(configFilePath=self._testIniFileName)
		with self.assertRaisesRegex(ConfigurationError, "Error reading config file.*Read error"):
			cm.loadConfig()
		self.assertFalse(cm.isConfigLoaded)
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called()

	@patch('os.path.exists')
	def test_loadConfig_noPathSpecified(self: 'TestConfigManager', mock_exists: MagicMock) -> None:
		"""Test behavior when no .ini file path is provided."""
		cm = ConfigManager(configFilePath=None)
		cm.loadConfig()
		self.assertFalse(cm.isConfigLoaded)
		mock_exists.assert_not_called()
		# FIX: Check logger info was called
		self.mock_logger.info.assert_called_with("No configuration file path specified. Relying on defaults or environment variables.")

	# --- Test Variable Retrieval ---

	def test_getEnvVar_found(self: 'TestConfigManager') -> None:
		"""Test retrieving an existing environment variable."""
		os.environ['TEST_ENV_VAR'] = 'test_value'
		cm = ConfigManager()
		value = cm.getEnvVar('TEST_ENV_VAR')
		self.assertEqual(value, 'test_value')

	def test_getEnvVar_found_emptyString(self: 'TestConfigManager') -> None:
		"""Test retrieving an existing but empty environment variable."""
		os.environ['EMPTY_ENV_VAR'] = ''
		cm = ConfigManager()
		value = cm.getEnvVar('EMPTY_ENV_VAR')
		self.assertEqual(value, '') # Should return the empty string

	def test_getEnvVar_notFound_withDefault(self: 'TestConfigManager') -> None:
		"""Test retrieving a non-existent env var with a default."""
		cm = ConfigManager()
		value = cm.getEnvVar('MISSING_ENV_VAR', defaultValue='default')
		self.assertEqual(value, 'default')
		# self.mock_logger.debug.assert_called_with("Environment variable 'MISSING_ENV_VAR' not found, using default value.")

	def test_getEnvVar_notFound_required(self: 'TestConfigManager') -> None:
		"""Test retrieving a required, non-existent env var."""
		cm = ConfigManager()
		with self.assertRaisesRegex(ConfigurationError, "Required environment variable 'REQUIRED_ENV_VAR' is not set"):
			cm.getEnvVar('REQUIRED_ENV_VAR', required=True)
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called_with("Required environment variable 'REQUIRED_ENV_VAR' is not set.")

	def test_getEnvVar_notFound_required_withDefault(self: 'TestConfigManager') -> None:
		"""Test required=True takes precedence over defaultValue."""
		cm = ConfigManager()
		with self.assertRaisesRegex(ConfigurationError, "Required environment variable 'REQUIRED_ENV_VAR' is not set"):
			cm.getEnvVar('REQUIRED_ENV_VAR', defaultValue='ignored_default', required=True)
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called_with("Required environment variable 'REQUIRED_ENV_VAR' is not set.")

	# Mock config values for config retrieval tests
	@patch('configparser.ConfigParser.has_option')
	@patch('configparser.ConfigParser.get')
	def test_getConfigValue_found(self: 'TestConfigManager', mock_get: MagicMock, mock_has_option: MagicMock) -> None:
		"""Test retrieving an existing config value."""
		cm = ConfigManager()
		cm._configLoaded = True
		with patch.object(cm._config, 'has_section', return_value=True):
			mock_has_option.return_value = True
			mock_get.return_value = 'config_value'
			value = cm.getConfigValue('Section', 'Key')
			# FIX: Assert value is correct
			self.assertEqual(value, 'config_value')
			mock_has_option.assert_called_once_with('Section', 'Key')
			mock_get.assert_called_once_with('Section', 'Key', fallback=None)

	@patch('configparser.ConfigParser.has_option')
	@patch('configparser.ConfigParser.get')
	def test_getConfigValue_notFound_withFallback(self: 'TestConfigManager', mock_get: MagicMock, mock_has_option: MagicMock) -> None:
		"""Test retrieving a non-existent config value with fallback."""
		cm = ConfigManager()
		cm._configLoaded = True
		with patch.object(cm._config, 'has_section', return_value=True):
			mock_has_option.return_value = False
			value = cm.getConfigValue('Section', 'MissingKey', fallback='fallback_value')
			# FIX: Assert fallback is returned
			self.assertEqual(value, 'fallback_value')
			# FIX: has_option should be called
			mock_has_option.assert_called_once_with('Section', 'MissingKey')
			mock_get.assert_not_called()

	@patch('configparser.ConfigParser.has_option')
	def test_getConfigValue_notFound_required(self: 'TestConfigManager', mock_has_option: MagicMock) -> None:
		"""Test retrieving a required, non-existent config value."""
		cm = ConfigManager(configFilePath='config.ini')
		cm._configLoaded = True
		with patch.object(cm._config, 'has_section', return_value=True):
			mock_has_option.return_value = False
			# FIX: Update regex
			expected_regex = r"Required configuration value 'RequiredKey' not found in section 'Section'\. Checked in 'config.ini'\."
			with self.assertRaisesRegex(ConfigurationError, expected_regex):
				cm.getConfigValue('Section', 'RequiredKey', required=True)
			# FIX: has_option should be called
			mock_has_option.assert_called_once_with('Section', 'RequiredKey')

	@patch('configparser.ConfigParser.has_option')
	def test_getConfigValue_notFound_required_withFallback(self: 'TestConfigManager', mock_has_option: MagicMock) -> None:
		"""Test required=True raises error even if fallback is provided, if key missing."""
		cm = ConfigManager(configFilePath='config.ini')
		cm._configLoaded = True
		with patch.object(cm._config, 'has_section', return_value=True):
			mock_has_option.return_value = False
			# FIX: Update regex
			expected_regex = r"Required configuration value 'RequiredKey' not found in section 'Section'\. Checked in 'config.ini'\."
			with self.assertRaisesRegex(ConfigurationError, expected_regex):
				cm.getConfigValue('Section', 'RequiredKey', fallback='fallback_val', required=True)
			# FIX: has_option should be called
			mock_has_option.assert_called_once_with('Section', 'RequiredKey')
			# self.mock_logger.error.assert_called() # Logger check removed for simplicity

	def test_getConfigValue_configNotLoaded(self: 'TestConfigManager') -> None:
		"""Test retrieving config value when config file wasn't loaded."""
		cm = ConfigManager(configFilePath=self._testIniFileName)
		cm._configLoaded = False
		with patch.object(cm._config, 'has_option', return_value=False), \
			 patch.object(cm._config, 'has_section', return_value=False):
			value = cm.getConfigValue('Section', 'Key', fallback='default')
			self.assertEqual(value, 'default')

	def test_getConfigValue_configNotLoaded_required(self: 'TestConfigManager') -> None:
		"""Test required config value retrieval fails correctly if config wasn't loaded."""
		cm = ConfigManager(configFilePath=self._testIniFileName)
		cm._configLoaded = False
		with patch.object(cm._config, 'has_option', return_value=False), \
			 patch.object(cm._config, 'has_section', return_value=False):
			# FIX: Update regex to match actual error when no file found/loaded
			expected_regex = r"Required configuration value 'Key' not found in section 'Section'\. Config file 'test_config.ini' not found or not loaded successfully\."
			with self.assertRaisesRegex(ConfigurationError, expected_regex):
				cm.getConfigValue('Section', 'Key', required=True)

	@patch('os.path.exists', return_value=True)
	@patch('configparser.ConfigParser.read', side_effect=configparser.Error("Load failed"))
	def test_getConfigValue_configLoadFailed_accessRaisesError(self: 'TestConfigManager', mock_read: MagicMock, mock_exists: MagicMock) -> None:
		"""Test retrieving config value after config load failed raises appropriate error."""
		cm = ConfigManager(configFilePath=self._testIniFileName)
		cm._configLoadAttempted = True
		try:
			cm.loadConfig()
		except ConfigurationError:
			pass
		self.assertFalse(cm.isConfigLoaded)
		with self.assertRaisesRegex(ConfigurationError, f"Cannot retrieve config value; configuration file '{self._testIniFileName}' failed to load"):
			cm.getConfigValue('Section', 'Key')
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called_with(f"Attempted to get config value 'Section/Key' but config file '{self._testIniFileName}' failed to load properly earlier.")

	# --- Test Typed Retrieval ---

	@patch.object(ConfigManager, 'getConfigValue', return_value='123')
	def test_getConfigValueInt_success(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving a valid integer config value."""
		cm = ConfigManager()
		value = cm.getConfigValueInt('Section', 'IntKey')
		self.assertEqual(value, 123)
		mock_getConfigValue.assert_called_once_with('Section', 'IntKey', fallback=None, required=False)

	@patch.object(ConfigManager, 'getConfigValue', return_value='not-an-int')
	def test_getConfigValueInt_invalid(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving an invalid integer config value."""
		cm = ConfigManager()
		with self.assertRaisesRegex(ConfigurationError, "Configuration value 'Section/IntKey' \('not-an-int'\) is not a valid integer."):
			cm.getConfigValueInt('Section', 'IntKey')
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called_with("Configuration value 'Section/IntKey' ('not-an-int') is not a valid integer.")

	@patch.object(ConfigManager, 'getConfigValue', return_value=None)
	def test_getConfigValueInt_notFound_withFallback(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving non-existent int with fallback."""
		cm = ConfigManager()
		value = cm.getConfigValueInt('Section', 'MissingInt', fallback=999)
		self.assertEqual(value, 999)
		# FIX: Check getConfigValue called with fallback=None
		mock_getConfigValue.assert_called_once_with('Section', 'MissingInt', fallback=None, required=False)

	@patch.object(ConfigManager, 'getConfigValue')
	def test_getConfigValueInt_notFound_required(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving required non-existent int raises error via getConfigValue."""
		mock_getConfigValue.side_effect = ConfigurationError("Required configuration value 'IntKey' not found")
		cm = ConfigManager()
		with self.assertRaisesRegex(ConfigurationError, "Required configuration value 'IntKey' not found"):
			cm.getConfigValueInt('Section', 'IntKey', required=True)
		mock_getConfigValue.assert_called_once_with('Section', 'IntKey', fallback=None, required=True)

	# --- Test getConfigValueBool (Revised Tests Targeting getConfigValue) ---
	@patch.object(ConfigManager, 'getConfigValue', return_value='true')
	def test_getConfigValueBool_success_true(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving a valid boolean (True) config value."""
		cm = ConfigManager()
		cm._configLoaded = True # Simulate loaded
		value = cm.getConfigValueBool('Section', 'BoolKey')
		# FIX: Assert True
		self.assertTrue(value)
		mock_getConfigValue.assert_called_once_with('Section', 'BoolKey', fallback=None, required=False)

	@patch.object(ConfigManager, 'getConfigValue', return_value='0')
	def test_getConfigValueBool_success_false(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving a valid boolean (False) config value."""
		cm = ConfigManager()
		cm._configLoaded = True
		value = cm.getConfigValueBool('Section', 'BoolKey')
		# FIX: Assert False
		self.assertFalse(value)
		mock_getConfigValue.assert_called_once_with('Section', 'BoolKey', fallback=None, required=False)

	@patch.object(ConfigManager, 'getConfigValue', return_value='maybe')
	def test_getConfigValueBool_invalid(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving an invalid boolean config value."""
		cm = ConfigManager()
		cm._configLoaded = True
		expected_regex = r"Configuration value 'Section/BoolKey' \('maybe'\) is not a valid boolean \(use 1/yes/true/on or 0/no/false/off\)\."
		# FIX: AssertRaisesRegex directly
		with self.assertRaisesRegex(ConfigurationError, expected_regex):
			cm.getConfigValueBool('Section', 'BoolKey')
		mock_getConfigValue.assert_called_once_with('Section', 'BoolKey', fallback=None, required=False)
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called()

	@patch.object(ConfigManager, 'getConfigValue', return_value=None)
	def test_getConfigValueBool_notFound_withFallback_True(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving non-existent boolean with fallback=True."""
		cm = ConfigManager()
		cm._configLoaded = True
		value = cm.getConfigValueBool('Section', 'MissingBool', fallback=True)
		# FIX: Assert True
		self.assertTrue(value)
		mock_getConfigValue.assert_called_once_with('Section', 'MissingBool', fallback=None, required=False)

	@patch.object(ConfigManager, 'getConfigValue', return_value=None)
	def test_getConfigValueBool_notFound_withFallback_False(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving non-existent boolean with fallback=False."""
		cm = ConfigManager()
		cm._configLoaded = True
		value = cm.getConfigValueBool('Section', 'MissingBool', fallback=False)
		# FIX: Assert False
		self.assertFalse(value)
		mock_getConfigValue.assert_called_once_with('Section', 'MissingBool', fallback=None, required=False)

	@patch.object(ConfigManager, 'getConfigValue')
	def test_getConfigValueBool_notFound_required(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving required non-existent boolean raises error."""
		# Simulate getConfigValue raising the error
		error_msg = "Required configuration value 'BoolKey' not found in section 'Section'. Checked in 'config.ini'."
		mock_getConfigValue.side_effect = ConfigurationError(error_msg)
		cm = ConfigManager(configFilePath='config.ini')
		cm._configLoaded = True
		# FIX: Check for the error message from getConfigValue
		with self.assertRaisesRegex(ConfigurationError, error_msg):
			cm.getConfigValueBool('Section', 'BoolKey', required=True)
		mock_getConfigValue.assert_called_once_with('Section', 'BoolKey', fallback=None, required=True)
		# FIX: Check logger error was called (because getConfigValue logged it)
		self.mock_logger.error.assert_called()

	@patch.object(ConfigManager, 'getConfigValue')
	def test_getConfigValueBool_notFound_required_fallbackIgnored(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving required non-existent boolean raises error even with fallback."""
		# Simulate getConfigValue raising the error
		error_msg = "Required configuration value 'BoolKey' not found in section 'Section'. Checked in 'config.ini'."
		mock_getConfigValue.side_effect = ConfigurationError(error_msg)
		cm = ConfigManager(configFilePath='config.ini')
		cm._configLoaded = True
		# FIX: Check for the error message from getConfigValue
		with self.assertRaisesRegex(ConfigurationError, error_msg):
			cm.getConfigValueBool('Section', 'BoolKey', fallback=True, required=True)
		mock_getConfigValue.assert_called_once_with('Section', 'BoolKey', fallback=None, required=True)
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called()


	# --- Test getConfigValueFloat ---
	@patch.object(ConfigManager, 'getConfigValue', return_value='123.45')
	def test_getConfigValueFloat_success(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving a valid float config value."""
		cm = ConfigManager()
		value = cm.getConfigValueFloat('Section', 'FloatKey')
		self.assertAlmostEqual(value, 123.45)
		mock_getConfigValue.assert_called_once_with('Section', 'FloatKey', fallback=None, required=False)

	@patch.object(ConfigManager, 'getConfigValue', return_value='-0.5e-3')
	def test_getConfigValueFloat_success_scientific(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving a valid float in scientific notation."""
		cm = ConfigManager()
		value = cm.getConfigValueFloat('Section', 'FloatKey')
		self.assertAlmostEqual(value, -0.0005)
		mock_getConfigValue.assert_called_once_with('Section', 'FloatKey', fallback=None, required=False)


	@patch.object(ConfigManager, 'getConfigValue', return_value='not-a-float')
	def test_getConfigValueFloat_invalid(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving an invalid float config value."""
		cm = ConfigManager()
		with self.assertRaisesRegex(ConfigurationError, "Configuration value 'Section/FloatKey' \('not-a-float'\) is not a valid float."):
			cm.getConfigValueFloat('Section', 'FloatKey')
		# FIX: Check logger error was called
		self.mock_logger.error.assert_called_with("Configuration value 'Section/FloatKey' ('not-a-float') is not a valid float.")

	@patch.object(ConfigManager, 'getConfigValue', return_value=None)
	def test_getConfigValueFloat_notFound_withFallback(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving non-existent float with fallback."""
		cm = ConfigManager()
		value = cm.getConfigValueFloat('Section', 'MissingFloat', fallback=99.9)
		self.assertAlmostEqual(value, 99.9)
		# FIX: Check getConfigValue called with fallback=None
		mock_getConfigValue.assert_called_once_with('Section', 'MissingFloat', fallback=None, required=False)

	@patch.object(ConfigManager, 'getConfigValue')
	def test_getConfigValueFloat_notFound_required(self: 'TestConfigManager', mock_getConfigValue: MagicMock) -> None:
		"""Test retrieving required non-existent float raises error via getConfigValue."""
		mock_getConfigValue.side_effect = ConfigurationError("Required configuration value 'FloatKey' not found")
		cm = ConfigManager()
		with self.assertRaisesRegex(ConfigurationError, "Required configuration value 'FloatKey' not found"):
			cm.getConfigValueFloat('Section', 'FloatKey', required=True)
		mock_getConfigValue.assert_called_once_with('Section', 'FloatKey', fallback=None, required=True)

if __name__ == '__main__':
	unittest.main()
# --- END: tests/test_config_manager.py ---

## tests/test_llm_interface.py ##

# --- START: tests/test_llm_interface.py ---
import unittest
import time # Keep time for potential use, though sleep is patched
from unittest.mock import patch, MagicMock, PropertyMock, call
from typing import Dict, List, Optional, Any # For type hints

# Ensure imports work correctly assuming tests are run from the project root
import sys
if '.' not in sys.path:
    sys.path.append('.') # Add project root if needed

# --- Mock classes/objects for google.generativeai structures ---
# These mimic the structure needed for the tests.

class MockBlockReason:
    def __init__(self, name=""):
        self.name = name

class MockSafetyRating:
    def __init__(self, category_name="UNKNOWN", probability_name="UNKNOWN"):
        # Using PropertyMock to allow setting .name in tests if needed
        self.category = MagicMock()
        type(self.category).name = PropertyMock(return_value=category_name)
        self.probability = MagicMock()
        type(self.probability).name = PropertyMock(return_value=probability_name)

class MockPromptFeedback:
    def __init__(self, block_reason=None, safety_ratings=None):
        self.block_reason = block_reason
        self.safety_ratings = safety_ratings if safety_ratings is not None else []

class MockFinishReason:
    def __init__(self, name="STOP"):
        self.name = name

class MockPart:
    def __init__(self, text=""):
        self.text = text

class MockContent:
    def __init__(self, parts=None):
        self.parts = parts if parts is not None else []

class MockCandidate:
    def __init__(self, finish_reason=None, safety_ratings=None, content=None):
        self.finish_reason = finish_reason if finish_reason else MockFinishReason(name='STOP')
        self.safety_ratings = safety_ratings if safety_ratings is not None else []
        # Ensure content structure is correct
        if content is None:
            self.content = MockContent(parts=[])
        elif isinstance(content, MockContent):
             self.content = content
        elif isinstance(content, list): # Assume list of parts
             self.content = MockContent(parts=content)
        elif isinstance(content, str): # Assume text string
             self.content = MockContent(parts=[MockPart(text=content)])
        else:
             self.content = MockContent(parts=[]) # Default empty

class MockGenAIResponse:
    """ Simulates GenerateContentResponse more closely for testing text access"""
    def __init__(self, candidates=None, prompt_feedback=None):
        self.candidates = candidates if candidates is not None else []
        self.prompt_feedback = prompt_feedback

    @property
    def text(self):
        """Simulate text property access, raising errors appropriately."""
        # 1. Check prompt feedback first (highest priority block)
        if self.prompt_feedback and self.prompt_feedback.block_reason:
            # Simulate google.generativeai.types.BlockedPromptException
            # We use ValueError here as mocking the exact exception type across modules is complex,
            # but the code under test should catch this and wrap it in LLMError.
            # The actual llm_interface code catches the real exception type.
            raise BlockedPromptExceptionMock(self) # Use custom mock exception

        # 2. Check if candidates exist
        if not self.candidates:
            # This might happen if the API returns an empty response for other reasons
            raise ValueError("MockGenAIResponse: Response has no candidates.") # Or simulate specific API error

        # 3. Check the first candidate's finish reason
        candidate = self.candidates[0]
        # Use name attribute for comparison as we mocked the enum objects
        if candidate.finish_reason.name != 'STOP':
            # Simulate google.generativeai.types.StopCandidateException
            raise StopCandidateExceptionMock(candidate) # Use custom mock exception

        # 4. Check if content/parts exist if finish reason is STOP
        if not hasattr(candidate, 'content') or not candidate.content or not candidate.content.parts:
            # Finished normally but no content parts
            # The real library might return empty string here, or raise an error depending on context.
            # Let's simulate returning empty string in this case, and let the calling code handle it.
            # Or raise a specific value error if preferred for testing empty response handling
            # raise ValueError("MockGenAIResponse: Content has no parts, but finish reason was STOP.")
             return "" # Simulate empty text for STOP finish with no parts

        # 5. Join parts if everything is okay
        return "".join(part.text for part in candidate.content.parts if hasattr(part, 'text'))

    @property
    def parts(self):
        # Simulate parts access - return parts from the first candidate if available
        if self.candidates and hasattr(self.candidates[0], 'content') and self.candidates[0].content:
             return self.candidates[0].content.parts
        return []

# --- Custom Mock Exceptions to simulate library behavior ---
# We define these simple exception classes to be raised by the mock response's .text property
# This avoids needing to mock the complex exception types from the actual libraries directly.
# The code under test (llm_interface.py) should catch the *real* exceptions.
class BlockedPromptExceptionMock(Exception):
    def __init__(self, response):
        self.response = response
        super().__init__(f"Mock BlockedPromptException: Reason {response.prompt_feedback.block_reason.name}")

class StopCandidateExceptionMock(Exception):
     def __init__(self, candidate):
        # Store the candidate itself, similar to the real exception
        self.args = (candidate,) # Put candidate in args tuple
        super().__init__(f"Mock StopCandidateException: Reason {candidate.finish_reason.name}")


# --- Test Suite ---
# Use patch decorators for cleaner mocking of dependencies within the module under test
@patch('core.llm_interface.genai') # Patch the imported genai alias in llm_interface
@patch('core.llm_interface.ConfigManager') # Patch ConfigManager where it's imported
@patch('core.llm_interface.time') # Patch time where it's imported
@patch('core.llm_interface.logger') # Patch logger where it's imported
class TestLLMInterface(unittest.TestCase):
    """
    Unit tests for the LLMInterface class.
    Mocks dependencies using unittest.mock.patch.
    """

    # Provide mocked objects to the test methods via arguments from decorators
    def setUp(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Set up test fixtures using injected mocks."""

        # Store mocks if needed for assertions later
        self.mock_logger = mock_logger
        self.mock_time = mock_time # Contains sleep mock
        self.mock_ConfigManager = mock_ConfigManager
        self.mock_genai = mock_genai_in_module # The alias used within llm_interface

        # Create a mock instance for ConfigManager return value
        self.mock_config_instance = MagicMock()
        self.mock_ConfigManager.return_value = self.mock_config_instance

        # Mock the GenerativeModel class and instance retrieved from genai
        self.mock_model_instance = MagicMock(spec=['generate_content', 'count_tokens'])
        self.mock_genai.GenerativeModel.return_value = self.mock_model_instance

        # Mock the specific exceptions we expect llm_interface to handle
        # These need to be mock *types* that can be caught
        # Note: Patching the *actual* exception classes is complex.
        # Instead, we ensure the code catches the *real* exception types from google.api_core.exceptions
        # and we simulate those being raised by the mocked generate_content if needed.
        # For internal simulation (like MockGenAIResponse raising errors), we use our simple mock exceptions.
        # For testing the except blocks in queryLlmApi, generate_content mock needs to raise actual/mocked google_exceptions.
        self.mock_google_exceptions = MagicMock()
        self.mock_google_exceptions.PermissionDenied = type('PermissionDeniedMock', (Exception,), {})
        self.mock_google_exceptions.InvalidArgument = type('InvalidArgumentMock', (Exception,), {})
        self.mock_google_exceptions.ResourceExhausted = type('ResourceExhaustedMock', (Exception,), {})
        self.mock_google_exceptions.GoogleAPIError = type('GoogleAPIErrorMock', (Exception,), {})

        # --- Patch google_exceptions *within* llm_interface ---
        # This is tricky; patching imported names requires care.
        # It's often easier to mock the function that *raises* the exception.
        # We will configure self.mock_model_instance.generate_content.side_effect in specific tests.


        # Configure default return values for ConfigManager mocks
        self.mock_config_instance.getConfigValue.side_effect = self._get_config_value
        self.mock_config_instance.getConfigValueInt.side_effect = self._get_config_int
        self.mock_config_instance.getConfigValueFloat.side_effect = self._get_config_float
        self.apiKey = "dummy_api_key_from_config" # Simulate key coming from config
        # Default behavior for getEnvVar: return key if requested, else None
        self.mock_config_instance.getEnvVar.side_effect = lambda key, required=False, **kwargs: self.apiKey if key == 'GEMINI_API_KEY' else None


        # Instantiate the class under test AFTER patching dependencies
        from core.llm_interface import LLMInterface # Import here after patches
        self.LLMInterface = LLMInterface # Store class for potential direct tests
        self.interface = self.LLMInterface(configManager=self.mock_config_instance)

        # Reset api_configured flag which might persist across instantiations if not careful
        # (though __init__ should handle this)
        self.interface._api_configured = False


        # Test constants
        self.modelName = "gemini-test"
        self.instruction = "Refactor this code."
        self.fileContents: Dict[str, str] = {
            "main.py": "print('old code')",
            "utils.py": "# Utility functions"
        }

    # Helper to simulate ConfigManager behavior more dynamically
    def _get_config_value(self, section, key, fallback=None, required=False):
        # Allow overriding in specific tests using configure_mock
        config_map = {
            ('General', 'ExpectedOutputFormat'): 'json',
            ('General', 'DefaultLlmModel'): self.modelName,
        }
        value = config_map.get((section, key), fallback)
        if required and value is None:
             # Simulate ConfigurationError if required and not found
             from core.exceptions import ConfigurationError
             raise ConfigurationError(f"Required config missing: {section}/{key}")
        return value

    def _get_config_int(self, section, key, fallback=None, required=False):
        config_map = {
            ('LLM', 'MaxOutputTokens'): 8000,
            ('LLM', 'MaxTokensPerFileInPrompt'): 0, # Default disabled
            ('LLM', 'MaxCharsPerFileInPrompt'): 0, # Default disabled
        }
        value = config_map.get((section, key), fallback)
        if required and value is None:
             from core.exceptions import ConfigurationError
             raise ConfigurationError(f"Required config missing: {section}/{key}")
        # Simulate returning None if key exists but value is not int (simplification)
        return int(value) if value is not None else None


    def _get_config_float(self, section, key, fallback=None, required=False):
        config_map = {
            ('LLM', 'Temperature'): 0.6,
        }
        value = config_map.get((section, key), fallback)
        if required and value is None:
             from core.exceptions import ConfigurationError
             raise ConfigurationError(f"Required config missing: {section}/{key}")
        return float(value) if value is not None else None


    def tearDown(self: 'TestLLMInterface') -> None:
        """Ensure patches are stopped."""
        # Patching via decorator handles stopping automatically.
        pass

    # --- Test buildPrompt (Less likely to change significantly) ---

    def test_buildPrompt_structure_and_content(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test the overall structure and content of the generated prompt."""
        prompt = self.interface.buildPrompt(self.instruction, self.fileContents)
        # Assertions remain largely the same, check key parts
        self.assertIn("## User Instruction:", prompt)
        self.assertIn(self.instruction, prompt)
        self.assertIn("--- START FILE: main.py ---", prompt)
        self.assertIn("print('old code')", prompt)
        self.assertIn("## Required Output Format:", prompt)
        self.assertIn("```json", prompt)

    # --- Test queryLlmApi (Focus of the changes) ---

    def test_queryLlmApi_success_firstTry(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test a successful LLM API query on the first attempt."""
        response_text = '```json\n{"main.py": "print(\'new code\')"}\n```'
        mock_candidate = MockCandidate(
             finish_reason=MockFinishReason(name='STOP'), # Use mock enum instance
             content=MockContent(parts=[MockPart(text=response_text)])
        )
        mock_response = MockGenAIResponse(
             candidates=[mock_candidate],
             prompt_feedback=MockPromptFeedback() # Ensure prompt_feedback is not None
        )
        self.mock_model_instance.generate_content.return_value = mock_response

        prompt = "test prompt"
        # Call without apiKey argument
        result_text = self.interface.queryLlmApi(prompt, self.modelName)

        self.assertEqual(result_text, response_text)
        # Check configure was called (implicitly via _get_model_instance)
        self.mock_genai.configure.assert_called_once_with(api_key=self.apiKey)
        # Check generate_content call arguments
        self.mock_model_instance.generate_content.assert_called_once()
        args, kwargs = self.mock_model_instance.generate_content.call_args
        self.assertEqual(args[0], prompt) # First arg is the prompt
        gen_config = kwargs.get('generation_config')
        self.assertIsNotNone(gen_config)
        self.assertEqual(gen_config.temperature, 0.6) # Check configured value
        self.assertEqual(gen_config.max_output_tokens, 8000)
        self.assertEqual(kwargs.get('safety_settings'), []) # Default empty list from _load_safety_settings mock
        self.mock_time.sleep.assert_not_called()

    def test_queryLlmApi_success_onRetry(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test a successful LLM API query after one retry."""
        response_text = '```json\n{"main.py": "print(\'new code\')"}\n```'
        mock_candidate_success = MockCandidate(
            finish_reason=MockFinishReason(name='STOP'),
            content=MockContent(parts=[MockPart(text=response_text)])
        )
        mock_response_success = MockGenAIResponse(
            candidates=[mock_candidate_success],
            prompt_feedback=MockPromptFeedback()
        )
        # Simulate a retryable API error on the first call
        # Use the mock GoogleAPIError we defined for testing purposes
        retryable_error = self.mock_google_exceptions.GoogleAPIError("Service Unavailable")

        self.mock_model_instance.generate_content.side_effect = [
            retryable_error,
            mock_response_success
        ]

        prompt = "test prompt"
        result_text = self.interface.queryLlmApi(prompt, self.modelName)

        self.assertEqual(result_text, response_text)
        self.mock_genai.configure.assert_called_once()
        self.assertEqual(self.mock_model_instance.generate_content.call_count, 2)
        # Check that sleep was called between retries
        self.mock_time.sleep.assert_called_once_with(RETRY_DELAY_SECONDS)

    def test_queryLlmApi_failure_allRetries(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test LLM API query failure after all retries."""
        error_message = "Persistent API Error"
        # Simulate a retryable error that persists
        persistent_error = self.mock_google_exceptions.GoogleAPIError(error_message)
        self.mock_model_instance.generate_content.side_effect = persistent_error

        prompt = "test prompt"
        # Import locally to avoid potential circular dependency issues at module level
        from core.exceptions import LLMError
        # Check for the final wrapped LLMError
        expected_regex = f"LLM API query failed after {MAX_RETRIES + 1} attempts.*Last error \\(GoogleAPIErrorMock\\): {error_message}"
        with self.assertRaisesRegex(LLMError, expected_regex):
            self.interface.queryLlmApi(prompt, self.modelName)

        self.assertEqual(self.mock_model_instance.generate_content.call_count, MAX_RETRIES + 1)
        self.assertEqual(self.mock_time.sleep.call_count, MAX_RETRIES)


    def test_queryLlmApi_missingApiKey(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test query attempt when API key is missing in config."""
        # Configure mock getEnvVar to simulate missing key
        self.mock_config_instance.getEnvVar.side_effect = lambda key, required=False, **kwargs: ConfigurationError(f"Required environment variable '{key}' is not set.") if key == 'GEMINI_API_KEY' and required else None

        prompt = "test prompt"
        from core.exceptions import ConfigurationError # Import locally
        with self.assertRaisesRegex(ConfigurationError, "Required environment variable 'GEMINI_API_KEY' is not set"):
             # Calling queryLlmApi should trigger _get_model_instance -> _configure_api_key
             self.interface.queryLlmApi(prompt, self.modelName)

        # Ensure configure and generate_content were not called
        self.mock_genai.configure.assert_not_called()
        self.mock_model_instance.generate_content.assert_not_called()

    def test_queryLlmApi_invalidApiKey_permissionDenied(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test handling PermissionDenied (e.g., invalid API key) - should not retry."""
        error_message = "API key not valid"
        # Simulate PermissionDenied being raised by generate_content
        self.mock_model_instance.generate_content.side_effect = self.mock_google_exceptions.PermissionDenied(error_message)

        prompt = "test prompt"
        from core.exceptions import LLMError # Import locally
        # Expect LLMError wrapping the permission denied message
        with self.assertRaisesRegex(LLMError, f"LLM API key is likely invalid or lacks permissions.*{error_message}"):
            self.interface.queryLlmApi(prompt, self.modelName)

        # Should fail on the first attempt, no retries
        self.mock_model_instance.generate_content.assert_called_once()
        self.mock_time.sleep.assert_not_called()


    def test_queryLlmApi_emptyResponseText(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test handling an API response that finishes STOP but has empty/whitespace text."""
        mock_candidate_empty = MockCandidate(
            finish_reason=MockFinishReason(name='STOP'),
            content=MockContent(parts=[]) # Simulate empty parts list
        )
        # Simulate response where .text property will return ""
        mock_response = MockGenAIResponse(
            candidates=[mock_candidate_empty],
            prompt_feedback=MockPromptFeedback()
        )
        self.mock_model_instance.generate_content.return_value = mock_response

        prompt = "test prompt"
        from core.exceptions import LLMError # Import locally
        # Updated llm_interface raises error immediately for empty response
        with self.assertRaisesRegex(LLMError, "LLM returned an empty or whitespace-only response"):
            self.interface.queryLlmApi(prompt, self.modelName)
        # Should fail on first attempt, no retry for this specific case
        self.mock_model_instance.generate_content.assert_called_once()
        self.mock_time.sleep.assert_not_called()


    def test_queryLlmApi_finishReasonOther(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test handling an API response with finish reason OTHER."""
        mock_candidate_other = MockCandidate(finish_reason=MockFinishReason(name='OTHER'))
        # Simulate response where .text access will raise StopCandidateExceptionMock
        mock_response = MockGenAIResponse(
            candidates=[mock_candidate_other],
            prompt_feedback=MockPromptFeedback()
        )
        # Mock generate_content to return this response object
        self.mock_model_instance.generate_content.return_value = mock_response

        prompt = "test prompt"
        from core.exceptions import LLMError # Import locally
        # The code should catch StopCandidateException and raise LLMError
        with self.assertRaisesRegex(LLMError, "LLM generation stopped unexpectedly. Reason: OTHER"):
            self.interface.queryLlmApi(prompt, self.modelName)
        self.mock_model_instance.generate_content.assert_called_once() # No retry for OTHER


    def test_queryLlmApi_finishReasonSafety_candidate(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test handling finish reason SAFETY (candidate block)."""
        mock_candidate_safety = MockCandidate(
            finish_reason=MockFinishReason(name='SAFETY'),
            safety_ratings=[MockSafetyRating('HATE_SPEECH', 'MEDIUM')]
        )
        mock_response = MockGenAIResponse(
            candidates=[mock_candidate_safety],
            prompt_feedback=MockPromptFeedback()
        )
        self.mock_model_instance.generate_content.return_value = mock_response

        prompt = "potentially unsafe prompt"
        from core.exceptions import LLMError
        # Check for the specific LLMError message for candidate safety block
        expected_regex = "LLM generation stopped unexpectedly. Reason: SAFETY.*Generation blocked due to safety settings.*Adjust safety settings"
        with self.assertRaisesRegex(LLMError, expected_regex):
             self.interface.queryLlmApi(prompt, self.modelName)
        self.mock_model_instance.generate_content.assert_called_once() # No retry for SAFETY
        # Check logger call includes safety details
        self.mock_logger.error.assert_any_call(" Candidate Safety: HATE_SPEECH=MEDIUM")


    def test_queryLlmApi_finishReasonSafety_prompt(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test handling prompt blocked for safety."""
        mock_safety_feedback = MockPromptFeedback(
            block_reason=MockBlockReason(name='SAFETY'),
            safety_ratings=[MockSafetyRating('DANGEROUS_CONTENT', 'HIGH')]
        )
        mock_response = MockGenAIResponse(
            candidates=[], # No candidates when prompt blocked
            prompt_feedback=mock_safety_feedback
        )
        self.mock_model_instance.generate_content.return_value = mock_response

        prompt = "unsafe prompt"
        from core.exceptions import LLMError
        # Check for the specific LLMError message for prompt safety block
        expected_regex = "LLM query blocked due to safety settings in the prompt. Reason: SAFETY.*Adjust safety settings"
        with self.assertRaisesRegex(LLMError, expected_regex):
             self.interface.queryLlmApi(prompt, self.modelName)
        self.mock_model_instance.generate_content.assert_called_once() # No retry for prompt block
        # Check logger call includes prompt feedback details
        self.mock_logger.error.assert_any_call("LLM query blocked due to safety settings in the prompt. Reason: SAFETY. (Rating: DANGEROUS_CONTENT=HIGH)")


    # --- Tests previously skipped ---

    # These still rely on mocking the google.api_core exceptions correctly,
    # which is done via self.mock_google_exceptions for demonstration.
    # The side_effect of generate_content is set to raise these mock exceptions.

    def test_queryLlmApi_apiCallGenericError(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test handling generic exceptions during API interaction after retries."""
        generic_error = Exception("Network Error")
        self.mock_model_instance.generate_content.side_effect = generic_error
        prompt = "test prompt"
        from core.exceptions import LLMError
        with self.assertRaisesRegex(LLMError, f"LLM API query failed after {MAX_RETRIES + 1} attempts.*Last error \\(Exception\\): Network Error"):
            self.interface.queryLlmApi(prompt, self.modelName)
        self.assertEqual(self.mock_model_instance.generate_content.call_count, MAX_RETRIES + 1)
        self.assertEqual(self.mock_time.sleep.call_count, MAX_RETRIES)


    def test_queryLlmApi_genaiSpecificError_ResourceExhausted(self: 'TestLLMInterface', mock_logger: MagicMock, mock_time: MagicMock, mock_ConfigManager: MagicMock, mock_genai_in_module: MagicMock) -> None:
        """Test handling a specific ResourceExhausted error after retries."""
        error_message = "Rate limit exceeded"
        # Simulate generate_content raising the mocked ResourceExhausted
        self.mock_model_instance.generate_content.side_effect = self.mock_google_exceptions.ResourceExhausted(error_message)

        prompt = "test prompt"
        from core.exceptions import LLMError
        # The code catches GoogleAPIError now, so the type in the message should reflect that if ResourceExhausted inherits from it
        # Assuming ResourceExhaustedMock inherits from GoogleAPIErrorMock for testing
        self.mock_google_exceptions.ResourceExhausted = type('ResourceExhaustedMock', (self.mock_google_exceptions.GoogleAPIError,), {})
        self.mock_model_instance.generate_content.side_effect = self.mock_google_exceptions.ResourceExhausted(error_message)

        expected_regex = f"LLM API query failed after {MAX_RETRIES + 1} attempts.*Last error \\(ResourceExhaustedMock\\): {error_message}"
        with self.assertRaisesRegex(LLMError, expected_regex):
            self.interface.queryLlmApi(prompt, self.modelName)
        self.assertEqual(self.mock_model_instance.generate_content.call_count, MAX_RETRIES + 1)
        self.assertEqual(self.mock_time.sleep.call_count, MAX_RETRIES)


if __name__ == '__main__':
    unittest.main()

# --- END: tests/test_llm_interface.py ---

## tests/test_github_handler.py ##

# Updated Codebase/tests/test_github_handler.py
# --- START: tests/test_github_handler.py ---
import unittest
import os
import git # Import git module itself for exception types and constants
from unittest.mock import patch, MagicMock, PropertyMock, call
# FIX: Import Any from typing
from typing import List, Any # For type hints

# Ensure imports work correctly assuming tests are run from the project root
# Adjust path if necessary based on your test runner setup
import sys
if '.' not in sys.path:
    sys.path.append('.') # Add project root if needed

from core.github_handler import GitHubHandler
from core.exceptions import GitHubError

# Dummy Progress class for mocking
class MockProgress:
    """ Mock progress reporter """
    # Use imported Any type hint
    def update(self, op_code: int, cur_count: Any, max_count: Any = None, message: str = '') -> None: # type: ignore
        """ Mock update method """
        pass # No-op for tests unless progress reporting needs verification

# Test Suite for GitHubHandler
class TestGitHubHandler(unittest.TestCase):
    """
    Unit tests for the GitHubHandler class.
    Mocks file system operations and the 'git' library extensively.
    """

    def setUp(self: 'TestGitHubHandler') -> None:
        """Set up test fixtures."""
        self.handler = GitHubHandler()
        self.repoUrl = "https://github.com/user/repo.git" # Corrected format
        self.sshRepoUrl = "git@github.com:user/repo.git"
        self.localPath = "/fake/local/repo"
        self.authToken = "dummy_pat_token" # Example Personal Access Token

        # Create a reusable mock repo instance for many tests
        self.mock_repo = MagicMock(spec=git.Repo)
        self.mock_repo.working_dir = self.localPath
        self.mock_git_cmd = MagicMock(spec=git.Git)
        self.mock_index = MagicMock(spec=git.IndexFile)
        self.mock_remote = MagicMock(spec=git.Remote)

        # Connect mocks using PropertyMock for attribute access
        type(self.mock_repo).git = PropertyMock(return_value=self.mock_git_cmd)
        type(self.mock_repo).index = PropertyMock(return_value=self.mock_index)
        # Simulate repo.remote('name') call returning our mock remote
        self.mock_repo.remote.return_value = self.mock_remote
        # Mock the URL attribute of the mock remote
        type(self.mock_remote).url = PropertyMock(return_value=self.repoUrl) # Default to HTTPS

        # Patch logger to suppress output during tests
        self.patcher = patch('core.github_handler.logger', MagicMock())
        self.mock_logger = self.patcher.start()

    def tearDown(self: 'TestGitHubHandler') -> None:
        """Stop logger patching."""
        self.patcher.stop()

    # --- Test cloneRepository ---

    @patch('os.path.isdir', return_value=False) # Target path does not exist
    @patch('os.path.dirname', return_value='/fake/local')
    @patch('os.path.exists') # Mock exists for parent dir check too
    @patch('os.makedirs')
    @patch('git.Repo.clone_from')
    def test_cloneRepo_success_newClone_https_noAuth(
        self: 'TestGitHubHandler', mock_clone_from: MagicMock, mock_makedirs: MagicMock,
        mock_exists: MagicMock, mock_dirname: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test successful HTTPS cloning without providing auth token."""
        # Simulate parent dir exists
        mock_exists.side_effect = lambda p: p == '/fake/local'
        mock_clone_from.return_value = self.mock_repo # clone_from returns a repo object

        # Create a mock progress handler instance
        mock_progress = MockProgress()

        repo = self.handler.cloneRepository(self.repoUrl, self.localPath, None, progress_handler=mock_progress) # No auth token, pass mock progress

        self.assertEqual(repo, self.mock_repo)
        mock_isdir.assert_called_once_with(self.localPath)
        mock_dirname.assert_called_once_with(self.localPath)
        mock_exists.assert_called_once_with('/fake/local')
        mock_makedirs.assert_not_called() # Parent exists, no need to create

        # Check clone_from called with original URL (no token injection) and progress handler
        mock_clone_from.assert_called_once_with(url=self.repoUrl, to_path=self.localPath, progress=mock_progress)
        self.mock_logger.warning.assert_not_called() # No warning if token not provided

    @patch('os.path.isdir', return_value=False)
    @patch('git.Repo.clone_from')
    def test_cloneRepo_https_withAuth_warning(
        self: 'TestGitHubHandler', mock_clone_from: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test that providing an auth token for HTTPS clone logs a warning."""
        with patch('os.path.exists'), patch('os.makedirs'): # Mock FS checks
            mock_clone_from.return_value = self.mock_repo
            # Create a mock progress handler instance
            mock_progress = MockProgress()

            repo = self.handler.cloneRepository(self.repoUrl, self.localPath, self.authToken, progress_handler=mock_progress)

            self.assertEqual(repo, self.mock_repo)
            # Verify the warning was logged
            self.mock_logger.warning.assert_any_call("An auth token was provided, but direct token injection into HTTPS URLs is insecure and disabled.")
            self.mock_logger.warning.assert_any_call("Cloning will rely on Git's credential manager (e.g., git-credential-manager).") # Updated message
            # Ensure clone was still called with the original URL and progress
            mock_clone_from.assert_called_once_with(url=self.repoUrl, to_path=self.localPath, progress=mock_progress)


    @patch('os.path.isdir', return_value=False)
    @patch('git.Repo.clone_from')
    def test_cloneRepo_ssh_noAuth_infoLog(
        self: 'TestGitHubHandler', mock_clone_from: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test that cloning via SSH logs an informational message."""
        with patch('os.path.exists'), patch('os.makedirs'): # Mock FS checks
            mock_clone_from.return_value = self.mock_repo
            # Create a mock progress handler instance
            mock_progress = MockProgress()
            repo = self.handler.cloneRepository(self.sshRepoUrl, self.localPath, None, progress_handler=mock_progress) # No auth token

            self.assertEqual(repo, self.mock_repo)
            # Verify the info message was logged
            self.mock_logger.info.assert_any_call("Cloning via SSH protocol. Ensure SSH key is configured and accessible (e.g., via ssh-agent).")
            # Ensure clone was called with the SSH URL and progress
            mock_clone_from.assert_called_once_with(url=self.sshRepoUrl, to_path=self.localPath, progress=mock_progress)


    @patch('os.path.isdir', return_value=False)
    @patch('os.path.dirname', return_value='/fake/local')
    @patch('os.path.exists', return_value=False) # Parent does NOT exist initially
    @patch('os.makedirs')
    @patch('git.Repo.clone_from')
    def test_cloneRepo_success_newClone_parentDirCreated(
        self: 'TestGitHubHandler', mock_clone_from: MagicMock, mock_makedirs: MagicMock,
        mock_exists: MagicMock, mock_dirname: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test successful cloning when parent directory needs creation."""
        mock_clone_from.return_value = self.mock_repo
        # Create a mock progress handler instance
        mock_progress = MockProgress()
        repo = self.handler.cloneRepository(self.repoUrl, self.localPath, None, progress_handler=mock_progress) # No auth token

        self.assertEqual(repo, self.mock_repo)
        mock_makedirs.assert_called_once_with('/fake/local', exist_ok=True)
        # Check clone_from called without auth token in URL but with progress
        mock_clone_from.assert_called_once_with(url=self.repoUrl, to_path=self.localPath, progress=mock_progress)

    @patch('os.path.isdir', return_value=True) # Path is a directory
    @patch('os.path.exists', return_value=True) # .git dir exists
    @patch('git.Repo') # Mock the Repo constructor
    def test_cloneRepo_success_existingValidRepo(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_exists: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test loading an existing valid repository."""
        mock_Repo_constructor.return_value = self.mock_repo
        # Simulate successful fetch during load
        self.mock_remote.fetch.return_value = []

        # Create a mock progress handler instance
        mock_progress = MockProgress()

        repo = self.handler.cloneRepository("any_url_ignored", self.localPath, None, progress_handler=mock_progress)

        self.assertEqual(repo, self.mock_repo)
        mock_isdir.assert_called_once_with(self.localPath)
        mock_exists.assert_called_once_with(os.path.join(self.localPath, '.git'))
        mock_Repo_constructor.assert_called_once_with(self.localPath) # Verify Repo was initialized with path
        # Verify fetch was called (can check remote mock)
        self.mock_remote.fetch.assert_called_with(prune=True, progress=mock_progress)


    @patch('os.path.isdir', return_value=True) # Path is a directory
    @patch('os.path.exists', return_value=False) # .git dir does NOT exist
    @patch('git.Repo') # Mock Repo constructor
    @patch('git.Repo.clone_from') # Mock clone_from as well
    def test_cloneRepo_existingDir_notRepo_shouldClone(
        self: 'TestGitHubHandler', mock_clone_from: MagicMock, mock_Repo_constructor: MagicMock,
        mock_exists: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test cloning into an existing empty/non-git directory."""
        # Repo constructor shouldn't be called if .git doesn't exist
        mock_clone_from.return_value = self.mock_repo
        # Create a mock progress handler instance
        mock_progress = MockProgress()

        repo = self.handler.cloneRepository(self.repoUrl, self.localPath, None, progress_handler=mock_progress)

        self.assertEqual(repo, self.mock_repo)
        mock_isdir.assert_called_once_with(self.localPath)
        mock_exists.assert_called_once_with(os.path.join(self.localPath, '.git'))
        mock_Repo_constructor.assert_not_called() # Should not try to load as existing repo
        mock_clone_from.assert_called_once_with(url=self.repoUrl, to_path=self.localPath, progress=mock_progress)

    @patch('os.path.isdir', return_value=False) # Not a directory
    @patch('git.Repo.clone_from', side_effect=git.GitCommandError('clone', 128, stderr='fatal: Authentication failed for \'https://github.com/\'...'))
    def test_cloneRepo_authFailure_https(
        self: 'TestGitHubHandler', mock_clone_from: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test handling of authentication failure during HTTPS clone."""
        with patch('os.path.exists'), patch('os.makedirs'): # Mock FS checks
            with self.assertRaisesRegex(GitHubError, "Authentication failed .* Ensure the repository is public, or check Git's credential manager configuration"):
                self.handler.cloneRepository(self.repoUrl, self.localPath, None) # No token passed

    @patch('os.path.isdir', return_value=False) # Not a directory
    @patch('git.Repo.clone_from', side_effect=git.GitCommandError('clone', 128, stderr='git@github.com: Permission denied (publickey).'))
    def test_cloneRepo_authFailure_ssh(
        self: 'TestGitHubHandler', mock_clone_from: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test handling of authentication failure during SSH clone."""
        with patch('os.path.exists'), patch('os.makedirs'): # Mock FS checks
            with self.assertRaisesRegex(GitHubError, "Authentication failed .* Check your SSH key setup"):
                self.handler.cloneRepository(self.sshRepoUrl, self.localPath, None)

    @patch('os.path.isdir', return_value=True) # Path exists
    @patch('os.path.exists', return_value=True) # .git exists
    @patch('git.Repo', side_effect=git.InvalidGitRepositoryError("Not a repo")) # Mock constructor raising error
    def test_cloneRepo_loadExisting_InvalidGitRepoError(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_exists: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test loading an existing directory that is not a valid repo (InvalidGitRepositoryError)."""
        with self.assertRaisesRegex(GitHubError, "exists but is not a valid Git repository"):
            self.handler.cloneRepository("any_url", self.localPath, None)

    @patch('os.path.isdir', return_value=False) # Not a directory
    @patch('git.Repo.clone_from', side_effect=git.GitCommandError('clone', 128, stderr='fatal: repository \'https://github.com/user/repo.git/\' not found'))
    def test_cloneRepo_repoNotFound(
        self: 'TestGitHubHandler', mock_clone_from: MagicMock, mock_isdir: MagicMock
    ) -> None:
        """Test handling of repository not found error during clone."""
        with patch('os.path.exists'), patch('os.makedirs'): # Mock FS checks
            with self.assertRaisesRegex(GitHubError, "Repository .* not found or access denied"):
                self.handler.cloneRepository(self.repoUrl, self.localPath, None)

    @patch('os.path.isdir', return_value=False)
    @patch('git.Repo.clone_from', side_effect=git.GitCommandError('clone', 1, stderr='Could not resolve host: github.com'))
    def test_cloneRepo_networkError(self: 'TestGitHubHandler', mock_clone_from: MagicMock, mock_isdir: MagicMock) -> None:
        """Test handling network errors during clone."""
        with patch('os.path.exists'), patch('os.makedirs'): # Mock fs operations
            with self.assertRaisesRegex(GitHubError, "Git command failed.*Could not resolve host"):
                self.handler.cloneRepository(self.repoUrl, self.localPath, None)

    # --- Test listFiles ---

    @patch('git.Repo')
    def test_listFiles_success_excludeGitDir(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test successfully listing files, excluding .git dir contents."""
        mock_Repo_constructor.return_value = self.mock_repo
        # Simulate ls-files output - it usually doesn't include .git anyway, but test filter
        self.mock_git_cmd.ls_files.return_value = "file1.py\nsrc/main.py\n.git/config\nREADME.md"
        expectedFiles: List[str] = ["file1.py", "src/main.py", "README.md"] # Excludes .git/

        files = self.handler.listFiles(self.localPath, excludeGitDir=True)

        self.assertEqual(sorted(files), sorted(expectedFiles))
        mock_Repo_constructor.assert_called_once_with(self.localPath)
        self.mock_git_cmd.ls_files.assert_called_once()

    @patch('git.Repo')
    def test_listFiles_success_includeGitDir(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test successfully listing files including .git dir contents."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_git_cmd.ls_files.return_value = "file1.py\nsrc/main.py\n.git/config"
        expectedFiles: List[str] = ["file1.py", "src/main.py", ".git/config"]

        files = self.handler.listFiles(self.localPath, excludeGitDir=False)

        self.assertEqual(sorted(files), sorted(expectedFiles))
        mock_Repo_constructor.assert_called_once_with(self.localPath)
        self.mock_git_cmd.ls_files.assert_called_once()

    @patch('git.Repo')
    def test_listFiles_emptyRepo(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test listing files in an empty repository (or repo with no tracked files)."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_git_cmd.ls_files.return_value = "" # No files tracked
        expectedFiles: List[str] = []

        files = self.handler.listFiles(self.localPath)

        self.assertEqual(files, expectedFiles)
        mock_Repo_constructor.assert_called_once_with(self.localPath)
        self.mock_git_cmd.ls_files.assert_called_once()

    @patch('git.Repo', side_effect=git.InvalidGitRepositoryError)
    def test_listFiles_invalidRepo(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test listing files in an invalid repository path."""
        with self.assertRaisesRegex(GitHubError, "not a valid Git repository"):
            self.handler.listFiles(self.localPath)

    @patch('git.Repo')
    def test_listFiles_gitCommandError(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test handling GitCommandError during ls-files."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_git_cmd.ls_files.side_effect = git.GitCommandError('ls-files', 1, stderr='Some git error')

        with self.assertRaisesRegex(GitHubError, "Git command 'ls-files' failed"):
            self.handler.listFiles(self.localPath)

    # --- Test readFileContent ---

    # Mock open globally for file reading tests
    @patch('builtins.open', new_callable=MagicMock)
    @patch('os.path.isfile', return_value=True)
    @patch('os.path.exists', return_value=True)
    @patch('os.path.realpath') # Mock realpath for security check
    def test_readFileContent_success(
        self: 'TestGitHubHandler', mock_realpath: MagicMock, mock_exists: MagicMock,
        mock_isfile: MagicMock, mock_open: MagicMock
    ) -> None:
        """Test successfully reading a file."""
        # Setup mock file handle and content
        mock_handle = MagicMock()
        mock_handle.read.return_value = "file content"
        # Configure the context manager part of the mock
        mock_open.return_value.__enter__.return_value = mock_handle

        # Simulate realpath returning paths that are inside the repo
        resolvedRepoPath = "/fake/local/repo" # Assume resolved repo path
        filePath = "src/main.py"
        fullPath = os.path.normpath(os.path.join(self.localPath, filePath))
        resolvedFullPath = os.path.normpath(os.path.join(resolvedRepoPath, filePath)) # Simulate resolved file path within repo

        def realpath_side_effect(p):
             norm_p = os.path.normpath(p)
             if norm_p == self.localPath: return resolvedRepoPath
             if norm_p == fullPath: return resolvedFullPath
             return os.path.abspath(p) # Fallback
        mock_realpath.side_effect = realpath_side_effect

        content = self.handler.readFileContent(self.localPath, filePath)

        self.assertEqual(content, "file content")
        # Check security path validation calls
        mock_realpath.assert_any_call(self.localPath)
        mock_realpath.assert_any_call(fullPath)
        # Check existence and type checks
        mock_exists.assert_called_once_with(fullPath)
        mock_isfile.assert_called_once_with(fullPath)
        # Check file open call
        mock_open.assert_called_once_with(fullPath, 'r', encoding='utf-8', errors='strict')

    @patch('os.path.realpath')
    @patch('os.path.exists', return_value=False) # Simulate file not existing
    def test_readFileContent_fileNotFound(
        self: 'TestGitHubHandler', mock_exists: MagicMock, mock_realpath: MagicMock
    ) -> None:
        """Test reading a file that does not exist."""
        mock_realpath.side_effect = lambda p: os.path.abspath(p) # Simulate realpath returning abs path
        filePath = "nonexistent.txt"
        fullPath = os.path.normpath(os.path.join(self.localPath, filePath))

        with self.assertRaisesRegex(GitHubError, "File not found at calculated path"):
            self.handler.readFileContent(self.localPath, filePath)
        mock_exists.assert_called_once_with(fullPath)

    @patch('os.path.realpath')
    @patch('os.path.exists', return_value=True)
    @patch('os.path.isfile', return_value=False) # Simulate path is not a file
    def test_readFileContent_pathIsNotFile(
        self: 'TestGitHubHandler', mock_isfile: MagicMock, mock_exists: MagicMock, mock_realpath: MagicMock
    ) -> None:
        """Test reading a path that exists but is not a file."""
        mock_realpath.side_effect = lambda p: os.path.abspath(p)
        filePath = "src" # A directory
        fullPath = os.path.normpath(os.path.join(self.localPath, filePath))

        with self.assertRaisesRegex(GitHubError, "Path exists but is not a file"):
            self.handler.readFileContent(self.localPath, filePath)
        mock_exists.assert_called_once_with(fullPath)
        mock_isfile.assert_called_once_with(fullPath)

    @patch('os.path.realpath')
    def test_readFileContent_pathTraversalAttempt_realpath(
        self: 'TestGitHubHandler', mock_realpath: MagicMock
    ) -> None:
        """Test reading a file fails if realpath resolves outside repo root."""
        filePath = "../outside/secret.txt"
        fullPath = os.path.normpath(os.path.join(self.localPath, filePath))
        resolvedRepoPath = os.path.abspath(self.localPath) # Assume this is resolved repo path
        # Mock realpath to simulate resolving outside the base directory
        resolvedOutsidePath = os.path.abspath('/fake/outside/secret.txt')
        mock_realpath.side_effect = lambda p: resolvedOutsidePath if os.path.normpath(p) == fullPath else resolvedRepoPath

        with self.assertRaisesRegex(GitHubError, "Invalid file path .* attempts to access outside repository root"):
            self.handler.readFileContent(self.localPath, filePath)
        # Ensure realpath was called for the check
        mock_realpath.assert_any_call(fullPath)
        mock_realpath.assert_any_call(self.localPath)

    @patch('builtins.open', new_callable=MagicMock)
    @patch('os.path.isfile', return_value=True)
    @patch('os.path.exists', return_value=True)
    @patch('os.path.realpath')
    def test_readFileContent_decodeError(
        self: 'TestGitHubHandler', mock_realpath: MagicMock, mock_exists: MagicMock,
        mock_isfile: MagicMock, mock_open: MagicMock
    ) -> None:
        """Test reading a file with undecodable content (using default UTF-8 strict)."""
        resolvedRepoPath = os.path.abspath(self.localPath)
        filePath = "binary.dat"
        fullPath = os.path.normpath(os.path.join(self.localPath, filePath))
        resolvedFullPath = os.path.abspath(fullPath)
        mock_realpath.side_effect = lambda p: resolvedFullPath if os.path.normpath(p) == fullPath else resolvedRepoPath

        # Make mock file handle raise UnicodeDecodeError when read() is called
        mock_handle = MagicMock()
        mock_handle.read.side_effect = UnicodeDecodeError('utf-8', b'\x80', 0, 1, 'invalid start byte')
        mock_open.return_value.__enter__.return_value = mock_handle

        with self.assertRaisesRegex(GitHubError, "Could not decode file .* using UTF-8"):
            self.handler.readFileContent(self.localPath, filePath)
        mock_open.assert_called_once_with(fullPath, 'r', encoding='utf-8', errors='strict')

    # --- Test isDirty ---

    @patch('git.Repo')
    def test_isDirty_cleanRepo(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test isDirty on a clean repository."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_git_cmd.status.return_value = "" # Empty porcelain status means clean

        is_dirty = self.handler.isDirty(self.localPath)

        self.assertFalse(is_dirty)
        mock_Repo_constructor.assert_called_once_with(self.localPath)
        self.mock_git_cmd.status.assert_called_once_with(porcelain=True)

    @patch('git.Repo')
    def test_isDirty_modifiedFile(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test isDirty with a modified file."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_git_cmd.status.return_value = " M modified_file.py" # Non-empty status

        is_dirty = self.handler.isDirty(self.localPath)

        self.assertTrue(is_dirty)
        self.mock_git_cmd.status.assert_called_once_with(porcelain=True)

    @patch('git.Repo')
    def test_isDirty_untrackedFile(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test isDirty with an untracked file."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_git_cmd.status.return_value = "?? untracked_file.txt" # Non-empty status

        is_dirty = self.handler.isDirty(self.localPath)

        self.assertTrue(is_dirty)
        self.mock_git_cmd.status.assert_called_once_with(porcelain=True)

    @patch('git.Repo')
    def test_isDirty_stagedFile(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test isDirty with a staged file."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_git_cmd.status.return_value = "A  newly_staged_file.py" # Non-empty status

        is_dirty = self.handler.isDirty(self.localPath)

        self.assertTrue(is_dirty)
        self.mock_git_cmd.status.assert_called_once_with(porcelain=True)

    @patch('git.Repo', side_effect=git.InvalidGitRepositoryError)
    def test_isDirty_invalidRepo(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test isDirty on an invalid repository path."""
        with self.assertRaisesRegex(GitHubError, "not a valid Git repository"):
            self.handler.isDirty(self.localPath)

    @patch('git.Repo')
    def test_isDirty_gitCommandError(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock) -> None:
        """Test handling GitCommandError during status check."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_git_cmd.status.side_effect = git.GitCommandError('status', 1, stderr='Some git status error')

        with self.assertRaisesRegex(GitHubError, "Git command 'status' failed"):
            self.handler.isDirty(self.localPath)

    # --- Test updateRepo ---

    @patch.object(GitHubHandler, 'isDirty', return_value=False)
    @patch('git.Repo')
    def test_updateRepo_noChanges_viaIsDirty(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock
    ) -> None:
        """Test updateRepo returns 'No changes' when isDirty returns False."""
        mock_Repo_constructor.return_value = self.mock_repo

        result = self.handler.updateRepo(self.localPath, "Commit msg", push=False)

        self.assertEqual(result, "No changes detected.")
        mock_isDirty.assert_called_once_with(self.localPath)
        # Ensure add/commit were not called
        self.mock_git_cmd.add.assert_not_called()
        self.mock_index.commit.assert_not_called()

    @patch.object(GitHubHandler, 'isDirty', return_value=True) # Simulate changes exist
    @patch('git.Repo')
    def test_updateRepo_commitOnly_success(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock
    ) -> None:
        """Test successful local commit without push."""
        mock_Repo_constructor.return_value = self.mock_repo

        result = self.handler.updateRepo(self.localPath, "Test commit", push=False)

        self.assertEqual(result, "Changes committed locally.")
        mock_isDirty.assert_called_once_with(self.localPath)
        self.mock_git_cmd.add.assert_called_once_with(A=True)
        self.mock_index.commit.assert_called_once_with("Test commit")
        # Ensure push was not called
        self.mock_remote.push.assert_not_called()

    @patch.object(GitHubHandler, '_check_branch_status', return_value=(False, "Branch up-to-date")) # Simulate pre-check success
    @patch.object(GitHubHandler, 'isDirty', return_value=True) # Simulate changes exist
    @patch('git.Repo')
    def test_updateRepo_commitAndPush_success(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock, mock_check_status: MagicMock
    ) -> None:
        """Test successful commit and push using PushInfo flags."""
        mock_Repo_constructor.return_value = self.mock_repo
        # Simulate successful push flags (e.g., FAST_FORWARD or NEW_TAG/HEAD)
        mock_push_info = MagicMock(spec=git.PushInfo, flags=git.PushInfo.NEW_HEAD)
        # Provide attributes needed for summary generation if that logic is complex in updateRepo
        mock_push_info.local_ref = MagicMock(); type(mock_push_info.local_ref).name = PropertyMock(return_value='main')
        mock_push_info.remote_ref_string = 'refs/heads/main'
        mock_push_info.summary = "[new branch]      main -> main" # Simple summary example

        self.mock_remote.push.return_value = [mock_push_info]
        # Create mock progress handler
        mock_progress = MockProgress()

        result = self.handler.updateRepo(self.localPath, "Test push", push=True, remoteName='origin', branchName='main', progress_handler=mock_progress)

        self.assertTrue(result.startswith("Changes committed and pushed"))
        mock_isDirty.assert_called_once_with(self.localPath)
        self.mock_git_cmd.add.assert_called_once_with(A=True)
        self.mock_index.commit.assert_called_once_with("Test push")
        mock_check_status.assert_called_once_with(self.mock_repo, 'origin', 'main') # Verify pre-check call
        self.mock_repo.remote.assert_called_once_with(name='origin')
        self.mock_remote.push.assert_called_once_with(refspec='main:main', progress=mock_progress)


    @patch.object(GitHubHandler, '_check_branch_status', return_value=(False, "Branch up-to-date")) # Simulate pre-check success
    @patch.object(GitHubHandler, 'isDirty', return_value=True)
    @patch('git.Repo')
    def test_updateRepo_push_rejected_viaPushInfoFlag(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock, mock_check_status: MagicMock
    ) -> None:
        """Test handling push rejection via PushInfo.REJECTED flag."""
        mock_Repo_constructor.return_value = self.mock_repo
        # Simulate rejection flag
        mock_push_info = MagicMock(spec=git.PushInfo, flags=git.PushInfo.REJECTED)
        mock_push_info.summary = "! [rejected]        main -> main (non-fast-forward)"
        self.mock_remote.push.return_value = [mock_push_info]

        with self.assertRaisesRegex(GitHubError, "Push operation failed after command execution.*Push rejected.*non-fast-forward"):
            self.handler.updateRepo(self.localPath, "Test push rejected", push=True)
        self.mock_index.commit.assert_called_once() # Ensure commit happened before push failed
        mock_check_status.assert_called_once()
        self.mock_remote.push.assert_called_once()

    @patch.object(GitHubHandler, '_check_branch_status', return_value=(False, "Branch up-to-date")) # Simulate pre-check success
    @patch.object(GitHubHandler, 'isDirty', return_value=True)
    @patch('git.Repo')
    def test_updateRepo_push_error_viaPushInfoFlag(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock, mock_check_status: MagicMock
    ) -> None:
        """Test handling push error via PushInfo.ERROR flag."""
        mock_Repo_constructor.return_value = self.mock_repo
        # Simulate error flag
        mock_push_info = MagicMock(spec=git.PushInfo, flags=git.PushInfo.ERROR)
        mock_push_info.summary = "error: src refspec main does not match any" # Example summary
        self.mock_remote.push.return_value = [mock_push_info]

        with self.assertRaisesRegex(GitHubError, "Push operation failed after command execution.*src refspec main does not match any"):
            self.handler.updateRepo(self.localPath, "Test push error", push=True)
        self.mock_index.commit.assert_called_once()
        mock_check_status.assert_called_once()
        self.mock_remote.push.assert_called_once()

    @patch.object(GitHubHandler, '_check_branch_status', return_value=(False, "Branch up-to-date")) # Simulate pre-check success
    @patch.object(GitHubHandler, 'isDirty', return_value=True)
    @patch('git.Repo')
    def test_updateRepo_push_authError_viaGitCommandError_https(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock, mock_check_status: MagicMock
    ) -> None:
        """Test handling push authentication error via GitCommandError (HTTPS)."""
        mock_Repo_constructor.return_value = self.mock_repo
        # Simulate push raising GitCommandError with auth failure stderr
        self.mock_remote.push.side_effect = git.GitCommandError('push', 128, stderr='remote: Support for password authentication was removed.*')
        # Mock remote URL for error message check
        type(self.mock_remote).url = PropertyMock(return_value=self.repoUrl) # HTTPS URL

        with self.assertRaisesRegex(GitHubError, "Authentication failed during push.*Check credentials/SSH keys."): # Adjusted message check
            self.handler.updateRepo(self.localPath, "Test push auth fail", push=True)
        self.mock_index.commit.assert_called_once() # Ensure commit happened before push failed
        mock_check_status.assert_called_once()
        self.mock_remote.push.assert_called_once()

    @patch.object(GitHubHandler, '_check_branch_status', return_value=(False, "Branch up-to-date")) # Simulate pre-check success
    @patch.object(GitHubHandler, 'isDirty', return_value=True)
    @patch('git.Repo')
    def test_updateRepo_push_authError_viaGitCommandError_ssh(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock, mock_check_status: MagicMock
    ) -> None:
        """Test handling push authentication error via GitCommandError (SSH)."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_remote.push.side_effect = git.GitCommandError('push', 128, stderr='git@github.com: Permission denied (publickey).')
        # Mock remote URL for error message check
        type(self.mock_remote).url = PropertyMock(return_value=self.sshRepoUrl) # SSH URL

        with self.assertRaisesRegex(GitHubError, "Authentication failed during push.*Check credentials/SSH keys."): # Adjusted message check
            self.handler.updateRepo(self.localPath, "Test push auth fail", push=True)
        self.mock_index.commit.assert_called_once()
        mock_check_status.assert_called_once()
        self.mock_remote.push.assert_called_once()

    @patch.object(GitHubHandler, '_check_branch_status', return_value=(False, "Branch up-to-date")) # Simulate pre-check success
    @patch.object(GitHubHandler, 'isDirty', return_value=True)
    @patch('git.Repo')
    def test_updateRepo_push_rejected_viaGitCommandError(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock, mock_check_status: MagicMock
    ) -> None:
        """Test handling push rejection via GitCommandError (stderr check)."""
        mock_Repo_constructor.return_value = self.mock_repo
        self.mock_remote.push.side_effect = git.GitCommandError(
            'push', 1, stderr='error: failed to push some refs to \'...\'\n...'
                               'Updates were rejected because the remote contains work that you do')

        with self.assertRaisesRegex(GitHubError, "Push rejected.*Remote branch .* has changes not present locally"):
            self.handler.updateRepo(self.localPath, "Test push rejected", push=True)
        self.mock_index.commit.assert_called_once()
        mock_check_status.assert_called_once()
        self.mock_remote.push.assert_called_once()

    @patch.object(GitHubHandler, 'isDirty', return_value=True)
    @patch('git.Repo')
    def test_updateRepo_remoteNotFound(self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock) -> None:
        """Test handling push failure when the specified remote doesn't exist."""
        mock_Repo_constructor.return_value = self.mock_repo
        # Simulate repo.remote('name') raising ValueError BEFORE _check_branch_status is called
        self.mock_repo.remote.side_effect = ValueError("Remote 'bad_remote' not found")

        # Mock _check_branch_status; it shouldn't be reached if remote lookup fails first in updateRepo
        with patch.object(self.handler, '_check_branch_status') as mock_check_status:
            with self.assertRaisesRegex(GitHubError, "Remote 'bad_remote' does not exist"):
                self.handler.updateRepo(self.localPath, "Test push bad remote", push=True, remoteName='bad_remote')

            # Ensure commit still happened before remote lookup failure
            self.mock_index.commit.assert_called_once()
            # Ensure remote lookup was attempted
            self.mock_repo.remote.assert_any_call(name='bad_remote')
            # Ensure pre-check and push were not attempted
            mock_check_status.assert_not_called()
            self.mock_remote.push.assert_not_called()


    @patch.object(GitHubHandler, '_check_branch_status', return_value=(True, "Local branch 'main' is behind remote. Please pull changes before pushing.")) # Simulate pre-check failure (behind)
    @patch.object(GitHubHandler, 'isDirty', return_value=True)
    @patch('git.Repo')
    def test_updateRepo_push_aborted_due_to_behind(
        self: 'TestGitHubHandler', mock_Repo_constructor: MagicMock, mock_isDirty: MagicMock, mock_check_status: MagicMock
    ) -> None:
        """Test that push is aborted and commit is reset if pre-check shows branch is behind."""
        mock_Repo_constructor.return_value = self.mock_repo
        # Mock repo.index.reset to verify it's called
        mock_reset = MagicMock()
        self.mock_index.reset = mock_reset # Attach mock reset method to mock index

        with self.assertRaisesRegex(GitHubError, "Push aborted.*Local branch 'main' is behind remote.*Local commit has been reset"):
            self.handler.updateRepo(self.localPath, "Test push behind", push=True)

        mock_isDirty.assert_called_once()
        self.mock_git_cmd.add.assert_called_once()
        self.mock_index.commit.assert_called_once() # Commit happened
        mock_check_status.assert_called_once()      # Pre-check happened
        self.mock_remote.push.assert_not_called()  # Push did NOT happen
        # Verify commit reset was called
        mock_reset.assert_called_once_with(head=True) # Check reset call args (reset --hard HEAD) - Needs verification based on actual code



if __name__ == '__main__':
    unittest.main()
# --- END: tests/test_github_handler.py ---

## tests/test_integration.py ##

# --- START: tests/test_integration.py ---
import unittest
import os
import shutil
import tempfile
import json
import git # Import git for Repo object simulation and exceptions
from unittest.mock import patch, MagicMock, PropertyMock, call
from typing import List, Dict, Optional, Any

# Ensure imports work correctly assuming tests are run from the project root
# Adjust path if necessary based on your test runner setup
import sys
if '.' not in sys.path:
    sys.path.append('.') # Add project root if needed

# Import core components
# Mock ConfigManager before other imports that might use it implicitly
mock_config_manager_instance_integration = MagicMock()
mock_config_manager_class_integration = MagicMock(return_value=mock_config_manager_instance_integration)
sys.modules['core.config_manager'] = MagicMock(ConfigManager=mock_config_manager_class_integration)

# --- Mock LLM Interface dependencies BEFORE importing LLMInterface ---
# Mock google.generativeai used by llm_interface
mock_genai_integration = MagicMock()
sys.modules['google.generativeai'] = mock_genai_integration
sys.modules['google.generativeai.types'] = MagicMock()
# Mock google.api_core exceptions used by llm_interface
mock_api_exceptions_integration = MagicMock()
sys.modules['google.api_core'] = MagicMock(exceptions=mock_api_exceptions_integration)
# It's important these mocks are in place *before* llm_interface is imported below

from core.github_handler import GitHubHandler
from core.llm_interface import LLMInterface
from core.file_processor import FileProcessor
from core.exceptions import GitHubError, LLMError, ParsingError, FileProcessingError, ConfigurationError
# from core.config_manager import ConfigManager # No need to import mocked version directly


# Note: Integration tests involving GUI elements (PySide6) often require
# specific test runners or frameworks like pytest-qt to handle the event loop
# and widget interactions. This example focuses on integrating the core logic flow.

# We can simulate the workflow without needing the actual GUI/Threads.
class TestCoreIntegration(unittest.TestCase):
    """
    Integration tests for the core logic workflow (excluding direct GUI interaction).
    Mocks external dependencies like Git remote operations and LLM API calls.
    Uses a temporary directory for local file operations and a simulated Git repo.
    """

    # Constants for test files and content
    _INITIAL_FILE_REL_PATH: str = "module/main.py"
    _INITIAL_FILE_CONTENT: str = "print('Hello from initial file!')"
    _UPDATED_FILE_CONTENT: str = "print('Hello from LLM updated file!')\n# New line added"
    _NEW_FILE_REL_PATH: str = "data/new_data.txt"
    _NEW_FILE_CONTENT: str = "This is a new file generated by the LLM."
    _MOCK_URL: str = "https://example.com/user/repo.git" # Corrected URL format
    _DUMMY_API_KEY: str = "dummy_api_key_123" # Used for mocking config only
    _MOCK_MODEL_NAME: str = "mock-gemini-model"
    _COMMIT_MSG: str = "Apply LLM updates"
    _REMOTE_NAME: str = "origin"
    _BRANCH_NAME: str = "main"

    def setUp(self: 'TestCoreIntegration') -> None:
        """
        Sets up a temporary directory, initialises a real Git repository within it,
        creates an initial file, and initialises core component instances with mocks.
        """
        # Create temporary directory for the test run
        self.test_dir = tempfile.mkdtemp()
        self.local_repo_path = os.path.join(self.test_dir, "repo")

        # Initialise a *real* git repo in the temp dir for realistic local operations
        self.repo = git.Repo.init(self.local_repo_path)

        # Create and commit an initial file
        self.initial_file_abs_path = os.path.join(self.local_repo_path, self._INITIAL_FILE_REL_PATH)
        os.makedirs(os.path.dirname(self.initial_file_abs_path), exist_ok=True)
        with open(self.initial_file_abs_path, 'w', encoding='utf-8') as f:
            f.write(self._INITIAL_FILE_CONTENT)
        self.repo.index.add([self._INITIAL_FILE_REL_PATH])
        self.repo.index.commit("Initial commit")

        # Add a dummy remote for push tests (won't actually connect)
        self.repo.create_remote(self._REMOTE_NAME, url="https://example.com/dummy/push/target.git") # Corrected URL format

        # Configure the mocked ConfigManager instance centrally
        self.config_manager = mock_config_manager_instance_integration
        self.config_manager.reset_mock() # Ensure clean state for each test
        self.config_manager.getEnvVar.side_effect = self._mock_get_env_var
        self.config_manager.getConfigValue.side_effect = self._mock_get_config_value
        self.config_manager.getConfigValueInt.side_effect = self._mock_get_config_value_int
        self.config_manager.getConfigValueFloat.side_effect = self._mock_get_config_value_float

        # Initialise core components, passing the mocked ConfigManager
        self.github_handler = GitHubHandler()
        # LLMInterface instantiation relies on the sys.modules mocks for google.generativeai being active
        self.llm_interface = LLMInterface(configManager=self.config_manager)
        self.file_processor = FileProcessor()

        # Patch loggers for all core modules used to suppress output during tests
        self.patchers = {
            'gh': patch('core.github_handler.logger', MagicMock()),
            'llm': patch('core.llm_interface.logger', MagicMock()),
            'fp': patch('core.file_processor.logger', MagicMock()),
            # 'cm': patch('core.config_manager.logger', MagicMock()), # Mocked via sys.modules approach
            # '__main__': patch('__main__.logger', MagicMock(), create=True) # Avoid if __main__ not relevant
        }
        # Start required patchers
        self.mock_loggers = {name: patcher.start() for name, patcher in self.patchers.items()}


    def tearDown(self: 'TestCoreIntegration') -> None:
        """Cleans up the temporary directory and stops patching."""
        # Stop all patchers
        for patcher in self.patchers.values():
            patcher.stop()
        # Remove the temporary directory
        shutil.rmtree(self.test_dir)

    # --- Mock ConfigManager Helpers ---
    def _mock_get_env_var(self, key: str, defaultValue: Optional[str] = None, required: bool = False) -> Optional[str]:
        """Simulates retrieving environment variables."""
        if key == 'GEMINI_API_KEY':
            return self._DUMMY_API_KEY
        if required and defaultValue is None:
            # Simulate raising error if a required env var used in tests is missing
            raise ConfigurationError(f"Mock missing required env var: {key}")
        return defaultValue

    def _mock_get_config_value(self, section: str, key: str, fallback: Optional[str] = None, required: bool = False) -> Optional[str]:
        """Simulates retrieving string config values."""
        config_map = {
            'General': {
                'DefaultLlmModel': self._MOCK_MODEL_NAME,
                'ExpectedOutputFormat': 'json',
                'DefaultCloneDir': os.path.join(self.test_dir, 'cloned_repos') # Use temp dir
            },
            'GitHub': {
                'DefaultRemoteName': self._REMOTE_NAME,
                'DefaultBranchName': self._BRANCH_NAME,
                'DefaultCommitMessage': 'LLM Auto-Update via Colonol Code'
            },
            'Logging': { # Provide some defaults for logging setup if tested implicitly
                'FileLogLevel': 'INFO',
                'LogDirectory': os.path.join(self.test_dir, 'logs'),
                'LogFileName': 'test_app_log.log',
                'GuiLogLevel': 'INFO'
            },
            'LLM': {} # Add LLM section for safety settings if needed
        }
        # Add safety settings defaults (e.g., None)
        safety_keys = [
            'HarmCategoryHarassmentThreshold', 'HarmCategoryHateSpeechThreshold',
            'HarmCategorySexuallyExplicitThreshold', 'HarmCategoryDangerousContentThreshold'
        ]
        for skey in safety_keys:
             if (section, key) == ('LLM', skey):
                  return None # Simulate safety keys not being set

        value = config_map.get(section, {}).get(key)
        if value is not None:
            return value
        if required and fallback is None:
            raise ConfigurationError(f"Mock missing required config: [{section}] {key}")
        return fallback

    def _mock_get_config_value_int(self, section: str, key: str, fallback: Optional[int] = None, required: bool = False) -> Optional[int]:
        """Simulates retrieving integer config values."""
        config_map_int = {
            'LLM': {
                'MaxOutputTokens': 8192,
                'MaxCharsPerFileInPrompt': 10000, # Default large value for most tests
                'MaxTokensPerFileInPrompt': 0 # Default disabled for most tests
            }
        }
        # Return directly from map if present
        value = config_map_int.get(section, {}).get(key)
        if value is not None:
            return value # Assume value is already int for simplicity here

        if required and fallback is None:
            raise ConfigurationError(f"Mock missing required int config: [{section}] {key}")
        return fallback # Return the provided fallback type (int or None)

    def _mock_get_config_value_float(self, section: str, key: str, fallback: Optional[float] = None, required: bool = False) -> Optional[float]:
        """Simulates retrieving float config values."""
        config_map_float = {
            'LLM': {
                'Temperature': 0.7
            }
        }
         # Return directly from map if present
        value = config_map_float.get(section, {}).get(key)
        if value is not None:
             return value # Assume value is already float

        if required and fallback is None:
            raise ConfigurationError(f"Mock missing required float config: [{section}] {key}")
        return fallback


    # --- Integration Test Cases ---

    @patch('core.github_handler.GitHubHandler.cloneRepository') # Still mock initial clone/load for simplicity
    @patch('core.llm_interface.LLMInterface.queryLlmApi')      # Mock LLM call
    @patch('core.github_handler.GitHubHandler.updateRepo')     # Mock commit/push action
    def test_full_workflow_success_update_and_new_file(
        self: 'TestCoreIntegration',
        mock_updateRepo: MagicMock,
        mock_queryLlmApi: MagicMock,
        mock_cloneRepository: MagicMock
    ) -> None:
        """
        Tests the complete workflow: load -> list -> read -> prompt -> query LLM -> parse -> save -> commit/push.
        Simulates an LLM response that updates one file and creates a new one.
        Uses the real local Git repo for local file operations (list, read, save, isDirty).
        """
        # --- Arrange: Setup Mocks and Expected Data ---
        # 1. Mock cloneRepository to return the real repo object created in setUp
        mock_cloneRepository.return_value = self.repo

        # 2. Define mock LLM response (updates one file, creates another)
        mock_llm_response_json = {
            self._INITIAL_FILE_REL_PATH: self._UPDATED_FILE_CONTENT,
            self._NEW_FILE_REL_PATH: self._NEW_FILE_CONTENT
        }
        mock_llm_response_text = f"```json\n{json.dumps(mock_llm_response_json, indent=2)}\n```"
        mock_queryLlmApi.return_value = mock_llm_response_text

        # 3. Mock updateRepo (commit/push) response
        mock_updateRepo.return_value = "Changes committed and pushed successfully."

        # --- Act: Simulate Workflow Steps ---
        # 1. Load/Clone Repo (Initial call is mocked)
        repo_loaded = self.github_handler.cloneRepository(self._MOCK_URL, self.local_repo_path)
        mock_cloneRepository.assert_called_once_with(self._MOCK_URL, self.local_repo_path, None, progress_handler=None) # Assuming no progress handler passed here
        self.assertEqual(repo_loaded.working_dir, self.local_repo_path, "Loaded repo path mismatch")

        # 2. List files (Uses real Git repo)
        files = self.github_handler.listFiles(self.local_repo_path)
        self.assertIn(self._INITIAL_FILE_REL_PATH, files, "Initial file not listed")
        selected_files = [self._INITIAL_FILE_REL_PATH] # Simulate selecting the initial file

        # 3. Read file content (Uses real Git repo - NO MOCK NEEDED)
        file_contents: Dict[str, str] = {}
        for f_path in selected_files:
            content = self.github_handler.readFileContent(self.local_repo_path, f_path)
            file_contents[f_path] = content
        self.assertEqual(file_contents[self._INITIAL_FILE_REL_PATH], self._INITIAL_FILE_CONTENT, "Initial file content mismatch")

        # 4. Build Prompt (Uses real implementation with mocked config)
        instruction = "Update the print statement, add a comment, and create a new data file."
        prompt = self.llm_interface.buildPrompt(instruction, file_contents)
        self.assertIn(instruction, prompt, "Instruction missing in prompt")
        self.assertIn(self._INITIAL_FILE_CONTENT, prompt, "File content missing in prompt")
        self.assertIn("```json", prompt, "JSON output format specifier missing in prompt")

        # 5. Query LLM (Mocked)
        # FIX: Call queryLlmApi without apiKey argument
        llm_response = self.llm_interface.queryLlmApi(prompt, self._MOCK_MODEL_NAME)
        mock_queryLlmApi.assert_called_once_with(prompt, self._MOCK_MODEL_NAME) # Check args
        self.assertEqual(llm_response, mock_llm_response_text, "LLM response mismatch")

        # 6. Extract Code Block (Uses real implementation)
        code_block = self.file_processor.extractCodeBlock(llm_response, language='json') # Use mocked config format
        self.assertIsNotNone(code_block, "Code block extraction failed")

        # 7. Parse Structured Output (Uses real implementation)
        parsed_data = self.file_processor.parseStructuredOutput(code_block, format='json') # Use mocked config format
        self.assertEqual(parsed_data, mock_llm_response_json, "Parsed data mismatch")

        # 8. Save Files to Disk (Uses real Git repo in temp dir - NO MOCK NEEDED)
        saved_files = self.file_processor.saveFilesToDisk(self.local_repo_path, parsed_data)
        self.assertCountEqual(saved_files, list(mock_llm_response_json.keys()), "Saved files list mismatch") # Use assertCountEqual for lists

        # --- Assert: Verification after saving (before commit/push) ---
        # Check content of updated file
        updated_file_abs_path = os.path.join(self.local_repo_path, self._INITIAL_FILE_REL_PATH)
        self.assertTrue(os.path.exists(updated_file_abs_path), "Updated file does not exist")
        with open(updated_file_abs_path, 'r', encoding='utf-8') as f:
            self.assertEqual(f.read(), self._UPDATED_FILE_CONTENT, "Updated file content incorrect")

        # Check content of new file
        new_file_abs_path = os.path.join(self.local_repo_path, self._NEW_FILE_REL_PATH)
        self.assertTrue(os.path.exists(new_file_abs_path), "New file does not exist")
        with open(new_file_abs_path, 'r', encoding='utf-8') as f:
            self.assertEqual(f.read(), self._NEW_FILE_CONTENT, "New file content incorrect")

        # 9. Check Dirty Status (Uses real Git repo - NO MOCK NEEDED)
        is_dirty = self.github_handler.isDirty(self.local_repo_path)
        self.assertTrue(is_dirty, "Repository should be dirty after saving changes.")

        # 10. Commit & Push (Mocked)
        update_result = self.github_handler.updateRepo(
            self.local_repo_path, self._COMMIT_MSG, push=True, remoteName=self._REMOTE_NAME, branchName=self._BRANCH_NAME
        )

        # --- Assert: Final Verification ---
        mock_updateRepo.assert_called_once_with(
            self.local_repo_path, self._COMMIT_MSG, push=True, remoteName=self._REMOTE_NAME, branchName=self._BRANCH_NAME, progress_handler=None
        )
        self.assertEqual(update_result, "Changes committed and pushed successfully.", "Final update result mismatch")


    @patch('core.github_handler.GitHubHandler.cloneRepository')
    @patch('core.llm_interface.LLMInterface.queryLlmApi') # Mock LLM call
    @patch('core.github_handler.GitHubHandler.updateRepo') # Mock commit/push action
    def test_workflow_llm_returns_no_changes(
        self: 'TestCoreIntegration',
        mock_updateRepo: MagicMock,
        mock_queryLlmApi: MagicMock,
        mock_cloneRepository: MagicMock
    ) -> None:
        """
        Tests workflow where LLM response indicates no files need changes (empty JSON object).
        Ensures no files are saved and commit/push doesn't happen due to no changes.
        """
        # --- Arrange ---
        mock_cloneRepository.return_value = self.repo
        mock_llm_response_text = "```json\n{}\n```" # Empty JSON object
        mock_queryLlmApi.return_value = mock_llm_response_text

        # --- Act ---
        repo_loaded = self.github_handler.cloneRepository(self._MOCK_URL, self.local_repo_path)
        selected_files = [self._INITIAL_FILE_REL_PATH]
        file_contents = {f: self.github_handler.readFileContent(self.local_repo_path, f) for f in selected_files}
        instruction = "Review this code but make no changes."
        prompt = self.llm_interface.buildPrompt(instruction, file_contents)
        # FIX: Call queryLlmApi without apiKey argument
        llm_response = self.llm_interface.queryLlmApi(prompt, self._MOCK_MODEL_NAME)
        code_block = self.file_processor.extractCodeBlock(llm_response, language='json')
        parsed_data = self.file_processor.parseStructuredOutput(code_block, format='json')

        # --- Assert ---
        self.assertEqual(parsed_data, {}, "Parsed data should be an empty dictionary")

        # Attempt to save (should do nothing gracefully if data is empty)
        saved_files = self.file_processor.saveFilesToDisk(self.local_repo_path, parsed_data)
        self.assertEqual(saved_files, [], "No files should have been saved")

        # Verify file content remains unchanged
        with open(self.initial_file_abs_path, 'r', encoding='utf-8') as f:
            self.assertEqual(f.read(), self._INITIAL_FILE_CONTENT, "Initial file content should be unchanged")

        # Verify repo is not dirty
        self.assertFalse(self.github_handler.isDirty(self.local_repo_path), "Repository should be clean as no changes were saved.")

        # Verify updateRepo is called but returns "No changes detected." because repo isn't dirty
        with patch.object(self.github_handler, 'isDirty', return_value=False) as mock_isDirty_in_update:
            update_result = self.github_handler.updateRepo(self.local_repo_path, self._COMMIT_MSG, push=True)
            self.assertEqual(update_result, "No changes detected.", "updateRepo should report no changes")
            mock_isDirty_in_update.assert_called_once_with(self.local_repo_path)

        # Ensure the main updateRepo mock (for push) was NOT called
        mock_updateRepo.assert_not_called()


    @patch('core.github_handler.GitHubHandler.cloneRepository')
    @patch('core.llm_interface.LLMInterface.queryLlmApi')
    def test_workflow_llm_error_handling(
        self: 'TestCoreIntegration',
        mock_queryLlmApi: MagicMock,
        mock_cloneRepository: MagicMock
    ) -> None:
        """Tests workflow stops correctly if the LLM query fails with an LLMError."""
        # --- Arrange ---
        mock_cloneRepository.return_value = self.repo
        llm_error_message = "API rate limit exceeded"
        mock_queryLlmApi.side_effect = LLMError(llm_error_message)

        # --- Act ---
        repo_loaded = self.github_handler.cloneRepository(self._MOCK_URL, self.local_repo_path)
        selected_files = [self._INITIAL_FILE_REL_PATH]
        file_contents = {f: self.github_handler.readFileContent(self.local_repo_path, f) for f in selected_files}
        instruction = "Do something that will cause an LLM error."
        prompt = self.llm_interface.buildPrompt(instruction, file_contents)

        # --- Assert ---
        # Expect LLMError to be raised when querying
        with self.assertRaisesRegex(LLMError, llm_error_message):
            # FIX: Call queryLlmApi without apiKey argument
            self.llm_interface.queryLlmApi(prompt, self._MOCK_MODEL_NAME)

        # Verify file content remains unchanged
        with open(self.initial_file_abs_path, 'r', encoding='utf-8') as f:
            self.assertEqual(f.read(), self._INITIAL_FILE_CONTENT, "File content should be unchanged after LLM error")

        # Verify repo is not dirty
        self.assertFalse(self.github_handler.isDirty(self.local_repo_path), "Repo should be clean after LLM error")


    @patch('core.github_handler.GitHubHandler.cloneRepository')
    @patch('core.llm_interface.LLMInterface.queryLlmApi')
    def test_workflow_parsing_error_invalid_json(
        self: 'TestCoreIntegration',
        mock_queryLlmApi: MagicMock,
        mock_cloneRepository: MagicMock
    ) -> None:
        """Tests workflow stops correctly if LLM response contains invalid JSON."""
        # --- Arrange ---
        mock_cloneRepository.return_value = self.repo
        mock_llm_response_text = "```json\n{\n  \"file.py\": \"print('hello')\",\n  \"invalid\": \n}\n```" # Invalid JSON
        mock_queryLlmApi.return_value = mock_llm_response_text

        # --- Act ---
        repo_loaded = self.github_handler.cloneRepository(self._MOCK_URL, self.local_repo_path)
        selected_files = [self._INITIAL_FILE_REL_PATH]
        file_contents = {f: self.github_handler.readFileContent(self.local_repo_path, f) for f in selected_files}
        instruction = "Generate invalid JSON."
        prompt = self.llm_interface.buildPrompt(instruction, file_contents)
        # FIX: Call queryLlmApi without apiKey argument
        llm_response = self.llm_interface.queryLlmApi(prompt, self._MOCK_MODEL_NAME)
        code_block = self.file_processor.extractCodeBlock(llm_response, language='json')

        # --- Assert ---
        self.assertIsNotNone(code_block)
        # Expect ParsingError (wrapping JSONDecodeError) when parsing
        with self.assertRaisesRegex(ParsingError, "Invalid JSON detected"):
            self.file_processor.parseStructuredOutput(code_block, format='json')

        # Verify file content remains unchanged
        with open(self.initial_file_abs_path, 'r', encoding='utf-8') as f:
            self.assertEqual(f.read(), self._INITIAL_FILE_CONTENT, "File content should be unchanged after parsing error")

        # Verify repo is not dirty
        self.assertFalse(self.github_handler.isDirty(self.local_repo_path), "Repo should be clean after parsing error")


    @patch('core.github_handler.GitHubHandler.cloneRepository')
    @patch('core.llm_interface.LLMInterface.queryLlmApi')
    def test_workflow_parsing_error_unsafe_path(
        self: 'TestCoreIntegration',
        mock_queryLlmApi: MagicMock,
        mock_cloneRepository: MagicMock
    ) -> None:
        """Tests workflow stops correctly if LLM response contains an unsafe file path."""
        # --- Arrange ---
        mock_cloneRepository.return_value = self.repo
        mock_llm_response_json = {
            "../unsafe_file.txt": "malicious content",
            self._INITIAL_FILE_REL_PATH: self._UPDATED_FILE_CONTENT
        }
        mock_llm_response_text = f"```json\n{json.dumps(mock_llm_response_json, indent=2)}\n```"
        mock_queryLlmApi.return_value = mock_llm_response_text

        # --- Act ---
        repo_loaded = self.github_handler.cloneRepository(self._MOCK_URL, self.local_repo_path)
        # FIX: Call queryLlmApi without apiKey argument
        llm_response = self.llm_interface.queryLlmApi("prompt", self._MOCK_MODEL_NAME)
        code_block = self.file_processor.extractCodeBlock(llm_response, language='json')

        # --- Assert ---
        self.assertIsNotNone(code_block)
        # Expect ParsingError due to unsafe path key
        with self.assertRaisesRegex(ParsingError, "key '../unsafe_file.txt' is not a safe relative path"):
            self.file_processor.parseStructuredOutput(code_block, format='json')

        # Verify file content remains unchanged
        with open(self.initial_file_abs_path, 'r', encoding='utf-8') as f:
            self.assertEqual(f.read(), self._INITIAL_FILE_CONTENT, "File content should be unchanged after unsafe path error")

        # Verify repo is not dirty
        self.assertFalse(self.github_handler.isDirty(self.local_repo_path), "Repo should be clean after unsafe path error")

    @patch('core.github_handler.GitHubHandler.cloneRepository')
    # No LLM mock needed for this test
    def test_workflow_file_read_error(
        self: 'TestCoreIntegration',
        mock_cloneRepository: MagicMock
    ) -> None:
        """Tests workflow handling when reading a selected file fails (e.g., file deleted)."""
        # --- Arrange ---
        mock_cloneRepository.return_value = self.repo
        repo_loaded = self.github_handler.cloneRepository(self._MOCK_URL, self.local_repo_path)
        selected_files = ["non_existent_file.txt"] # Simulate selecting a file that doesn't exist

        # --- Act & Assert ---
        # Expect GitHubError when attempting to read the non-existent file
        with self.assertRaisesRegex(GitHubError, "File not found at calculated path"):
            # This loop simulates what the FileWorker or main logic might do
            for f_path in selected_files:
                self.github_handler.readFileContent(self.local_repo_path, f_path)

        # Verify repo is not dirty (as no changes were made)
        self.assertFalse(self.github_handler.isDirty(self.local_repo_path), "Repo should be clean after file read error")


    @patch('core.github_handler.GitHubHandler.cloneRepository')
    @patch('core.llm_interface.LLMInterface.queryLlmApi')
    @patch('core.file_processor.FileProcessor.saveFilesToDisk') # Mock saving specifically
    def test_workflow_file_save_error(
        self: 'TestCoreIntegration',
        mock_saveFilesToDisk: MagicMock,
        mock_queryLlmApi: MagicMock,
        mock_cloneRepository: MagicMock
    ) -> None:
        """Tests workflow handling when saving files fails (e.g., permissions)."""
        # --- Arrange ---
        mock_cloneRepository.return_value = self.repo
        mock_llm_response_json = { self._INITIAL_FILE_REL_PATH: self._UPDATED_FILE_CONTENT }
        mock_llm_response_text = f"```json\n{json.dumps(mock_llm_response_json)}\n```"
        mock_queryLlmApi.return_value = mock_llm_response_text
        # Simulate saveFilesToDisk raising an error
        save_error_message = "Permission denied writing file"
        mock_saveFilesToDisk.side_effect = FileProcessingError(save_error_message)

        # --- Act ---
        repo_loaded = self.github_handler.cloneRepository(self._MOCK_URL, self.local_repo_path)
        # FIX: Call queryLlmApi without apiKey argument
        llm_response = self.llm_interface.queryLlmApi("prompt", self._MOCK_MODEL_NAME)
        code_block = self.file_processor.extractCodeBlock(llm_response, language='json')
        parsed_data = self.file_processor.parseStructuredOutput(code_block, format='json')

        # --- Assert ---
        # Expect FileProcessingError when attempting to save
        with self.assertRaisesRegex(FileProcessingError, save_error_message):
            self.file_processor.saveFilesToDisk(self.local_repo_path, parsed_data)

        # Verify saveFilesToDisk was called
        mock_saveFilesToDisk.assert_called_once_with(self.local_repo_path, parsed_data)

        # Verify file content remains unchanged (assuming error prevents partial writes)
        with open(self.initial_file_abs_path, 'r', encoding='utf-8') as f:
            self.assertEqual(f.read(), self._INITIAL_FILE_CONTENT, "File content should be unchanged after save error")

        # Verify repo is not dirty (assuming error prevents changes)
        self.assertFalse(self.github_handler.isDirty(self.local_repo_path), "Repo state uncertain after save error, ideally should be checked.")


    @patch('core.github_handler.GitHubHandler.cloneRepository')
    @patch('core.llm_interface.LLMInterface.queryLlmApi')
    @patch('core.github_handler.GitHubHandler.updateRepo') # Mock commit/push
    def test_workflow_commit_push_error_rejected(
        self: 'TestCoreIntegration',
        mock_updateRepo: MagicMock,
        mock_queryLlmApi: MagicMock,
        mock_cloneRepository: MagicMock
    ) -> None:
        """Tests workflow handling when commit/push fails (e.g., rejected due to remote changes)."""
        # --- Arrange ---
        mock_cloneRepository.return_value = self.repo
        mock_llm_response_json = { self._INITIAL_FILE_REL_PATH: self._UPDATED_FILE_CONTENT }
        mock_llm_response_text = f"```json\n{json.dumps(mock_llm_response_json)}\n```"
        mock_queryLlmApi.return_value = mock_llm_response_text
        # Simulate updateRepo raising a GitHubError for rejection
        push_error_message = "Push rejected. Remote branch .* has changes not present locally"
        mock_updateRepo.side_effect = GitHubError(push_error_message)

        # --- Act ---
        repo_loaded = self.github_handler.cloneRepository(self._MOCK_URL, self.local_repo_path)
        # FIX: Call queryLlmApi without apiKey argument
        llm_response = self.llm_interface.queryLlmApi("prompt", self._MOCK_MODEL_NAME)
        code_block = self.file_processor.extractCodeBlock(llm_response, language='json')
        parsed_data = self.file_processor.parseStructuredOutput(code_block, format='json')
        self.file_processor.saveFilesToDisk(self.local_repo_path, parsed_data) # Real save

        # Verify repo is dirty before attempting push
        self.assertTrue(self.github_handler.isDirty(self.local_repo_path), "Repo should be dirty before push attempt")

        # --- Assert ---
        # Expect GitHubError when attempting to push
        with self.assertRaisesRegex(GitHubError, push_error_message):
            self.github_handler.updateRepo(
                self.local_repo_path, self._COMMIT_MSG, push=True, remoteName=self._REMOTE_NAME, branchName=self._BRANCH_NAME
            )

        # Verify updateRepo was called
        mock_updateRepo.assert_called_once_with(
            self.local_repo_path, self._COMMIT_MSG, push=True, remoteName=self._REMOTE_NAME, branchName=self._BRANCH_NAME, progress_handler=None
        )

        # Verify repo remains dirty locally after failed push
        self.assertTrue(self.github_handler.isDirty(self.local_repo_path), "Repo should remain dirty after failed push")
        # Verify commit was made locally (check HEAD)
        self.assertEqual(self.repo.head.commit.message.strip(), self._COMMIT_MSG.strip(), "Local commit message mismatch after failed push")


if __name__ == '__main__':
    unittest.main()

# --- END: tests/test_integration.py ---

## tests/__init__.py ##



## utils/logger_setup.py ##

# --- START: utils/logger_setup.py ---
# utils/logger_setup.py
"""
Provides a centralised function for configuring the application's logging system.
Sets up handlers (console, file) and formatters.
"""

import logging
import sys
import os
from logging.handlers import RotatingFileHandler
from typing import List, Optional # Import List, Optional

# Define standard formats - can be customised via config or arguments
DEFAULT_LOG_FORMAT: str = '%(asctime)s - %(name)s - %(levelname)s - %(module)s:%(lineno)d - %(message)s'
DEFAULT_DATE_FORMAT: str = '%Y-%m-%d %H:%M:%S'


def setupLogging(
	logLevel: int = logging.INFO,
	logToConsole: bool = True,
	logToFile: bool = True, # Defaulting to True, often useful
	logFileName: str = 'app.log',
	logFileLevel: int = logging.INFO,
	logDir: str = 'logs', # Default log directory
	maxBytes: int = 10*1024*1024, # 10 MB
	backupCount: int = 5,
	logFormat: str = DEFAULT_LOG_FORMAT,
	dateFormat: str = DEFAULT_DATE_FORMAT
) -> logging.Logger:
	"""
	Configures the root logger for the application.

	Sets up console and/or file logging handlers with specified levels and formats.
	Removes existing handlers before adding new ones to prevent duplication.

	Args:
		logLevel (int): The minimum logging level for the root logger (default: INFO).
		logToConsole (bool): Whether to add a handler to log messages to the console (stderr).
		logToFile (bool): Whether to add a handler to log messages to a rotating file.
		logFileName (str): The name of the log file (used if logToFile is True).
		logFileLevel (int): The minimum logging level for the file handler.
		logDir (str): The directory where the log file should be stored.
		maxBytes (int): The maximum size in bytes before the log file rotates.
		backupCount (int): The number of backup log files to keep.
		logFormat (str): The logging format string.
		dateFormat (str): The date format string for the formatter.

	Returns:
		logging.Logger: The configured root logger instance.
	"""
	# Declare list locally
	logHandlers: List[logging.Handler] = []

	formatter: logging.Formatter = logging.Formatter(logFormat, datefmt=dateFormat)

	# Configure Console Handler
	if logToConsole:
		consoleHandler: logging.StreamHandler = logging.StreamHandler(sys.stderr)
		consoleHandler.setFormatter(formatter)
		# Console handler typically uses the root logger's level,
		# but can be set explicitly if needed: consoleHandler.setLevel(logLevel)
		logHandlers.append(consoleHandler)

	# Configure File Handler
	if logToFile:
		try:
			# Ensure log directory exists
			# Use os.path.abspath to handle relative paths robustly
			absLogDir = os.path.abspath(logDir)
			if not os.path.exists(absLogDir):
				os.makedirs(absLogDir, exist_ok=True)

			logFilePath: str = os.path.join(absLogDir, logFileName)

			# Use RotatingFileHandler for better log management
			fileHandler: RotatingFileHandler = RotatingFileHandler(
				logFilePath,
				maxBytes=maxBytes,
				backupCount=backupCount,
				encoding='utf-8'
			)
			fileHandler.setFormatter(formatter)
			fileHandler.setLevel(logFileLevel)
			logHandlers.append(fileHandler)
		except (OSError, IOError) as e:
			# If file logging setup fails, log an error to console (if available)
			# or just print, and continue without file logging.
			print(f"ERROR: Failed to configure file logging to '{os.path.join(logDir, logFileName)}': {e}", file=sys.stderr)
			# Log using root logger if console handler was added
			if logToConsole:
				logging.getLogger().error(f"Failed to configure file logging: {e}", exc_info=False)


	# Get the root logger and configure it
	rootLogger: logging.Logger = logging.getLogger()
	rootLogger.setLevel(logLevel)

	# Clear existing handlers before adding new ones (important if re-configuring)
	if rootLogger.hasHandlers():
		# Explicitly copy list before iterating for removal
		existingHandlers: List[logging.Handler] = rootLogger.handlers[:]
		for handler in existingHandlers:
			rootLogger.removeHandler(handler)

	# Add the newly configured handlers
	for handler in logHandlers:
		rootLogger.addHandler(handler)

	if logHandlers: # Only log if handlers were successfully added
		rootLogger.info(f"Logging initialised (Root Level: {logging.getLevelName(rootLogger.level)}). Console: {logToConsole}, File: {logToFile} (Level: {logging.getLevelName(logFileLevel)} in '{os.path.join(logDir, logFileName)}').")
	else:
		print("WARNING: Logging initialisation completed but no handlers were configured.", file=sys.stderr)

	return rootLogger

# --- END: utils/logger_setup.py ---

## utils/__init__.py ##



## resources/__init__.py ##



## gui/threads.py ##

"""
Threading module for background task execution in the GUI application.
Provides worker classes for handling long-running operations without freezing the UI.

Features:
- Base worker thread with common signal handling
- GitHub operations worker for repository interactions
- LLM worker for AI model interactions
- File processing worker with validation capabilities

Each worker emits signals to update the GUI about progress and completion status.
"""

# Standard library imports
import logging
import time
import os
import io
import json
from typing import Optional, List, Dict, Any, Tuple

# Qt imports
from PySide6.QtCore import QThread, Signal, Slot

# Initialize logging
logger: logging.Logger = logging.getLogger(__name__)

# Third-party validation imports (with fallback handling)
try:
    import pyflakes.api
    import pyflakes.reporter
    PYFLAKES_AVAILABLE = True
except ImportError:
    PYFLAKES_AVAILABLE = False
    logger.warning(
        "pyflakes library not found. Python validation disabled. "
        "Install with 'pip install pyflakes'."
    )

try:
    import yaml
    PYYAML_AVAILABLE = True
except ImportError:
    PYYAML_AVAILABLE = False
    yaml = None
    logger.warning("PyYAML library not found. YAML validation may be limited.")

# Local imports
from core.github_handler import GitHubHandler, GitProgressHandler
from core.llm_interface import LLMInterface
from core.file_processor import FileProcessor
from core.exceptions import (
    BaseApplicationError,
    GitHubError,
    ParsingError,
    LLMError,
    ConfigurationError,
    FileProcessingError
)
from core.config_manager import ConfigManager


class BaseWorker(QThread):
    """
    Base class for worker threads providing common functionality and signals.
    
    This abstract class defines the basic structure and common signals used
    by all worker threads in the application.
    
    Signals:
        progressUpdate (int, str): Emitted to update progress percentage and message
        statusUpdate (str): Emitted to update status message
        errorOccurred (str): Emitted when an error occurs
    
    Attributes:
        _task (Optional[str]): Current task name
        _args (list): Task arguments
        _kwargs (dict): Task keyword arguments
        _isRunning (bool): Thread running state
    """
    
    progressUpdate = Signal(int, str)
    statusUpdate = Signal(str)
    errorOccurred = Signal(str)
    
    def __init__(self: 'BaseWorker', parent: Optional[Any] = None) -> None:
        """
        Initialize the base worker thread.
        
        Args:
            parent: Optional parent QObject
        """
        super().__init__(parent)
        self._task: Optional[str] = None
        self._args: list = []
        self._kwargs: dict = {}
        self._isRunning = False

    def setTask(self: 'BaseWorker', taskName: str, args: list, kwargs: dict) -> None:
        self._task = taskName
        self._args = args
        self._kwargs = kwargs

    def start(self, priority=QThread.Priority.InheritPriority) -> None:
        if self._isRunning:
            logger.warning(f"{self.__class__.__name__} already running. Ignoring start request.")
            return
        self._isRunning = True
        super().start(priority)

    def run(self: 'BaseWorker') -> None:
        if not self._task:
            logger.warning(f"{self.__class__.__name__} started without a task.")
            self.errorOccurred.emit(f"{self.__class__.__name__} started without task.")
            self._isRunning = False
            return
        try:
            self._executeTask()
        except Exception as e:
            logger.critical(f"Unhandled exception in {self.__class__.__name__} task '{self._task}': {e}", exc_info=True)
            self.errorOccurred.emit(f"Critical internal error in {self.__class__.__name__}: {e}")
        finally:
            self._task = None
            self._isRunning = False
            try:
                self.progressUpdate.emit(0, "Task finished.")
                self.statusUpdate.emit("Idle.")
            except RuntimeError as e:
                logger.error(f"Error emitting final signals in {self.__class__.__name__}: {e}")

    def _executeTask(self: 'BaseWorker') -> None:
        raise NotImplementedError("Subclasses must implement _executeTask.")


class GitHubWorker(BaseWorker):
    """
    Worker thread for handling Git/GitHub operations asynchronously.
    
    Signals:
        cloneFinished (str, list): Repository path and file list after clone
        pullFinished (str, bool): Pull message and conflict status
        listFilesFinished (list): List of files in repository
        readFileFinished (str): File content
        commitPushFinished (str): Commit/push result message
        isDirtyFinished (bool): Repository dirty status
        gitHubError (str): GitHub-specific error message
    """
    
    cloneFinished = Signal(str, list)
    pullFinished = Signal(str, bool)
    listFilesFinished = Signal(list)
    readFileFinished = Signal(str)
    commitPushFinished = Signal(str)
    isDirtyFinished = Signal(bool)
    gitHubError = Signal(str)
    
    def __init__(self: 'GitHubWorker', parent: Optional[Any] = None) -> None:
        """Initialize the GitHub worker with progress handling."""
        super().__init__(parent)
        self._handler: GitHubHandler = GitHubHandler()
        self._progress_handler_instance = GitProgressHandler(parent_qobject=self)
        
        if hasattr(self._progress_handler_instance, 'progressUpdateSignal'):
            self._progress_handler_instance.progressUpdateSignal.connect(self.progressUpdate)
        else:
            logger.warning("Could not connect progress handler signal in GitHubWorker.")

    @Slot(str, str, str)
    def startClone(self: 'GitHubWorker', repoUrlOrPath: str, localPath: str, authToken: Optional[str]) -> None:
        if self._isRunning:
            return
        self.setTask('clone', [repoUrlOrPath, localPath], {'authToken': authToken, 'progress_handler': self._progress_handler_instance})
        self.start()

    @Slot(str, str, str)
    def startPull(self: 'GitHubWorker', repoPath: str, remoteName: str, branchName: str) -> None:
        if self._isRunning:
            return
        self.setTask('pull', [repoPath], {'remoteName': remoteName, 'branchName': branchName, 'progress_handler': self._progress_handler_instance})
        self.start()

    @Slot(str)
    def startListFiles(self: 'GitHubWorker', repoPath: str) -> None:
        if self._isRunning:
            return
        self.setTask('listFiles', [repoPath], {})
        self.start()

    @Slot(str, str)
    def startReadFile(self: 'GitHubWorker', repoPath: str, filePath: str) -> None:
        if self._isRunning:
            return
        self.setTask('readFile', [repoPath, filePath], {})
        self.start()

    @Slot(str)
    def startIsDirty(self: 'GitHubWorker', repoPath: str) -> None:
        if self._isRunning:
            return
        self.setTask('isDirty', [repoPath], {})
        self.start()

    @Slot(str, str, str, str)
    def startCommitPush(self: 'GitHubWorker', repoPath: str, commitMessage: str, remoteName: str, branchName: str) -> None:
        if self._isRunning:
            return
        self.setTask('commitPush', [repoPath, commitMessage], {'push': True, 'remoteName': remoteName, 'branchName': branchName, 'progress_handler': self._progress_handler_instance})
        self.start()

    def _executeTask(self: 'GitHubWorker') -> None:
        try:
            if self._task == 'clone':
                repo = self._handler.cloneRepository(*self._args, **self._kwargs)
                repoPath: str = repo.working_dir
                fileList: List[str] = self._handler.listFiles(repoPath)
                self.cloneFinished.emit(repoPath, fileList)
            elif self._task == 'pull':
                message, had_conflicts = self._handler.pullRepository(*self._args, **self._kwargs)
                self.pullFinished.emit(message, had_conflicts)
            elif self._task == 'listFiles':
                self.statusUpdate.emit(f"Listing files in '{self._args[0]}'...")
                self.progressUpdate.emit(-1, "Listing files...")
                fileList = self._handler.listFiles(*self._args, **self._kwargs)
                self.listFilesFinished.emit(fileList)
            elif self._task == 'readFile':
                self.statusUpdate.emit(f"Reading file '{self._args[1]}'...")
                self.progressUpdate.emit(-1, f"Reading {self._args[1]}...")
                content = self._handler.readFileContent(*self._args, **self._kwargs)
                self.readFileFinished.emit(content)
            elif self._task == 'isDirty':
                self.statusUpdate.emit(f"Checking repository status '{self._args[0]}'...")
                self.progressUpdate.emit(-1, "Checking status...")
                is_dirty = self._handler.isDirty(*self._args, **self._kwargs)
                self.isDirtyFinished.emit(is_dirty)
            elif self._task == 'commitPush':
                message = self._handler.updateRepo(*self._args, **self._kwargs)
                self.commitPushFinished.emit(message)
            else:
                errMsg: str = f"Unknown GitHubWorker task: {self._task}"
                logger.error(errMsg)
                self.errorOccurred.emit(errMsg)
        except GitHubError as e:
            logger.error(f"GitHub task '{self._task}' failed: {e}", exc_info=False)
            self.gitHubError.emit(str(e))
        except Exception as e:
            logger.critical(f"Unexpected error during GitHub task '{self._task}': {e}", exc_info=True)
            self.errorOccurred.emit(f"Unexpected internal error during {self._task}: {e}")


class LLMWorker(BaseWorker):
    """
    Worker thread for handling LLM API interactions asynchronously.
    
    Handles communication with the LLM model, including standard queries
    and correction queries with temperature override.
    
    Signals:
        llmQueryFinished (str): Emitted with LLM response text
        llmError (str): Emitted with LLM-specific error message
    
    Attributes:
        _handler (LLMInterface): Interface for LLM operations
    """
    
    llmQueryFinished = Signal(str)
    llmError = Signal(str)
    
    def __init__(
        self: 'LLMWorker',
        parent: Optional[Any] = None,
        configManager: Optional[ConfigManager] = None
    ) -> None:
        """
        Initialize the LLM worker.
        
        Args:
            parent: Optional parent QObject
            configManager: Optional configuration manager instance
        """
        super().__init__(parent)
        self._handler: LLMInterface = LLMInterface(configManager=configManager)

    @Slot(str, str)
    def startQuery(self: 'LLMWorker', modelName: str, prompt: str) -> None:
        """
        Start a standard LLM query task.
        
        Args:
            modelName: Name of the LLM model to use
            prompt: The prompt text to send to the model
        """
        if self._isRunning:
            return
        self.setTask('query', [prompt], {'modelName': modelName})
        self.start()

    @Slot(str, str, float)
    def startCorrectionQuery(self: 'LLMWorker', modelName: str, correction_prompt: str, override_temperature: float) -> None:
        """Configures and starts the LLM correction query task."""
        if self._isRunning:
            return
        self.setTask('queryCorrection', [correction_prompt], {'modelName': modelName, 'override_temperature': override_temperature})
        self.start()

    def _executeTask(self: 'LLMWorker') -> None:
        """Executes the assigned LLM task."""
        try:
            if self._task == 'query' or self._task == 'queryCorrection':
                model_name_disp = self._kwargs.get('modelName', 'default model')
                override_temp = self._kwargs.get('override_temperature', None)
                status_msg = f"Querying LLM model {model_name_disp}"
                if self._task == 'queryCorrection':
                    status_msg = f"Requesting correction from LLM {model_name_disp} (Temp: {override_temp:.1f})..."
                self.statusUpdate.emit(status_msg)
                self.progressUpdate.emit(-1, status_msg)
                logger.debug(f"Calling queryLlmApi for task '{self._task}' with kwargs: {self._kwargs}")
                response: str = self._handler.queryLlmApi(*self._args, modelName=self._kwargs.get('modelName'), override_temperature=override_temp)
                self.llmQueryFinished.emit(response)
            else:
                errMsg: str = f"Unknown LLMWorker task: {self._task}"
                logger.error(errMsg)
                self.errorOccurred.emit(errMsg)
        except (LLMError, ConfigurationError) as e:
            logger.error(f"LLM task '{self._task}' failed: {e}", exc_info=False)
            self.llmError.emit(str(e))
        except TypeError as e:
            logger.critical(f"TypeError calling API in LLMWorker task '{self._task}': {e}", exc_info=True)
            self.errorOccurred.emit(f"Internal TypeError calling API: {e}")
        except Exception as e:
            logger.critical(f"Unexpected error during LLM task '{self._task}': {e}", exc_info=True)
            self.errorOccurred.emit(f"Unexpected internal error during {self._task}: {e}")


class FileWorker(BaseWorker):
    """
    Worker thread for file operations including parsing, validation, and saving.
    
    Signals:
        parsingFinished (dict, dict): Parsed data and validation results
        savingFinished (list): List of saved file paths
        fileContentsRead (dict, str): File contents and user instruction
        fileProcessingError (str): File processing error message
    """
    
    parsingFinished = Signal(dict, dict)
    savingFinished = Signal(list)
    fileContentsRead = Signal(dict, str)
    fileProcessingError = Signal(str)
    
    def __init__(self: 'FileWorker', parent: Optional[Any] = None) -> None:
        """Initialize the file worker."""
        super().__init__(parent)
        self._handler: FileProcessor = FileProcessor()
        self._github_handler: GitHubHandler = GitHubHandler()

    @Slot(str, str)
    def startParsing(self: 'FileWorker', llmResponse: str, expectedFormat: str = 'json') -> None:
        """Configures and starts the response parsing and validation task."""
        if self._isRunning:
            return
        try:
            codeBlock: Optional[str] = self._handler.extractCodeBlock(llmResponse, expectedFormat)
            if codeBlock is None:
                self.fileProcessingError.emit("Could not find or extract code block from LLM response.")
                return
            self.setTask('parseAndValidate', [codeBlock], {'format': expectedFormat})
            self.start()
        except Exception as e:
            logger.error(f"Error during code block extraction: {e}", exc_info=True)
            self.fileProcessingError.emit(f"Failed to extract code block: {e}")

    @Slot(str, list, str)
    def startReadFileContents(self: 'FileWorker', repoPath: str, filePaths: List[str], userInstruction: str) -> None:
        if self._isRunning:
            return
        self.setTask('readFileContents', [repoPath, filePaths], {'instruction': userInstruction})
        self.start()

    @Slot(str, dict)
    def startSaving(self: 'FileWorker', outputDir: str, fileData: Dict[str, str]) -> None:
        if self._isRunning:
            return
        self.setTask('save', [outputDir, fileData], {})
        self.start()

    def _validate_code_content(self, file_path: str, content: str) -> List[str]:
        """
        Validates code syntax based on file extension.
        
        Args:
            file_path: Path to the file (for determining type)
            content: Code content to validate
            
        Returns:
            List of validation error messages (empty if valid)
        """
        errors: List[str] = []
        _, extension = os.path.splitext(file_path.lower())
        
        try:
            if extension == '.py':
                if PYFLAKES_AVAILABLE and pyflakes:
                    error_stream = io.StringIO()
                    reporter = pyflakes.reporter.Reporter(io.StringIO(), error_stream)
                    try:
                        pyflakes.api.check(content, file_path, reporter=reporter)
                        error_output = error_stream.getvalue().strip()
                        if error_output:
                            errors.extend(error_output.splitlines())
                    except Exception as pyflakes_err:
                        errors.append(f"Pyflakes runtime error: {pyflakes_err}")
                    finally:
                        error_stream.close()
                else:
                    logger.debug("Skipped Python validation (pyflakes unavailable).")
            
            elif extension == '.json':
                try:
                    json.loads(content)
                except json.JSONDecodeError as json_err:
                    errors.append(
                        f"JSON Error: {json_err.msg} "
                        f"(line {json_err.lineno}, col {json_err.colno})"
                    )
            
            elif extension in ['.yaml', '.yml']:
                if PYYAML_AVAILABLE and yaml is not None:
                    try:
                        list(yaml.safe_load_all(content))
                    except yaml.YAMLError as yaml_err:
                        mark_info = (
                            f" (line {yaml_err.problem_mark.line + 1})"
                            if hasattr(yaml_err, 'problem_mark') and yaml_err.problem_mark
                            else ""
                        )
                        errors.append(f"YAML Error: {yaml_err.problem}{mark_info}")
                else:
                    logger.debug("Skipped YAML validation (PyYAML unavailable).")
                    
        except Exception as e:
            logger.error(
                f"Unexpected validation error for '{file_path}': {e}",
                exc_info=True
            )
            errors.append(f"Internal validation error: {e}")
            
        return errors

    def _executeTask(self: 'FileWorker') -> None:
        """Executes the assigned file processing task."""
        try:
            if self._task == 'parseAndValidate':
                fmt = self._kwargs.get('format', 'data')
                self.statusUpdate.emit(f"Parsing {fmt}...")
                self.progressUpdate.emit(-1, f"Parsing {fmt}...")
                codeBlockContent = self._args[0]
                parsedData: Dict[str, str] = self._handler.parseStructuredOutput(codeBlockContent, fmt)
                self.statusUpdate.emit(f"Validating {len(parsedData)} file(s)...")
                self.progressUpdate.emit(-1, f"Validating {len(parsedData)} files...")
                validationResults: Dict[str, List[str]] = {}
                total_files = len(parsedData)
                files_validated = 0
                for file_path, content in parsedData.items():
                    file_errors = self._validate_code_content(file_path, content)
                    if file_errors:
                        validationResults[file_path] = file_errors
                        logger.warning(f"Validation failed for '{file_path}': {len(file_errors)} error(s).")
                    files_validated += 1
                    percentage = int((files_validated / total_files) * 100) if total_files > 0 else 100
                    self.progressUpdate.emit(percentage, f"Validated {files_validated}/{total_files} files")
                if validationResults:
                    self.statusUpdate.emit(f"Parsing complete. Validation FAILED for {len(validationResults)} file(s).")
                else:
                    self.statusUpdate.emit("Parsing and validation complete. No errors found.")
                self.parsingFinished.emit(parsedData, validationResults)
            elif self._task == 'readFileContents':
                repoPath, filePaths = self._args
                userInstruction = self._kwargs.get('instruction', '')
                numFiles = len(filePaths)
                self.statusUpdate.emit(f"Reading {numFiles} files...")
                self.progressUpdate.emit(-1, f"Reading {numFiles} files...")
                fileContents: Dict[str, str] = {}
                for i, filePath in enumerate(filePaths):
                    try:
                        content = self._github_handler.readFileContent(repoPath, filePath)
                        fileContents[filePath] = content
                        percentage = int(((i + 1) / numFiles) * 100)
                        self.progressUpdate.emit(percentage, f"Reading {filePath} ({i+1}/{numFiles})")
                    except GitHubError as e:
                        logger.error(f"Failed to read file '{filePath}' for context: {e}")
                        self.fileProcessingError.emit(f"Error reading file '{filePath}': {e}")
                    except Exception as e:
                        logger.error(f"Unexpected error reading file '{filePath}': {e}", exc_info=True)
                        self.fileProcessingError.emit(f"Unexpected error reading '{filePath}': {e}")
                self.fileContentsRead.emit(fileContents, userInstruction)
            elif self._task == 'save':
                outputDir = self._args[0]
                numFiles = len(self._args[1])
                self.statusUpdate.emit(f"Saving {numFiles} files to '{outputDir}'...")
                self.progressUpdate.emit(-1, f"Saving {numFiles} files...")
                savedFiles: List[str] = self._handler.saveFilesToDisk(*self._args, **self._kwargs)
                self.savingFinished.emit(savedFiles)
            else:
                errMsg: str = f"Unknown FileWorker task: {self._task}"
                logger.error(errMsg)
                self.errorOccurred.emit(errMsg)
        except ParsingError as e:
            logger.error(f"File processing task '{self._task}' failed: {e}", exc_info=False)
            self.fileProcessingError.emit(f"ParsingError: {str(e)}")
        except (FileProcessingError, GitHubError) as e:
            logger.error(f"File processing task '{self._task}' failed: {e}", exc_info=False)
            self.fileProcessingError.emit(str(e))
        except Exception as e:
            logger.critical(f"Unexpected error during FileWorker task '{self._task}': {e}", exc_info=True)
            self.errorOccurred.emit(f"Unexpected internal error during {self._task}: {e}")

## gui/gui_utils.py ##

# Updated Codebase/gui/gui_utils.py
# --- START: gui/gui_utils.py ---
# gui/gui_utils.py
"""
Utility functions and classes specific to the GUI components.
Includes the custom logging handler for directing logs to the GUI.
"""

import logging
import sys # Import sys for stderr fallback
from typing import Callable, Optional
from PySide6.QtCore import QObject, Signal # Removed Slot as it's not used here

class QtLogHandler(logging.Handler, QObject):
	"""
	A custom logging handler that emits Qt signals with formatted log messages.
	Inherits from logging.Handler and QObject.
	"""
	# No explicit Signal definition needed here as the emitter is passed in.

	# Store the callable that will emit the signal (e.g., self.signalLogMessage.emit)
	_signal_emitter: Optional[Callable[[str], None]] = None

	# --- CORRECTED __init__ ---
	# Accepts the emitter callable and an optional QObject parent separately.
	def __init__(self: 'QtLogHandler', signal_emitter: Optional[Callable[[str], None]] = None, parent: Optional[QObject] = None) -> None:
		"""
		Initialiser for the QtLogHandler.

		Args:
			signal_emitter (Optional[Callable[[str], None]]): The callable (e.g., signal.emit) to call with the formatted log message.
			parent (QObject, optional): Parent QObject. Defaults to None.
		"""
		# Initialise base classes correctly
		logging.Handler.__init__(self)
		# Pass ONLY the parent QObject (or None) to the QObject initialiser
		QObject.__init__(self, parent)
		# Store the signal emitter callable
		self._signal_emitter = signal_emitter
	# --- END CORRECTION ---

	def emit(self: 'QtLogHandler', record: logging.LogRecord) -> None:
		"""
		Formats the log record and emits it via the stored signal emitter callable.

		Args:
			record (logging.LogRecord): The log record to process.
		"""
		# Check if an emitter callable was provided
		if not self._signal_emitter:
			# Handle case where no emitter was given (maybe log to stderr?)
			# Ensure sys is imported if using stderr here
			print(f"QtLogHandler Error: No signal emitter configured. Log Record: {record}", file=sys.stderr)
			return

		try:
			# Use the formatter attached to this handler (set during setup)
			msg = self.format(record)
			# Call the stored signal emitter callable
			self._signal_emitter(msg)
		except Exception:
			# Fallback in case of formatting errors etc.
			self.handleError(record)

	# Optional: Implement close() if resources need cleanup
	# def close(self) -> None:
	#     logging.Handler.close(self)

# --- END: gui/gui_utils.py ---

## gui/main_window.py ##

"""
Main application window module for the GUI application.

This module defines the primary window interface and coordinates all user
interactions, background tasks, and visual updates. It handles:
- Repository management (clone, pull, commit)
- File selection and display
- LLM interactions and response processing
- Code validation and diff viewing
- Error handling and status updates

The window uses multiple worker threads to prevent UI freezing during
long-running operations.
"""

# Standard library imports
import os
import logging
import difflib
import html
from typing import Optional, Dict, Union, List, Tuple

# Qt imports
from PySide6.QtWidgets import (
    QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QLabel, QLineEdit, QPushButton, QTextEdit,
    QListWidget, QProgressBar, QStatusBar,
    QMessageBox, QSplitter, QFileDialog,
    QInputDialog, QTabWidget, QListWidgetItem
)
from PySide6.QtCore import Qt, Slot, Signal, QObject
from PySide6.QtGui import QIcon, QTextOption, QFont, QColor

# Local imports
from core.config_manager import ConfigManager
from core.exceptions import (
    ConfigurationError,
    ParsingError,
    BaseApplicationError,
    GitHubError
)
from core.github_handler import GitHubHandler
from core.llm_interface import LLMInterface
from gui.threads import GitHubWorker, LLMWorker, FileWorker
from utils.logger_setup import setupLogging
from gui.gui_utils import QtLogHandler

# Initialize logging
logger: logging.Logger = logging.getLogger(__name__)

# Constants for UI styling
HTML_COLOR_ADDED_BG = "#e6ffed"
HTML_COLOR_DELETED_BG = "#ffeef0"
HTML_COLOR_PLACEHOLDER_BG = "#f8f9fa"
HTML_COLOR_LINE_NUM = "#6c757d"
HTML_COLOR_TEXT = "#212529"
HTML_FONT_FAMILY = "'Courier New', Courier, monospace"
HTML_FONT_SIZE = "9pt"
CORRECTION_RETRY_TEMPERATURE = 0.4  # Lower temperature for correction attempts

class MainWindow(QMainWindow):
    """
    Main application window implementing the primary user interface.
    
    Coordinates all user interactions, background tasks, and visual updates.
    Manages multiple worker threads for long-running operations.
    
    Signals:
        signalLogMessage (str): Emitted to update the log display
    """
    
    signalLogMessage = Signal(str)

    def __init__(self: 'MainWindow', configManager: ConfigManager, parent: Optional[QWidget] = None) -> None:
        """
        Initialize the main window.
        
        Args:
            configManager: Configuration manager instance
            parent: Optional parent widget
        """
        super().__init__(parent)
        self._configManager = configManager
        
        # Initialize state variables
        self._selectedFiles = []
        self._originalFileContents = {}
        self._clonedRepoPath = None
        self._parsedFileData = None
        self._validationErrors = None
        self._isBusy = False
        self._repoIsDirty = False
        self._is_syncing_scroll = False
        self._correction_attempted = False
        
        # Initialize core handlers
        self._githubHandlerInstance = GitHubHandler()
        self._llmInterfaceInstance = LLMInterface(configManager=self._configManager)
        
        logger.info("Initializing MainWindow...")
        self._setupUI()
        self._loadInitialSettings()
        
        # Initialize workers
        self._githubWorker = GitHubWorker(parent=self)
        self._llmWorker = LLMWorker(parent=self, configManager=self._configManager)
        self._fileWorker = FileWorker(parent=self)
        
        self._connectSignals()
        self._updateWidgetStates()
        self._setupGuiLogging()
        
        logger.info("MainWindow initialized.")

    # --- UI Setup (unchanged from previous revert) ---
    def _setupUI(self: 'MainWindow') -> None:
        """Sets up the user interface layout and widgets."""
        logger.debug("Setting up UI elements.")
        self.setWindowTitle("Colonol Code - LLM Code Updater")
        iconPath = os.path.join('resources', 'app_icon.png')
        if os.path.exists(iconPath): self.setWindowIcon(QIcon(iconPath))
        else: logger.warning(f"Application icon not found at: {iconPath}")
        self._centralWidget = QWidget(); self.setCentralWidget(self._centralWidget); self._mainLayout = QVBoxLayout(self._centralWidget)
        repoLayout = QHBoxLayout(); repoLabel = QLabel("GitHub Repo URL / Local Path:"); self._repoUrlInput = QLineEdit(); self._repoUrlInput.setPlaceholderText("[https://github.com/user/repo.git](https://github.com/user/repo.git) or /path/to/local/repo"); self._browseButton = QPushButton("Browse..."); self._cloneButton = QPushButton("Clone / Load Repo"); repoLayout.addWidget(repoLabel); repoLayout.addWidget(self._repoUrlInput, 1); repoLayout.addWidget(self._browseButton); repoLayout.addWidget(self._cloneButton); self._mainLayout.addLayout(repoLayout)
        middleSplitter = QSplitter(Qt.Orientation.Horizontal)
        fileListLayout = QVBoxLayout(); fileListLabel = QLabel("Select File(s) for Context (Click/Shift/Ctrl):"); self._fileListWidget = QListWidget(); self._fileListWidget.setSelectionMode(QListWidget.SelectionMode.ExtendedSelection); fileListLayout.addWidget(fileListLabel); fileListLayout.addWidget(self._fileListWidget); fileListWidgetContainer = QWidget(); fileListWidgetContainer.setLayout(fileListLayout); middleSplitter.addWidget(fileListWidgetContainer)
        promptLayout = QVBoxLayout(); promptLabel = QLabel("LLM Instruction / Prompt:"); self._promptInput = QTextEdit(); self._promptInput.setPlaceholderText("Enter your instructions for code modification...")
        llmInteractionLayout = QHBoxLayout(); self._sendToLlmButton = QPushButton("Send to LLM"); self._pasteResponseButton = QPushButton("Paste LLM Response"); self._llmResponseArea = QTextEdit(); self._llmResponseArea.setPlaceholderText("LLM response will appear here, or paste response and click 'Parse & Validate'"); self._llmResponseArea.setReadOnly(False); llmInteractionLayout.addWidget(self._sendToLlmButton); llmInteractionLayout.addWidget(self._pasteResponseButton); llmInteractionLayout.addStretch(1); promptLayout.addWidget(promptLabel); promptLayout.addWidget(self._promptInput, stretch=1); promptLayout.addLayout(llmInteractionLayout); promptLayout.addWidget(QLabel("LLM Response:")); promptLayout.addWidget(self._llmResponseArea, stretch=2); promptWidgetContainer = QWidget(); promptWidgetContainer.setLayout(promptLayout); middleSplitter.addWidget(promptWidgetContainer)
        middleSplitter.setSizes([300, 600]); self._mainLayout.addWidget(middleSplitter, stretch=1)
        bottomLayout = QVBoxLayout(); actionLayout = QHBoxLayout(); self._parseButton = QPushButton("Parse & Validate"); self._saveFilesButton = QPushButton("Save Changes Locally"); self._commitPushButton = QPushButton("Commit & Push"); actionLayout.addWidget(self._parseButton); actionLayout.addWidget(self._saveFilesButton); actionLayout.addWidget(self._commitPushButton); actionLayout.addStretch(1); bottomLayout.addLayout(actionLayout)
        self._bottomTabWidget = QTabWidget()
        diffWidget = QWidget(); diffLayout = QVBoxLayout(diffWidget); diffSplitter = QSplitter(Qt.Orientation.Horizontal)
        codeFont = QFont(HTML_FONT_FAMILY.split(',')[0].strip("' ")); codeFont.setStyleHint(QFont.StyleHint.Monospace); codeFont.setPointSize(int(HTML_FONT_SIZE.replace('pt','')))
        originalLayout = QVBoxLayout(); originalLayout.addWidget(QLabel("Original Code:")); self._originalCodeArea = QTextEdit(); self._originalCodeArea.setReadOnly(True); self._originalCodeArea.setLineWrapMode(QTextEdit.LineWrapMode.NoWrap); self._originalCodeArea.setFont(codeFont); originalContainer = QWidget(); originalContainer.setLayout(originalLayout); diffSplitter.addWidget(originalContainer)
        proposedLayout = QVBoxLayout(); proposedLayout.addWidget(QLabel("Proposed Code (from LLM):")); self._proposedCodeArea = QTextEdit(); self._proposedCodeArea.setReadOnly(True); self._proposedCodeArea.setLineWrapMode(QTextEdit.LineWrapMode.NoWrap); self._proposedCodeArea.setFont(codeFont); proposedContainer = QWidget(); proposedContainer.setLayout(proposedLayout); diffSplitter.addWidget(proposedContainer)
        diffSplitter.setSizes([400, 400]); diffLayout.addWidget(diffSplitter); self._bottomTabWidget.addTab(diffWidget, "Side-by-Side Diff")
        self._appLogArea = QTextEdit(); self._appLogArea.setReadOnly(True); self._appLogArea.setLineWrapMode(QTextEdit.LineWrapMode.NoWrap); logFont = QFont("monospace"); logFont.setPointSize(10); self._appLogArea.setFont(logFont); self._bottomTabWidget.addTab(self._appLogArea, "Application Log")
        bottomLayout.addWidget(self._bottomTabWidget, stretch=1); self._mainLayout.addLayout(bottomLayout, stretch=1)
        self._statusBar = QStatusBar(); self.setStatusBar(self._statusBar); self._progressBar = QProgressBar(); self._progressBar.setVisible(False); self._progressBar.setTextVisible(True); self._progressBar.setRange(0, 100); self._progressBar.setValue(0); self._progressBar.setFormat("%p%"); self._statusBar.addPermanentWidget(self._progressBar)
        self.setGeometry(100, 100, 1100, 850); logger.debug("UI setup complete.")

    # --- Load/Save Settings (unchanged) ---
    def _loadInitialSettings(self: 'MainWindow') -> None:
        try:
            last_repo = self._configManager.getConfigValue('General', 'LastRepoPath', fallback='')
        except Exception as e:
            logger.warning(f"Could not read LastRepoPath from config: {e}")
        if last_repo and isinstance(last_repo, str) and last_repo.strip(): logger.info(f"Loaded last used repository path: {last_repo}"); self._repoUrlInput.setText(last_repo)
        else: logger.debug("No last repository path found in config.")
        try:
            last_repo = self._configManager.getConfigValue('General', 'LastRepoPath', fallback='')
            if last_repo and isinstance(last_repo, str) and last_repo.strip():
                logger.info(f"Loaded last used repository path: {last_repo}")
                self._repoUrlInput.setText(last_repo)
            else:
                logger.debug("No last repository path found in config.")
        except ConfigurationError as e:
            logger.warning(f"Could not read LastRepoPath from config: {e}")
        try:
            last_repo = self._configManager.getConfigValue('General', 'LastRepoPath', fallback='')
            if last_repo and isinstance(last_repo, str) and last_repo.strip():
                logger.info(f"Loaded last used repository path: {last_repo}")
                self._repoUrlInput.setText(last_repo)
            else:
                logger.debug("No last repository path found in config.")
        except Exception as e:
            logger.error(f"Unexpected error loading initial settings: {e}", exc_info=True)
    def _saveLastRepoPath(self: 'MainWindow', repoPath: str) -> None:
        try: logger.debug(f"Attempting to save last repo path: {repoPath}"); self._configManager.setConfigValue('General', 'LastRepoPath', repoPath); logger.info(f"Saved last repository path to config: {repoPath}")
        except ConfigurationError as e: logger.error(f"Failed to save LastRepoPath to config: {e}")
        except Exception as e: logger.error(f"Unexpected error saving last repo path: {e}", exc_info=True)

    # --- Signal Connections (unchanged) ---
    def _connectSignals(self: 'MainWindow') -> None:
        logger.debug("Connecting signals to slots.")
        self._browseButton.clicked.connect(self._handleBrowseRepo); self._cloneButton.clicked.connect(self._handleCloneRepo); self._fileListWidget.itemSelectionChanged.connect(self._handleSelectionChange); self._sendToLlmButton.clicked.connect(self._handleSendToLlm); self._pasteResponseButton.clicked.connect(self._handlePasteResponse); self._parseButton.clicked.connect(self._handleParseAndValidate); self._saveFilesButton.clicked.connect(self._handleSaveChanges); self._commitPushButton.clicked.connect(self._handleCommitPush)
        self._githubWorker.statusUpdate.connect(self._updateStatusBar); self._githubWorker.progressUpdate.connect(self._updateProgress); self._githubWorker.errorOccurred.connect(self._handleWorkerError); self._githubWorker.gitHubError.connect(self._handleGitHubError); self._githubWorker.cloneFinished.connect(self._onCloneFinished); self._githubWorker.commitPushFinished.connect(self._onCommitPushFinished); self._githubWorker.isDirtyFinished.connect(self._onIsDirtyFinished); self._githubWorker.pullFinished.connect(self._onPullFinished)
        self._llmWorker.statusUpdate.connect(self._updateStatusBar); self._llmWorker.progressUpdate.connect(self._updateProgress); self._llmWorker.errorOccurred.connect(self._handleWorkerError); self._llmWorker.llmError.connect(self._handleLLMError); self._llmWorker.llmQueryFinished.connect(self._onLlmFinished)
        self._fileWorker.statusUpdate.connect(self._updateStatusBar); self._fileWorker.progressUpdate.connect(self._updateProgress); self._fileWorker.errorOccurred.connect(self._handleWorkerError); self._fileWorker.fileProcessingError.connect(self._handleFileProcessingError); self._fileWorker.parsingFinished.connect(self._onParsingFinished); self._fileWorker.savingFinished.connect(self._onSavingFinished); self._fileWorker.fileContentsRead.connect(self._onFileContentsRead)
        self.signalLogMessage.connect(self._appendLogMessage)
        orig_scrollbar = self._originalCodeArea.verticalScrollBar(); prop_scrollbar = self._proposedCodeArea.verticalScrollBar(); orig_scrollbar.valueChanged.connect(self._syncScrollProposedFromOriginal); prop_scrollbar.valueChanged.connect(self._syncScrollOriginalFromProposed)
        logger.debug("Signal connections established.")

    # --- GUI Logging (unchanged) ---
    def _setupGuiLogging(self: 'MainWindow') -> None:
        try:
            guiHandler = QtLogHandler(signal_emitter=self.signalLogMessage.emit, parent=self); guiLogLevelName = self._configManager.getConfigValue('Logging', 'GuiLogLevel', fallback='DEBUG'); guiLogLevel = getattr(logging, guiLogLevelName.upper(), logging.DEBUG); guiHandler.setLevel(guiLogLevel); logFormat = self._configManager.getConfigValue('Logging', 'GuiLogFormat', fallback='%(asctime)s - %(levelname)s - %(message)s'); dateFormat = self._configManager.getConfigValue('Logging', 'GuiLogDateFormat', fallback='%H:%M:%S'); formatter = logging.Formatter(logFormat, datefmt=dateFormat); guiHandler.setFormatter(formatter); logging.getLogger().addHandler(guiHandler); logger.info(f"GUI logging handler added with level {logging.getLevelName(guiLogLevel)}.")
        except ImportError: logger.error("QtLogHandler import failed. GUI logging disabled.")
        except Exception as e: logger.error(f"Failed to setup GUI logging handler: {e}", exc_info=True)

    # --- Slots (Event Handlers) ---
    @Slot()
    def _handleBrowseRepo(self: 'MainWindow') -> None: # Unchanged
        startDir = self._repoUrlInput.text() or os.path.expanduser("~"); directory = QFileDialog.getExistingDirectory(self, "Select Local Repository Folder", startDir);
        if directory: self._repoUrlInput.setText(directory)

    @Slot()
    def _handleCloneRepo(self: 'MainWindow') -> None:
        # Guard against busy state first
        if self._isBusy:
            self._showWarning("Busy", "Task already running.")
            return
            
        # Get and validate repo URL/path
        repoUrlOrPath = self._repoUrlInput.text().strip()
        if not repoUrlOrPath:
            self._showError("Repository Missing", "Enter URL or path.")
            return

        # Determine clone target path
        try:
            if os.path.isdir(repoUrlOrPath):
                cloneTargetFullPath = os.path.abspath(repoUrlOrPath)
            else:
                defaultCloneDir = self._configManager.getConfigValue('General', 'DefaultCloneDir', fallback='./cloned')
                cloneBaseDir = os.path.abspath(defaultCloneDir)
                os.makedirs(cloneBaseDir, exist_ok=True)
                repoName = os.path.basename(repoUrlOrPath.rstrip('/'))
                repoName = repoName[:-4] if repoName.endswith('.git') else repoName
                safeRepoName = "".join(c for c in repoName if c.isalnum() or c in ('-', '_')).strip() or "repository"
                cloneTargetFullPath = os.path.join(cloneBaseDir, safeRepoName)
        except Exception as e:
            self._showError("Path Error", f"Could not determine target path: {e}")
            return

        # Start clone operation
        self._isBusy = True
        self._updateWidgetStates()
        self._updateStatusBar("Loading/Cloning...")
        self._updateProgress(-1, "Starting...")
        
        # Clear state
        self._clonedRepoPath = None
        self._fileListWidget.clear()
        self._originalFileContents.clear()
        self._parsedFileData = None
        self._validationErrors = None
        self._originalCodeArea.clear()
        self._proposedCodeArea.clear()
        self._llmResponseArea.clear()
        
        # Start clone worker
        self._githubWorker.startClone(repoUrlOrPath, cloneTargetFullPath, None)

    @Slot()
    def _handleSelectionChange(self: 'MainWindow') -> None: # Unchanged
        if self._isBusy: return; selectedItems = self._fileListWidget.selectedItems(); self._selectedFiles = sorted([item.text() for item in selectedItems]); logger.debug(f"Selection changed. Selected files: {self._selectedFiles}"); currentItem = self._fileListWidget.currentItem(); self._displaySelectedFileDiff(currentItem, None)
    @Slot(QListWidgetItem, QListWidgetItem)
    def _displaySelectedFileDiff(self: 'MainWindow', current: Optional[QListWidgetItem], previous: Optional[QListWidgetItem]) -> None: # Unchanged
        _ = previous;
        if self._isBusy: return; self._originalCodeArea.clear(); self._proposedCodeArea.clear();
        if not current:
            if self._selectedFiles: self._updateStatusBar(f"{len(self._selectedFiles)} files selected. Click one to view diff.", 5000)
            else: self._updateStatusBar("Select file(s) for context.", 3000)
            self._syncScrollbars(); return
        filePath = current.text(); original_content = self._originalFileContents.get(filePath, None); proposed_content = None; is_new_file = False; status_msg = f"Displaying: {filePath}"; validation_info = ""
        if self._validationErrors and filePath in self._validationErrors: count = len(self._validationErrors[filePath]); validation_info = f" - <font color='red'><b>Validation Failed ({count} errors)</b></font>"
        elif self._parsedFileData is not None and filePath in self._parsedFileData and self._validationErrors is not None: validation_info = " - <font color='green'>Validation OK</font>"
        if self._parsedFileData is not None:
            if filePath in self._parsedFileData: proposed_content = self._parsedFileData[filePath];
            if original_content is None: is_new_file = True; original_content = ""; status_msg += " - New File"
            elif original_content == proposed_content: status_msg += " - Original (No Changes)"
            else: status_msg += " - Original vs Proposed"
            if original_content is not None: proposed_content = original_content; status_msg += " - Original (No Changes Proposed)"; validation_info = ""
            else: proposed_content = "(File details unavailable)"; original_content = proposed_content; validation_info = ""
        elif original_content is not None: proposed_content = "(Awaiting Parse/Validation)"; status_msg += " - Original (Awaiting Parse)"; validation_info = ""
        else: original_content = "(Content not loaded)"; proposed_content = ""; status_msg += " - (Awaiting Context)"; validation_info = ""
        original_html, proposed_html = self._generate_diff_html((original_content or "").splitlines(), (proposed_content or "").splitlines(), is_new_file)
        orig_sb = self._originalCodeArea.verticalScrollBar(); prop_sb = self._proposedCodeArea.verticalScrollBar(); orig_sb.blockSignals(True); prop_sb.blockSignals(True); self._originalCodeArea.setHtml(original_html); self._proposedCodeArea.setHtml(proposed_html); orig_sb.blockSignals(False); prop_sb.blockSignals(False); self._updateStatusBar(status_msg + validation_info, 10000); self._syncScrollbars()
    def _generate_diff_html(self: 'MainWindow', original_lines: List[str], proposed_lines: List[str], is_new_file: bool) -> Tuple[str, str]: # Unchanged
        html_style = (f"<style>body{{margin:0;padding:0;font-family:{HTML_FONT_FAMILY};font-size:{HTML_FONT_SIZE};color:{HTML_COLOR_TEXT};background-color:#fff;}}" f".line{{display:flex;white-space:pre;min-height:1.2em;border-bottom:1px solid #eee;}}" f".line-num{{flex:0 0 40px;text-align:right;padding-right:10px;color:{HTML_COLOR_LINE_NUM};background-color:#f1f1f1;user-select:none;border-right:1px solid #ddd;}}" f".line-content{{flex-grow:1;padding-left:10px;}}" f".equal{{background-color:#fff;}}.delete{{background-color:{HTML_COLOR_DELETED_BG};}}" f".insert{{background-color:{HTML_COLOR_ADDED_BG};}}" f".placeholder{{background-color:{HTML_COLOR_PLACEHOLDER_BG};color:#aaa;font-style:italic;}}" f".new-file-placeholder{{background-color:{HTML_COLOR_DELETED_BG};color:#aaa;font-style:italic;text-align:center;}}" f"</style>")
        original_html = [html_style, "<body>"]; proposed_html = [html_style, "<body>"]
        def format_line(num, content, css): esc_content = html.escape(content).replace(" ", "&nbsp;") or "&nbsp;"; num_str = str(num) if isinstance(num, int) else "&nbsp;"; return f'<div class="line {css}"><div class="line-num">{num_str}</div><div class="line-content">{esc_content}</div></div>'
        if is_new_file: original_html.append('<div class="line new-file-placeholder"><div class="line-num">&nbsp;</div><div class="line-content">&lt;New File&gt;</div></div>');
        for i, line in enumerate(proposed_lines): proposed_html.append(format_line(i + 1, line, 'insert'))
        else:
            matcher = difflib.SequenceMatcher(None, original_lines, proposed_lines, autojunk=False); o_num, p_num = 1, 1
            for tag, i1, i2, j1, j2 in matcher.get_opcodes():
                max_len = max(i2 - i1, j2 - j1)
                for i in range(max_len):
                    o_idx, p_idx = i1 + i, j1 + i; o_line, p_line = "", ""; o_css, p_css = "placeholder", "placeholder"; o_ln, p_ln = "", ""
                    if tag == 'equal':
                        if o_idx < i2: o_line, o_css, o_ln = original_lines[o_idx], 'equal', o_num; o_num += 1
                        if p_idx < j2: p_line, p_css, p_ln = proposed_lines[p_idx], 'equal', p_num; p_num += 1
                    elif tag == 'delete':
                        if o_idx < i2: o_line, o_css, o_ln = original_lines[o_idx], 'delete', o_num; o_num += 1
                        p_line, p_css, p_ln = "", 'placeholder', ""
                    elif tag == 'insert':
                        o_line, o_css, o_ln = "", 'placeholder', ""
                        if p_idx < j2: p_line, p_css, p_ln = proposed_lines[p_idx], 'insert', p_num; p_num += 1
                    elif tag == 'replace':
                        if o_idx < i2: o_line, o_css, o_ln = original_lines[o_idx], 'delete', o_num; o_num += 1
                        else: o_line, o_css, o_ln = "", 'placeholder', ""
                        if p_idx < j2: p_line, p_css, p_ln = proposed_lines[p_idx], 'insert', p_num; p_num += 1
                        else: p_line, p_css, p_ln = "", 'placeholder', ""
                    original_html.append(format_line(o_ln, o_line, o_css)); proposed_html.append(format_line(p_ln, p_line, p_css))
        original_html.append("</body>"); proposed_html.append("</body>")
        return "\n".join(original_html), "\n".join(proposed_html)

    # --- Send to LLM (MODIFIED: Reset correction flag) ---
    @Slot()
    def _handleSendToLlm(self: 'MainWindow') -> None:
        if self._isBusy: self._showWarning("Busy", "Task already running."); return
        userInstruction: str = self._promptInput.toPlainText().strip()
        if not userInstruction: self._showError("LLM Instruction Missing", "Enter instructions."); return
        if not self._clonedRepoPath: self._showError("Repository Not Loaded", "Load repository first."); return
        
        # Get currently selected files from the list widget
        selected_items = self._fileListWidget.selectedItems()
        self._selectedFiles = [item.text() for item in selected_items]
        
        file_context_msg = f" with context from {len(self._selectedFiles)} file(s)" if self._selectedFiles else " without file context"
        if not selected_items:  # Check selected_items instead of self._selectedFiles
            reply = QMessageBox.question(self, "No Files Selected", "Proceed without file context?", 
                                      QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.Cancel, 
                                      QMessageBox.StandardButton.Cancel)
            if reply == QMessageBox.StandardButton.Cancel: return

        self._correction_attempted = False
        self._isBusy = True; self._updateWidgetStates(); self._originalFileContents.clear(); self._parsedFileData = None; self._validationErrors = None
        self._originalCodeArea.clear(); self._proposedCodeArea.clear(); self._llmResponseArea.clear()
        self._updateStatusBar(f"Reading files{file_context_msg}..."); self._updateProgress(-1, "Reading files...")
        self._fileWorker.startReadFileContents(self._clonedRepoPath, self._selectedFiles, userInstruction)

    # --- File Contents Read (unchanged) ---
    @Slot(dict, str)
    def _onFileContentsRead(self: 'MainWindow', fileContents: Dict[str, str], userInstruction: str) -> None:
        logger.info(f"File reading finished ({len(fileContents)} files). Querying LLM...")
        self._originalFileContents = fileContents; self._displaySelectedFileDiff(self._fileListWidget.currentItem(), None)
        try: modelName = self._configManager.getConfigValue('General', 'DefaultLlmModel', fallback='gemini-pro') or 'gemini-pro'
        except ConfigurationError as e: self._showError("Config Error", f"Could not read LLM model: {e}"); self._resetTaskState(); return
        try: prompt = self._llmInterfaceInstance.buildPrompt(userInstruction, fileContents)
        except Exception as e: self._showError("Prompt Error", f"Failed to build prompt: {e}"); self._resetTaskState(); return
        self._updateStatusBar("Sending request to LLM..."); self._updateProgress(-1, "Sending to LLM...")
        # Send original query
        self._llmWorker.startQuery(modelName, prompt)

    # --- Paste Response (MODIFIED: Reset correction flag) ---
    @Slot()
    def _handlePasteResponse(self: 'MainWindow') -> None:
        self._llmResponseArea.clear(); self._parsedFileData = None; self._validationErrors = None; self._originalCodeArea.clear(); self._proposedCodeArea.clear(); self._llmResponseArea.setFocus()
        # +++ Reset correction flag +++
        self._correction_attempted = False
        self._updateStatusBar("Paste response, then click 'Parse & Validate'.", 5000); self._updateWidgetStates()

    # --- Parse & Validate (unchanged) ---
    @Slot()
    def _handleParseAndValidate(self: 'MainWindow') -> None:
        if self._isBusy: self._showWarning("Busy", "Task already running."); return
        llmResponse: str = self._llmResponseArea.toPlainText().strip()
        if not llmResponse: self._showError("Empty Response", "LLM Response area is empty."); return
        try: expectedFormat = self._configManager.getConfigValue('General', 'ExpectedOutputFormat', fallback='json') or 'json'
        except ConfigurationError as e: self._showError("Config Error", f"Could not read format: {e}"); return
        logger.info(f"Requesting parse & validate (format: {expectedFormat})...")
        self._isBusy = True; self._updateWidgetStates(); self._updateStatusBar(f"Parsing ({expectedFormat})...")
        self._updateProgress(-1, f"Parsing {expectedFormat}..."); self._parsedFileData = None; self._validationErrors = None
        self._originalCodeArea.clear(); self._proposedCodeArea.clear()
        self._fileWorker.startParsing(llmResponse, expectedFormat)

    # --- Save Changes (unchanged) ---
    @Slot()
    def _handleSaveChanges(self: 'MainWindow') -> None:
        if self._isBusy: self._showWarning("Busy", "Task already running."); return
        if self._parsedFileData is None: self._showError("No Data", "Parse response first."); return
        if self._validationErrors: self._showError("Validation Errors", "Cannot save with validation errors."); return
        if not self._clonedRepoPath or not os.path.isdir(self._clonedRepoPath): self._showError("Invalid Path", "Repo path invalid."); return
        fileCount = len(self._parsedFileData);
        if fileCount == 0: self._showInfo("No Changes", "Parsed response indicated no changes."); return
        reply = QMessageBox.question(self, 'Confirm Save', f"Overwrite {fileCount} file(s) in\n'{self._clonedRepoPath}'?", QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.Cancel, QMessageBox.StandardButton.Cancel)
        if reply == QMessageBox.StandardButton.Cancel: return
        logger.info(f"Requesting save of {fileCount} files..."); self._isBusy = True; self._updateWidgetStates(); self._updateStatusBar("Saving files..."); self._updateProgress(-1, "Saving files...")
        self._fileWorker.startSaving(self._clonedRepoPath, self._parsedFileData)

    # --- Commit & Push (unchanged) ---
    @Slot()
    def _handleCommitPush(self: 'MainWindow') -> None:
        if self._isBusy: self._showWarning("Busy", "Task already running."); return
        if not self._clonedRepoPath or not os.path.isdir(self._clonedRepoPath): self._showError("Invalid Path", "Repo path invalid."); return
        try: self._repoIsDirty = self._githubHandlerInstance.isDirty(self._clonedRepoPath)
        except Exception as e: self._showError("Git Status Error", f"Could not check status: {e}"); return
        if not self._repoIsDirty: self._showInfo("No Changes", "No changes to commit."); self._updateWidgetStates(); return
        try: defaultMsg = self._configManager.getConfigValue('GitHub', 'DefaultCommitMessage', fallback="LLM Update")
        except ConfigurationError as e: self._showWarning("Config Warning", f"Could not read default commit msg: {e}"); defaultMsg = "LLM Update"
        commitMessage, ok = QInputDialog.getText(self, "Commit Message", "Enter commit message:", QLineEdit.EchoMode.Normal, defaultMsg)
        if not ok or not commitMessage.strip(): self._showWarning("Commit Cancelled", "Commit message empty or cancelled."); return
        commitMessage = commitMessage.strip()
        try: remote = self._configManager.getConfigValue('GitHub', 'DefaultRemoteName', fallback='origin') or 'origin'; branch = self._configManager.getConfigValue('GitHub', 'DefaultBranchName', fallback='main') or 'main'
        except ConfigurationError as e: self._showError("Config Error", f"Could not read Git settings: {e}"); return
        reply = QMessageBox.question(self, 'Confirm Commit & Push', f"Commit & Push to '{remote}/{branch}'?\nMsg: '{commitMessage}'", QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.Cancel, QMessageBox.StandardButton.Cancel)
        if reply == QMessageBox.StandardButton.Cancel: return
        logger.info(f"Requesting commit/push..."); self._isBusy = True; self._updateWidgetStates(); self._updateStatusBar("Commit/Push..."); self._updateProgress(-1, "Commit/Push...")
        self._githubWorker.startCommitPush(self._clonedRepoPath, commitMessage, remote, branch)

    # --- Worker Thread Callback Slots ---
    @Slot(int, str)
    def _updateProgress(self: 'MainWindow', value: int, message: str) -> None: # Unchanged
        if not self._isBusy: self._progressBar.setVisible(False); return; self._progressBar.setVisible(True)
        if value == -1: self._progressBar.setRange(0, 0); self._progressBar.setFormat(message or "Working...")
        elif 0 <= value <= 100: self._progressBar.setRange(0, 100); self._progressBar.setValue(value); self._progressBar.setFormat(f"{message} (%p%)" if message else "%p%")
        else: self._progressBar.setVisible(False); self._progressBar.setRange(0, 100); self._progressBar.setValue(0); self._progressBar.setFormat("%p%")
        if message: self._updateStatusBar(message)
    @Slot(str, list)
    def _onCloneFinished(self: 'MainWindow', repoPath: str, fileList: list) -> None: # Unchanged
        logger.info(f"Clone/Load finished successfully. Path: {repoPath}, Files: {len(fileList)}"); self._isBusy = False; self._clonedRepoPath = repoPath; self._parsedFileData = None; self._validationErrors = None; self._originalFileContents.clear(); self._llmResponseArea.clear(); self._originalCodeArea.clear(); self._proposedCodeArea.clear(); self._saveLastRepoPath(repoPath); self._updateStatusBar(f"Repo loaded ({len(fileList)} files). Checking status...", 5000); self._fileListWidget.clear(); self._fileListWidget.addItems(sorted(fileList))
        if not self._isBusy and self._clonedRepoPath: self._isBusy = True; self._updateWidgetStates(); self._updateProgress(-1, "Checking status..."); self._githubWorker.startIsDirty(self._clonedRepoPath)
        else: logger.warning("Cannot start dirty check after clone/load."); self._updateWidgetStates()
    @Slot(bool)
    def _onIsDirtyFinished(self: 'MainWindow', is_dirty: bool) -> None: # Unchanged
        logger.info(f"Repository dirty status check completed: {is_dirty}"); self._repoIsDirty = is_dirty; self._isBusy = False; status_msg = "Repo status: Dirty" if is_dirty else "Repo status: Clean"; self._updateStatusBar(status_msg, 5000); self._updateProgress(100, "Status check complete."); self._updateWidgetStates()

    # --- MODIFIED: LLM Finished - Handle Correction Response ---
    @Slot(str)
    def _onLlmFinished(self: 'MainWindow', response: str) -> None:
        """Handles the successful response from the LLM query, including correction attempts."""
        logger.info(f"LLM query finished. Response length: {len(response)}")
        self._isBusy = False; self._updateProgress(100, "LLM query complete.")
        self._llmResponseArea.setPlainText(response); # Always display the latest response
        self._parsedFileData = None; self._validationErrors = None
        self._proposedCodeArea.clear() # Clear proposed diff until parsed
        self._displaySelectedFileDiff(self._fileListWidget.currentItem(), None) # Show original against blank proposed

        if self._correction_attempted:
            # This was the response to a correction request
            self._updateStatusBar("LLM correction received. Parsing corrected response...", 10000)
            # Automatically trigger parsing again
            self._handleParseAndValidate() # This will use the new content in _llmResponseArea
        else:
            # This was the response to the initial query
            self._updateStatusBar("LLM query successful. Click 'Parse & Validate'.", 5000)
            self._updateWidgetStates() # Update state now that response is available

    # --- MODIFIED: Parsing Finished - Clear correction flag ---
    @Slot(dict, dict)
    def _onParsingFinished(self: 'MainWindow', parsedData: Dict[str, str], validationResults: Dict[str, List[str]]) -> None:
        """Handles the result of parsing and validation."""
        logger.info(f"Parsing finished. Parsed items: {len(parsedData)}. Validation Errors: {len(validationResults)}")
        self._isBusy = False
        self._parsedFileData = parsedData
        self._validationErrors = validationResults if validationResults else None
        # +++ Clear correction flag after successful parse (even if validation failed) +++
        # Because we won't retry again for this specific response
        # self._correction_attempted = False # --> Moved reset to _handleFileProcessingError success path

        if self._validationErrors:
            log_message = ["--- Validation Failed ---"]; error_files = []
            for file_path, errors in self._validationErrors.items(): error_files.append(os.path.basename(file_path)); log_message.append(f"  File: {file_path}");
            for error in errors: log_message.append(f"    * {error}")
            log_message.append("-------------------------"); self._appendLogMessage("\n".join(log_message))
            error_summary = f"Validation failed for {len(self._validationErrors)} file(s).\nCheck Application Log tab for details.\n\nFiles with errors:\n - " + "\n - ".join(error_files)
            self._showWarning("Code Validation Failed", error_summary); status_msg = f"Response parsed. Validation FAILED ({len(self._validationErrors)} file(s))."
        else:
            status_msg = f"Response parsed ({len(parsedData)} files found). Validation OK.";
            if not parsedData: status_msg = "Response parsed: No changes found. Validation OK."
            self._appendLogMessage("--- Validation OK ---")
            # +++ Clear correction flag ONLY on successful validation +++
            # This allows retry if correction attempt *also* results in invalid JSON/structure later
            self._correction_attempted = False


        self._updateStatusBar(status_msg, 10000); self._updateProgress(100, "Parse & Validate complete.")
        current_files = set(self._fileListWidget.item(i).text() for i in range(self._fileListWidget.count())); new_files_added = False
        for filePath in sorted(parsedData.keys()):
            if filePath not in current_files: self._fileListWidget.addItem(QListWidgetItem(filePath)); new_files_added = True
        if new_files_added: self._fileListWidget.sortItems()
        self._displaySelectedFileDiff(self._fileListWidget.currentItem(), None)
        self._updateWidgetStates()

    @Slot(list)
    def _onSavingFinished(self: 'MainWindow', savedFiles: list) -> None: # Unchanged
        logger.info(f"Saving finished successfully. Saved files: {len(savedFiles)}"); self._isBusy = False; self._updateStatusBar(f"Changes saved locally ({len(savedFiles)} files).", 5000); self._updateProgress(100, "Saving complete.")
        if savedFiles:
            self._showInfo("Save Successful", f"{len(savedFiles)} file(s) saved/updated in\n'{self._clonedRepoPath}'."); self._repoIsDirty = True
            if self._parsedFileData:
                for saved_path in savedFiles:
                    if saved_path in self._parsedFileData: self._originalFileContents[saved_path] = self._parsedFileData[saved_path]
            self._parsedFileData = None; self._validationErrors = None; self._displaySelectedFileDiff(self._fileListWidget.currentItem(), None)
        else: logger.info("Saving finished, but no files were saved.")
        self._updateWidgetStates()
    @Slot(str)
    def _onCommitPushFinished(self: 'MainWindow', message: str) -> None: # Unchanged
        logger.info(f"Commit/Push finished: {message}"); self._isBusy = False; self._updateStatusBar("Commit/push successful.", 5000); self._updateProgress(100, "Commit/Push complete."); self._showInfo("Commit/Push Successful", message); self._repoIsDirty = False; self._originalCodeArea.clear(); self._proposedCodeArea.clear(); self._parsedFileData = None; self._validationErrors = None; self._updateWidgetStates()
    @Slot(str, bool)
    def _onPullFinished(self: 'MainWindow', message: str, had_conflicts: bool) -> None: # Unchanged
        logger.info(f"Pull finished: {message}, Conflicts: {had_conflicts}"); self._isBusy = False; self._updateStatusBar(f"Pull finished. {message}", 10000); self._updateProgress(100, "Pull complete.")
        if had_conflicts: self._showWarning("Pull Conflicts", f"Pull completed, but conflicts likely occurred.\n{message}\nPlease resolve conflicts manually."); self._repoIsDirty = True
        else:
            self._showInfo("Pull Finished", message)
            if self._clonedRepoPath and not self._isBusy: self._isBusy = True; self._updateWidgetStates(); self._updateStatusBar("Checking status after pull...", 5000); self._updateProgress(-1, "Checking status..."); self._githubWorker.startIsDirty(self._clonedRepoPath); return
            elif self._clonedRepoPath: logger.warning("Could not re-check dirty status after pull."); self._repoIsDirty = False
        self._updateWidgetStates()

    # --- Error Handling Slots ---
    @Slot(str)
    def _handleWorkerError(self: 'MainWindow', errorMessage: str) -> None: # Unchanged
        logger.critical(f"Unexpected worker thread error: {errorMessage}"); self._resetTaskState(); self._showError("Unexpected Background Task Error", f"A critical internal error occurred:\n{errorMessage}"); self._appendLogMessage(f"CRITICAL ERROR: {errorMessage}")
    @Slot(str)
    def _handleGitHubError(self: 'MainWindow', errorMessage: str) -> None: # Unchanged
        logger.error(f"GitHub operation failed: {errorMessage}"); is_load_error = any(s in errorMessage.lower() for s in ["clone", "load", "not found", "authentication failed", "valid git repo"]); self._resetTaskState(); self._showError("GitHub Error", errorMessage)
        if is_load_error: self._clonedRepoPath = None; self._fileListWidget.clear(); self._repoIsDirty = False; self._originalFileContents.clear(); self._parsedFileData = None; self._validationErrors = None; self._originalCodeArea.clear(); self._proposedCodeArea.clear(); self._updateWidgetStates()
        self._appendLogMessage(f"GIT ERROR: {errorMessage}")
    @Slot(str)
    def _handleLLMError(self: 'MainWindow', errorMessage: str) -> None: # Unchanged
        logger.error(f"LLM operation failed: {errorMessage}"); self._resetTaskState(); self._showError("LLM/Config Error", errorMessage); self._llmResponseArea.setPlainText(f"LLM Error:\n{errorMessage}"); self._appendLogMessage(f"LLM ERROR: {errorMessage}")

    # --- MODIFIED: Handle File Processing Error to Trigger Retry ---
    @Slot(str)
    def _handleFileProcessingError(self: 'MainWindow', errorMessage: str) -> None:
        """Handles file processing errors, potentially triggering an LLM correction retry."""
        logger.error(f"File processing failed: {errorMessage}")
        self._isBusy = False # Task finished (with error)

        # Check if it's a parsing error and if we haven't tried correcting yet
        # Use a simple string check for "ParsingError:" prefix added in FileWorker
        is_parsing_error = errorMessage.startswith("ParsingError:")
        can_retry = not self._correction_attempted

        if is_parsing_error and can_retry:
            logger.warning("Initial parsing failed. Attempting LLM self-correction.")
            self._correction_attempted = True # Mark that we are trying now
            self._updateStatusBar("Initial parsing failed. Requesting LLM correction...", 0) # Persistent message
            self._appendLogMessage(f"PARSE ERROR: {errorMessage}. Requesting LLM correction...")
            self._updateProgress(-1, "Requesting correction...")
            self._isBusy = True # Set busy again for the correction call
            self._updateWidgetStates()

            try:
                original_bad_response = self._llmResponseArea.toPlainText() # Get the full bad response
                original_instruction = self._promptInput.toPlainText() # Get original instruction
                expected_format = self._configManager.getConfigValue('General', 'ExpectedOutputFormat', fallback='json') or 'json'
                model_name = self._configManager.getConfigValue('General', 'DefaultLlmModel', fallback='gemini-pro') or 'gemini-pro'

                # Build the correction prompt
                correction_prompt = self._llmInterfaceInstance.build_correction_prompt(
                    original_bad_output=original_bad_response,
                    original_instruction=original_instruction,
                    expected_format=expected_format
                )

                # Trigger LLMWorker with correction task and lower temperature
                self._llmWorker.startCorrectionQuery(model_name, correction_prompt, CORRECTION_RETRY_TEMPERATURE)
                # Don't call _resetTaskState or _showError here, wait for correction result

            except Exception as e:
                # Error during the setup for the correction call itself
                logger.critical(f"Failed to initiate LLM correction query: {e}", exc_info=True)
                self._resetTaskState() # Reset state after this internal error
                self._showError("Correction Error", f"Could not initiate LLM correction attempt: {e}")
                self._appendLogMessage(f"CRITICAL: Failed to start correction query: {e}")
                self._correction_attempted = False # Allow trying again if user manually edits + parses

        else:
            # Not a parsing error, or correction already attempted - show original error
            self._resetTaskState()
            self._showError("File Processing Error", errorMessage)
            # Clear potentially invalid parsed data if error occurred after parsing started
            if is_parsing_error:
                self._parsedFileData = None; self._validationErrors = None
                self._originalCodeArea.clear(); self._proposedCodeArea.clear()
                self._updateWidgetStates()
            self._appendLogMessage(f"FILE/PARSE ERROR (Final): {errorMessage}")

    # --- Utility Methods (unchanged) ---
    def _updateWidgetStates(self: 'MainWindow') -> None:
        repoLoaded = self._clonedRepoPath is not None and os.path.isdir(self._clonedRepoPath); responseAvailable = bool(self._llmResponseArea.toPlainText().strip()); parsedDataAvailable = self._parsedFileData is not None; parsedDataHasContent = parsedDataAvailable and len(self._parsedFileData) > 0; validationPassed = parsedDataAvailable and self._validationErrors is None; repoIsActuallyDirty = repoLoaded and self._repoIsDirty; enabledIfNotBusy = not self._isBusy
        self._repoUrlInput.setEnabled(enabledIfNotBusy); self._browseButton.setEnabled(enabledIfNotBusy); self._cloneButton.setEnabled(enabledIfNotBusy); self._fileListWidget.setEnabled(enabledIfNotBusy and repoLoaded); self._promptInput.setEnabled(enabledIfNotBusy and repoLoaded); self._sendToLlmButton.setEnabled(enabledIfNotBusy and repoLoaded); self._pasteResponseButton.setEnabled(enabledIfNotBusy); self._llmResponseArea.setEnabled(enabledIfNotBusy)
        self._parseButton.setEnabled(enabledIfNotBusy and responseAvailable); self._saveFilesButton.setEnabled(enabledIfNotBusy and parsedDataHasContent and repoLoaded and validationPassed); self._commitPushButton.setEnabled(enabledIfNotBusy and repoLoaded and repoIsActuallyDirty)
    def _resetTaskState(self: 'MainWindow') -> None:
        self._isBusy = False; self._correction_attempted = False # Also reset correction flag
        self._updateWidgetStates(); self._updateProgress(0, "Task finished or failed."); self._updateStatusBar("Idle.")
    def _updateStatusBar(self: 'MainWindow', message: str, timeout: int = 0) -> None:
        if self._statusBar: self._statusBar.showMessage(message, timeout)
    def _showError(self: 'MainWindow', title: str, message: str) -> None: logger.error(f"{title}: {message}"); QMessageBox.critical(self, title, message)
    def _showWarning(self: 'MainWindow', title: str, message: str) -> None: logger.warning(f"{title}: {message}"); QMessageBox.warning(self, title, message)
    def _showInfo(self: 'MainWindow', title: str, message: str) -> None: logger.info(f"Info Dialog: {title} - {message}"); QMessageBox.information(self, title, message)
    @Slot(str)
    def _appendLogMessage(self: 'MainWindow', message: str) -> None:
        if self._appLogArea: self._appLogArea.append(message)
    @Slot(int)
    def _syncScrollProposedFromOriginal(self, value: int) -> None:
        if not self._is_syncing_scroll: self._is_syncing_scroll = True; self._proposedCodeArea.verticalScrollBar().setValue(value); self._is_syncing_scroll = False
    @Slot(int)
    def _syncScrollOriginalFromProposed(self, value: int) -> None:
        if not self._is_syncing_scroll: self._is_syncing_scroll = True; self._originalCodeArea.verticalScrollBar().setValue(value); self._is_syncing_scroll = False
    def _syncScrollbars(self) -> None:
        if not self._is_syncing_scroll: self._is_syncing_scroll = True; orig_val = self._originalCodeArea.verticalScrollBar().value(); self._proposedCodeArea.verticalScrollBar().setValue(orig_val); self._is_syncing_scroll = False
    def closeEvent(self: 'MainWindow', event) -> None:
        # Default to Yes if not busy
        reply = QMessageBox.StandardButton.Yes
        
        if self._isBusy:
            reply = QMessageBox.question(
                self, 'Confirm Exit',
                "A background task is running. Exit anyway?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.Cancel,
                QMessageBox.StandardButton.Cancel
            )
                
        if reply == QMessageBox.StandardButton.Cancel:
            event.ignore()
            return
            
        logger.info("Attempting graceful shutdown...")
        workers = [self._githubWorker, self._llmWorker, self._fileWorker]
        
        for worker in workers:
            if worker and worker.isRunning():
                worker.quit()
                worker.wait(1500)
                
        logger.info("Shutdown complete.")
        super().closeEvent(event)

## gui/__init__.py ##



## gui/widgets/__init__.py ##



## docs/__init__.py ##



## core/config_manager.py ##

# Updated Codebase/core/config_manager.py
# --- START: core/config_manager.py ---
# core/config_manager.py
"""
Manages loading and accessing application configuration from various sources.
Prioritises environment variables (via .env file) for secrets,
and uses a configuration file (config.ini) for non-sensitive settings.
Includes functionality to save configuration changes back to the .ini file.
"""

import os
import configparser
from dotenv import load_dotenv
from typing import Optional, Any, List # Import List
import logging

# Relative import within the same package - ensure project structure allows this
# If running scripts directly within core/, this might fail. Run from project root.
from .exceptions import ConfigurationError

# Get a logger instance specific to this module
logger: logging.Logger = logging.getLogger(__name__)

class ConfigManager:
	"""
	Handles loading and providing access to configuration parameters.
	Loads from .env files and .ini files, and allows saving changes to .ini.
	"""
	_config: configparser.ConfigParser
	_envLoaded: bool
	_configLoaded: bool
	_configLoadAttempted: bool # Track if loadConfig was called
	_configLoadError: Optional[Exception] = None # Store load error
	_envFilePath: Optional[str]
	_configFilePath: Optional[str]

	def __init__(self: 'ConfigManager', configFilePath: Optional[str] = 'config.ini', envFilePath: Optional[str] = '.env') -> None:
		"""
		Initialises the ConfigManager.

		Args:
			configFilePath (Optional[str]): Path to the .ini configuration file.
			envFilePath (Optional[str]): Path to the .env file for environment variables.
		"""
		# Use interpolation=None to disable interpolation globally for this parser instance
		self._config = configparser.ConfigParser(interpolation=None)
		self._envLoaded = False
		self._configLoaded = False
		self._configLoadAttempted = False
		self._configLoadError = None
		self._envFilePath = envFilePath
		self._configFilePath = configFilePath
		logger.debug(f"ConfigManager initialised with config file: '{configFilePath}', env file: '{envFilePath}'")

	def loadEnv(self: 'ConfigManager', override: bool = False) -> bool:
		"""
		Loads environment variables from the .env file specified during initialisation.
		Existing environment variables will NOT be overwritten unless override is True.

		Args:
			override (bool): Whether to override existing system environment variables
							 with values from the .env file. Defaults to False.

		Returns:
			bool: True if the .env file was found and loaded successfully, False otherwise.

		Raises:
			ConfigurationError: If there's an OS error checking or processing the .env file.
		"""
		if not self._envFilePath:
			logger.info("No .env file path specified. Skipping loading from .env file.")
			return False
		try:
			if os.path.exists(self._envFilePath):
				logger.info(f"Loading environment variables from: {self._envFilePath}")
				load_dotenv_success = load_dotenv(dotenv_path=self._envFilePath, override=override, verbose=True)
				self._envLoaded = load_dotenv_success
				if not load_dotenv_success:
					logger.warning(f".env file found at '{self._envFilePath}' but `load_dotenv` returned False. File might be empty or have format issues.")
				else:
					logger.debug(f"Successfully processed environment variables from {self._envFilePath}.")
				return self._envLoaded
			else:
				logger.warning(f".env file not found at specified path: {self._envFilePath}. Skipping.")
				return False
		except Exception as e:
			logger.error(f"Failed to load .env file from '{self._envFilePath}': {e}", exc_info=True)
			raise ConfigurationError(f"Error processing .env file '{self._envFilePath}': {e}") from e

	def loadConfig(self: 'ConfigManager') -> None:
		"""
		Loads configuration settings from the .ini file specified during initialisation.

		Raises:
			ConfigurationError: If the specified .ini file exists but is unreadable or has parsing errors.
		"""
		self._configLoadAttempted = True
		self._configLoaded = False
		self._configLoadError = None

		if not self._configFilePath:
			logger.info("No configuration file path specified. Relying on defaults or environment variables.")
			return

		try:
			if os.path.exists(self._configFilePath):
				logger.info(f"Loading configuration from: {self._configFilePath}")
				# Re-initialize parser with interpolation disabled
				self._config = configparser.ConfigParser(interpolation=None)
				readFiles: List[str] = self._config.read(self._configFilePath, encoding='utf-8')
				if not readFiles:
					err_msg = f"Config file exists at '{self._configFilePath}' but could not be read or parsed by configparser."
					logger.error(err_msg)
					self._configLoadError = ConfigurationError(err_msg)
					raise self._configLoadError
				self._configLoaded = True
				logger.debug(f"Successfully loaded configuration from {self._configFilePath}")
			else:
				logger.warning(f"Configuration file not found: {self._configFilePath}. Proceeding without it.")
		except configparser.Error as e:
			logger.error(f"Failed to parse configuration file '{self._configFilePath}': {e}", exc_info=True)
			self._configLoadError = e
			raise ConfigurationError(f"Error parsing config file '{self._configFilePath}': {e}") from e
		except Exception as e:
			logger.error(f"Failed to read configuration file '{self._configFilePath}': {e}", exc_info=True)
			self._configLoadError = e
			raise ConfigurationError(f"Error reading config file '{self._configFilePath}': {e}") from e

	def getEnvVar(self: 'ConfigManager', varName: str, defaultValue: Optional[str] = None, required: bool = False) -> Optional[str]:
		"""
		Retrieves an environment variable.

		Args:
			varName (str): The name of the environment variable.
			defaultValue (Optional[str]): The value to return if the variable is not found (and not required).
			required (bool): If True, raises ConfigurationError if the variable is not set.

		Returns:
			Optional[str]: The value of the environment variable, or the defaultValue.

		Raises:
			ConfigurationError: If required=True and the environment variable is not found.
		"""
		value = os.getenv(varName)
		if value is None:
			if required:
				errMsg = f"Required environment variable '{varName}' is not set."
				logger.error(errMsg)
				raise ConfigurationError(errMsg)
			return defaultValue
		return value

	# --- CORRECTED getConfigValue ---
	def getConfigValue(self: 'ConfigManager', section: str, key: str, fallback: Optional[Any] = None, required: bool = False) -> Optional[Any]:
		"""
		Retrieves a configuration value from the loaded .ini file, disabling interpolation.

		Args:
			section (str): The section name in the .ini file.
			key (str): The key name within the section.
			fallback (Optional[Any]): Value to return if key/section not found (and not required). Defaults to None.
			required (bool): If True, raises ConfigurationError if value not found. Defaults to False.

		Returns:
			Optional[Any]: The raw configuration value (as string), or fallback.

		Raises:
			ConfigurationError: If required and value not found, or if config failed to load earlier.
		"""
		if self._configLoadAttempted and not self._configLoaded and self._configLoadError:
			err_ctx = f"config file '{self._configFilePath}' failed to load properly earlier."
			logger.error(f"Attempted to get config value '{section}/{key}' but {err_ctx}")
			raise ConfigurationError(f"Cannot retrieve config value; configuration file '{self._configFilePath}' failed to load. Error: {self._configLoadError}") from self._configLoadError

		valueExists = self._configLoaded and self._config.has_section(section) and self._config.has_option(section, key)

		if required and not valueExists:
			errMsg = f"Required configuration value '{key}' not found in section '{section}'."
			# Add context about file status
			if self._configFilePath:
				try:
					file_exists_check = os.path.isfile(self._configFilePath)
				except Exception: file_exists_check = False
				if file_exists_check and self._configLoaded: errMsg += f" Checked in '{self._configFilePath}'."
				elif file_exists_check and not self._configLoaded: errMsg += f" Config file '{self._configFilePath}' exists but failed to load (Error: {self._configLoadError})."
				else: errMsg += f" Config file '{self._configFilePath}' not found or not accessible."
			elif self._configLoadAttempted: errMsg += " No config file path was specified, or load was attempted without a path."
			else: errMsg += " Configuration was not loaded."
			logger.error(errMsg)
			raise ConfigurationError(errMsg)

		if valueExists:
			try:
				# Use get with raw=True to disable interpolation
				# Note: If ConfigParser was init with interpolation=None, raw=True is redundant but safe.
				value = self._config.get(section, key, fallback=None, raw=True)
				# Remove potential inline comments manually if needed (raw=True doesn't handle this)
				if value is not None and isinstance(value, str):
						if '#' in value: value = value.split('#', 1)[0].strip()
						if ';' in value: value = value.split(';', 1)[0].strip()
				logger.debug(f"Accessed raw config value '{section}/{key}'. Value: '{value}'")
				return value
			except (configparser.NoSectionError, configparser.NoOptionError) as e:
				# Should not happen if valueExists is True, handle defensively
				logger.error(f"Internal error retrieving existing raw config value '{section}/{key}': {e}")
				raise ConfigurationError(f"Internal error: Could not get raw config value '{section}/{key}' despite checks.") from e
		else:
			logger.debug(f"Raw config value '{section}/{key}' not found, using fallback: {fallback}")
			return fallback
	# --- END CORRECTION ---

	# --- Convenience methods (no changes needed here, they use the corrected getConfigValue) ---
	def getConfigValueInt(self: 'ConfigManager', section: str, key: str, fallback: Optional[int] = None, required: bool = False) -> Optional[int]:
		valueStr = self.getConfigValue(section, key, fallback=None, required=required)
		if valueStr is None: return fallback
		try:
			return int(valueStr)
		except (ValueError, TypeError) as e:
			errMsg = f"Configuration value '{section}/{key}' ('{valueStr}') is not a valid integer."
			logger.error(errMsg)
			raise ConfigurationError(errMsg) from e

	def getConfigValueBool(self: 'ConfigManager', section: str, key: str, fallback: Optional[bool] = None, required: bool = False) -> Optional[bool]:
		valueStr = self.getConfigValue(section, key, fallback=None, required=required)
		if valueStr is None: return fallback
		valueLower = valueStr.strip().lower()
		if valueLower in ['true', 'yes', 'on', '1']: return True
		if valueLower in ['false', 'no', 'off', '0']: return False
		errMsg = f"Configuration value '{section}/{key}' ('{valueStr}') is not a valid boolean (use 1/yes/true/on or 0/no/false/off)."
		logger.error(errMsg)
		raise ConfigurationError(errMsg)

	def getConfigValueFloat(self: 'ConfigManager', section: str, key: str, fallback: Optional[float] = None, required: bool = False) -> Optional[float]:
		valueStr = self.getConfigValue(section, key, fallback=None, required=required)
		if valueStr is None: return fallback
		try:
			return float(valueStr)
		except (ValueError, TypeError) as e:
			errMsg = f"Configuration value '{section}/{key}' ('{valueStr}') is not a valid float."
			logger.error(errMsg)
			raise ConfigurationError(errMsg) from e

	# --- NEW: Method to save config changes ---
	def setConfigValue(self: 'ConfigManager', section: str, key: str, value: str) -> None:
		"""
		Sets a configuration value in memory and attempts to save it back to the .ini file.

		Args:
			section (str): The section name in the .ini file.
			key (str): The key name within the section.
			value (str): The string value to set.

		Raises:
			ConfigurationError: If the configuration file path is not set, if the config
								was not loaded successfully, or if there's an error writing
								the file.
		"""
		if not self._configFilePath:
			errMsg = "Cannot save configuration: No configuration file path was specified during initialisation."
			logger.error(errMsg)
			raise ConfigurationError(errMsg)

		if not self._configLoaded and self._configLoadError:
			errMsg = f"Cannot save configuration: The configuration file '{self._configFilePath}' failed to load initially. Error: {self._configLoadError}"
			logger.error(errMsg)
			raise ConfigurationError(errMsg) from self._configLoadError
		elif not self._configLoaded and not self._configLoadAttempted:
			# If config wasn't loaded because it didn't exist, allow creating/saving.
			logger.info(f"Config file '{self._configFilePath}' was not loaded (likely didn't exist). Will attempt to create/save.")
			# Ensure the parser is initialised
			if not self._config: self._config = configparser.ConfigParser(interpolation=None)


		try:
			# Ensure the section exists in the config object
			if not self._config.has_section(section):
				logger.debug(f"Adding new section '{section}' to configuration.")
				self._config.add_section(section)

			# Set the value in the config object
			logger.debug(f"Setting config value in memory: [{section}] {key} = {value}")
			self._config.set(section, key, value)

			# Write the entire configuration back to the file
			logger.info(f"Saving configuration changes to: {self._configFilePath}")
			with open(self._configFilePath, 'w', encoding='utf-8') as configfile:
				self._config.write(configfile)
			logger.debug(f"Successfully saved configuration to {self._configFilePath}")
			# Mark config as loaded if it wasn't before (e.g., file created)
			self._configLoaded = True
			self._configLoadError = None # Clear any previous load error

		except configparser.Error as e: # Errors during section creation or setting
			errMsg = f"Error updating configuration in memory for [{section}] {key}: {e}"
			logger.error(errMsg, exc_info=True)
			raise ConfigurationError(errMsg) from e
		except IOError as e: # Errors during file writing
			errMsg = f"Failed to write configuration file '{self._configFilePath}': {e}"
			logger.error(errMsg, exc_info=True)
			raise ConfigurationError(errMsg) from e
		except Exception as e: # Catch any other unexpected errors
			errMsg = f"An unexpected error occurred while saving configuration: {e}"
			logger.error(errMsg, exc_info=True)
			raise ConfigurationError(errMsg) from e
	# --- END NEW METHOD ---

	# --- Properties (Unchanged) ---
	@property
	def isEnvLoaded(self: 'ConfigManager') -> bool:
		return self._envLoaded

	@property
	def isConfigLoaded(self: 'ConfigManager') -> bool:
		return self._configLoaded

# --- END: core/config_manager.py ---

## core/exceptions.py ##

# --- START: core/exceptions.py ---
# core/exceptions.py
"""
Defines custom exception classes for specific error conditions within the application.
This allows for more granular error handling and reporting.
"""

# Adhering to user preference for explicit initialisation (though less common for classes)
# Using standard Exception inheritance which is Pythonic.

class BaseApplicationError(Exception):
	"""
	Base class for all custom application-specific exceptions.
	Provides a common ancestor for catching application-related errors.
	"""
	def __init__(self: 'BaseApplicationError', message: str = "An application error occurred.") -> None:
		"""
		Initialises the BaseApplicationError.

		Args:
			message (str): A descriptive message for the error.
		"""
		super().__init__(message)


class ConfigurationError(BaseApplicationError):
	"""
	Raised for errors encountered during loading, parsing, or accessing
	configuration settings (e.g., missing keys, invalid formats).
	"""
	def __init__(self: 'ConfigurationError', message: str = "Configuration error.") -> None:
		"""
		Initialises the ConfigurationError.

		Args:
			message (str): A descriptive message specific to the configuration issue.
		"""
		super().__init__(message)


class GitHubError(BaseApplicationError):
	"""
	Raised for errors related to interacting with Git repositories or the GitHub API.
	Examples include cloning failures, authentication issues, command execution errors,
	network problems during Git operations.
	"""
	def __init__(self: 'GitHubError', message: str = "GitHub interaction error.") -> None:
		"""
		Initialises the GitHubError.

		Args:
			message (str): A descriptive message specific to the Git/GitHub issue.
		"""
		super().__init__(message)


class LLMError(BaseApplicationError):
	"""
	Raised for errors encountered while interacting with the Large Language Model API.
	Examples include API key errors, network issues, rate limits, content safety blocks,
	or unexpected responses from the LLM service.
	"""
	def __init__(self: 'LLMError', message: str = "LLM interaction error.") -> None:
		"""
		Initialises the LLMError.

		Args:
			message (str): A descriptive message specific to the LLM API issue.
		"""
		super().__init__(message)


class ParsingError(BaseApplicationError):
	"""
	Raised for errors during the parsing of structured data, typically the LLM response.
	Examples include failing to find the expected code block, invalid JSON/YAML/XML format,
	or incorrect data structure within the parsed response.
	"""
	def __init__(self: 'ParsingError', message: str = "Parsing error.") -> None:
		"""
		Initialises the ParsingError.

		Args:
			message (str): A descriptive message specific to the parsing issue.
		"""
		super().__init__(message)


class FileProcessingError(BaseApplicationError):
	"""
	Raised for errors related to file system operations, such as reading from or
	writing to files during the processing stages.
	Examples include permission denied errors, disk full errors, file not found (when expected),
	or issues creating directories.
	"""
	def __init__(self: 'FileProcessingError', message: str = "File processing error.") -> None:
		"""
		Initialises the FileProcessingError.

		Args:
			message (str): A descriptive message specific to the file system operation issue.
		"""
		super().__init__(message)

# TODO: Consider adding more specific sub-exceptions if needed (e.g., GitHubAuthError, LLMApiKeyError).
# --- END: core/exceptions.py ---

## core/file_processor.py ##

# core/file_processor.py
"""
Handles processing related to file content generated by the LLM.
Includes extracting structured data (e.g., JSON) from the LLM response
and writing updated file contents to the local disk with enhanced path validation.
"""

import logging
import json
import os
import re # For regex fallback
from typing import Dict, Optional, List, Any, Union # Added Union

# Try importing yaml for type checking if available, but don't require it globally
try:
    import yaml
    PYYAML_AVAILABLE = True
except ImportError:
    PYYAML_AVAILABLE = False
    yaml = None # Ensure yaml is None if import fails

from .exceptions import ParsingError, FileProcessingError

logger: logging.Logger = logging.getLogger(__name__)

# Define potentially problematic characters for filenames/paths (OS-dependent subset)
# Allows C:\... but flags file:name.txt or other colons.
# Updated regex to disallow colons unless it's the second character (drive letter)
# Disallows '*', '?', '"', '<', '>', '|', null byte '\0', and ':' unless it follows a drive letter at the start.
INVALID_PATH_CHARS_REGEX = re.compile(r'[*?"<>|\0]|(?<!^[a-zA-Z]):')


class FileProcessor:
    """
    Provides methods for parsing LLM output and saving generated file content.
    """
    def __init__(self: 'FileProcessor') -> None:
        """Initialises the FileProcessor."""
        logger.debug("FileProcessor initialised.")
        # No specific configuration needed at initialisation for now.

    def extractCodeBlock(self: 'FileProcessor', llmResponse: str, language: str = 'json') -> Optional[str]:
        """
        Extracts the content of the first fenced code block (e.g., ```json ... ``` or ```python ... ```)
        from the LLM's response string. Uses improved line-based searching and regex fallbacks.

        It prioritizes finding a block matching the specified `language`. If not found,
        it falls back to finding the *first* fenced code block regardless of its language tag.

        Args:
            llmResponse (str): The raw response string from the LLM.
            language (str): The preferred language identifier of the code block (e.g., 'json', 'yaml').
                            Defaults to 'json'. If the specific language block isn't found,
                            it will look for any other fenced block. If language is an empty string,
                            it specifically looks for blocks without any language tag (```\n...\n```).

        Returns:
            Optional[str]: The extracted content within the code block (excluding fences),
                           or None if no fenced code block is found.
        """
        logger.debug(f"Attempting to extract '{language or 'generic/any'}' code block...")
        if not llmResponse: return None

        lines: List[str] = llmResponse.splitlines()
        startFencePrefixSpecific: Optional[str] = f"```{language.lower()}" if language else None
        startFenceGenericPrefix: str = "```"
        endFence: str = "```"
        foundBlockType: Optional[str] = None
        startLineIndex: int = -1
        endLineIndex: int = -1

        # --- Primary Method: Line-based search ---
        # 1. Try specific language fence first if a language is specified
        if startFencePrefixSpecific:
            for i, line in enumerate(lines):
                stripped_line_lower = line.strip().lower()
                # Check if line starts with ```language and has nothing or only whitespace after it
                if stripped_line_lower.startswith(startFencePrefixSpecific) and \
                   (len(stripped_line_lower) == len(startFencePrefixSpecific) or stripped_line_lower[len(startFencePrefixSpecific):].isspace()):
                    startLineIndex = i
                    foundBlockType = language # Found the specifically requested language
                    logger.debug(f"Found specific language fence '```{language}' at line {i+1}.")
                    break # Found the preferred block, stop searching

        # 2. If specific not found (or not requested), search for *any* code block fence (``` or ```otherlang)
        #    This handles cases where the LLM might use a different tag (e.g., ```python) even if 'json' was expected.
        if startLineIndex == -1:
            for i, line in enumerate(lines):
                stripped_line = line.strip()
                if stripped_line.startswith(startFenceGenericPrefix):
                    # Check if it's just ``` or ``` followed by something
                    potential_lang = stripped_line[len(startFenceGenericPrefix):].strip()
                    # Check if the rest of the line is empty or whitespace (or a language tag)
                    if potential_lang or len(stripped_line) == len(startFenceGenericPrefix):
                        # If language='' was specifically requested (meaning ```\n), skip blocks with tags.
                        if language == '' and potential_lang:
                            logger.debug(f"Skipping block with language '{potential_lang}' at line {i+1} because generic (no tag) block was requested.")
                            continue

                        # Found a generic block (```) or a block with a different language tag.
                        startLineIndex = i
                        foundBlockType = potential_lang if potential_lang else 'generic' # Store what was found
                        logger.debug(f"Found first available code block fence ('```{foundBlockType}') at line {i+1} (fallback).")
                        break # Found the first available block, stop searching

        # Find the corresponding end fence
        if startLineIndex != -1:
            for i in range(startLineIndex + 1, len(lines)):
                if lines[i].strip() == endFence:
                    endLineIndex = i
                    break

        # Extract content if a complete block was found by line search
        if startLineIndex != -1 and endLineIndex != -1 and endLineIndex > startLineIndex:
            blockContentLines = lines[startLineIndex+1:endLineIndex]
            extractedContent = "\n".join(blockContentLines).strip()
            # Determine log message based on what was found vs requested
            log_block_type_msg = f"'{foundBlockType}'"
            if language and foundBlockType != language.lower():
                log_block_type_msg += f" (found via fallback, '{language}' requested)"
            elif not language and foundBlockType != 'generic':
                 log_block_type_msg += f" (found via fallback, generic/any requested)"
            elif foundBlockType == 'generic':
                 log_block_type_msg += " (no language tag)"

            logger.info(f"Successfully extracted code block {log_block_type_msg} using line search. Length: {len(extractedContent)}")
            return extractedContent
        else:
            # --- Fallback Method: Regex ---
            # Log warning only if line search looked promising (found start) but failed to find end
            if startLineIndex != -1 and endLineIndex == -1:
                logger.warning(f"Found start fence '```{foundBlockType or ''}' but no end fence using line search. Attempting regex fallback...")
            else:
                logger.debug("Could not find any code block fence using line search. Attempting regex fallback...")


            extractedContent: Optional[str] = None
            # Regex 1: Try specific language first (if specified)
            # Use re.IGNORECASE for the language tag in the regex
            if language:
                lang_pattern_re = re.escape(language)
                # Pattern: ``` optional_whitespace LANGUAGE optional_whitespace optional_newline CONTENT optional_newline ```
                pattern_re_specific = rf"```{re.escape(language)}\s*\n?(.*?)\n?\s*```"
                flags_re = re.DOTALL | re.IGNORECASE # DOTALL allows '.' to match newlines, IGNORECASE for language tag
                match = re.search(pattern_re_specific, llmResponse, flags_re)
                if match:
                    extractedContent = match.group(1).strip()
                    logger.info(f"Successfully extracted '{language}' code block using specific regex fallback. Length: {len(extractedContent)}")
                    return extractedContent

            # Regex 2: Generic block (matches ``` or ```any_language) - This is the main fallback
            if extractedContent is None:
                # Pattern: ``` optional_whitespace [optional language tag] optional_whitespace newline CONTENT ```
                pattern_re_generic = r"```\h*(?:[\w\-]+)?\h*\s*\n?(.*?)\n?\s*```"
                flags_re = re.DOTALL # DOTALL is crucial here
                match = re.search(pattern_re_generic, llmResponse, flags_re)
                if match:
                    extractedContent = match.group(1).strip()
                    # Try to determine the language tag found by the regex for logging
                    full_match_text = match.group(0)
                    first_line = full_match_text.split('\n', 1)[0]
                    lang_tag_found = first_line.strip()[3:].strip() or 'generic (no tag)'

                    log_block_type_msg = f"'{lang_tag_found}'"
                    if language and lang_tag_found != language.lower():
                         log_block_type_msg += f" (found via generic regex fallback, '{language}' requested)"
                    elif not language and lang_tag_found != 'generic (no tag)':
                         log_block_type_msg += f" (found via generic regex fallback, generic/any requested)"

                    logger.info(f"Successfully extracted code block {log_block_type_msg} using generic regex fallback. Length: {len(extractedContent)}")
                    return extractedContent

            # If neither line search nor regex worked
            logger.error(f"Could not find any fenced code block (```...```) using any method. Language requested: '{language or 'generic/any'}'.")
            return None


    def _is_safe_relative_path(self: 'FileProcessor', path: Optional[str]) -> bool:
        """
        Validates if a given path string is a safe relative path component.
        Checks for non-strings, empty strings, absolute paths (Unix, Windows, UNC),
        directory traversal ('..'), and problematic characters.

        Args:
            path (Optional[str]): The path string to validate.

        Returns:
            bool: True if the path is considered safe, False otherwise.
        """
        if not isinstance(path, str) or not path.strip():
            logger.warning(f"Path validation failed: Path is not a non-empty string (received: {repr(path)}).")
            return False
        path = path.strip()
        if os.path.isabs(path):
            logger.warning(f"Path validation failed: Path '{path}' appears absolute (os.path.isabs).")
            return False
        if path.startswith('\\\\') or path.startswith('//'):
            logger.warning(f"Path validation failed: Path '{path}' appears to be a UNC path.")
            return False
        # Check for potential drive letters without being absolute (e.g., "C:file.txt" - invalid relative path)
        # Allows "C:\..." (caught by isabs) but flags "C:file"
        if len(path) > 1 and path[1] == ':' and path[0].isalpha() and not os.path.isabs(path):
            logger.warning(f"Path validation failed: Path '{path}' appears to be a drive-relative path (e.g., 'C:file').")
            return False
        try:
            # Normalize path separators to '/' for consistent '..' check
            normalized_path = os.path.normpath(path.replace('\\', '/'))
            # Check for '..' components in the normalized path segments
            if '..' in normalized_path.split('/') or normalized_path.startswith('../') or normalized_path == '..':
                logger.warning(f"Path validation failed: Path '{path}' contains '..' component (checked after normalization: '{normalized_path}').")
                return False
        except (ValueError, TypeError) as e: # Catch errors during normalization (e.g., null bytes)
            logger.warning(f"Path validation failed: Error normalizing path '{path}' for traversal check: {e}")
            return False
        # Check for other invalid characters using regex
        invalid_char_match = INVALID_PATH_CHARS_REGEX.search(path)
        if invalid_char_match:
            invalid_char = invalid_char_match.group(0)
            logger.warning(f"Path validation failed: Path '{path}' contains invalid character ({repr(invalid_char)}).")
            return False
        return True

    # --- UPDATED parseStructuredOutput ---
    def parseStructuredOutput(self: 'FileProcessor', structuredDataString: Optional[str], format: str = 'json') -> Dict[str, str]:
        """
        Parses the extracted structured data string (e.g., JSON, YAML) into a dictionary.
        Validates that the output is a dictionary mapping safe relative filenames (str)
        to content (str), allowing for content nested within a {"content": "..."} dictionary.
        Includes fallback logic for attempting to parse JSON even if surrounded by other text.
        Provides enhanced error messages for JSON parsing failures.

        Args:
            structuredDataString (Optional[str]): The raw string extracted from the LLM response,
                                                  expected to contain the structured data.
            format (str): The expected format ('json' or 'yaml'). Defaults to 'json'.

        Returns:
            Dict[str, str]: A dictionary mapping validated relative file paths to their content strings.

        Raises:
            ParsingError: If the string cannot be parsed, if the structure is invalid (not dict,
                          unsafe keys, invalid value types), or if the format is unsupported.
            NotImplementedError: If the requested format is not 'json' or 'yaml'.
        """
        if not structuredDataString:
            logger.info("Received empty or None structured data string. Returning empty dictionary.")
            return {}
        structuredDataString = structuredDataString.strip()
        if not structuredDataString:
            logger.info("Received whitespace-only structured data string. Returning empty dictionary.")
            return {}

        logger.info(f"Parsing structured output as '{format}'. Length: {len(structuredDataString)}")
        parsedData: Any

        try:
            # --- Parsing Logic (with JSON fallback) ---
            if format == 'json':
                try:
                    parsedData = json.loads(structuredDataString)
                except json.JSONDecodeError as e:
                    # Fallback logic for JSON surrounded by text
                    logger.warning(f"Initial JSON parsing failed ({e.msg} at char {e.pos}). Attempting JSON extraction fallback...")
                    potential_json = None
                    try:
                        # Try finding the outermost curly braces or square brackets
                        first_brace = structuredDataString.find('{')
                        first_bracket = structuredDataString.find('[')
                        start_index = -1
                        start_char = ''
                        end_char = ''

                        # Determine the starting character and index
                        if first_brace != -1 and (first_bracket == -1 or first_brace < first_bracket):
                            start_index = first_brace
                            start_char = '{'
                            end_char = '}'
                        elif first_bracket != -1:
                            start_index = first_bracket
                            start_char = '['
                            end_char = ']'
                        else:
                            # Neither '{' nor '[' found, cannot extract
                            start_index = -1


                        if start_index != -1:
                            # Find the matching closing bracket/brace, considering nesting
                            nesting_level = 0
                            end_index = -1
                            for i in range(start_index, len(structuredDataString)):
                                char = structuredDataString[i]
                                if char == start_char: # Opening char
                                    nesting_level += 1
                                elif char == end_char: # Closing char
                                    nesting_level -= 1
                                    if nesting_level == 0:
                                        end_index = i
                                        break # Found the matching end
                            if end_index != -1:
                                potential_json = structuredDataString[start_index : end_index + 1]
                                logger.debug(f"Fallback extracted potential JSON substring from index {start_index} to {end_index}.")
                            else:
                                logger.warning(f"Fallback found opening '{start_char}' at index {start_index} but no matching closing '{end_char}'.")
                                potential_json = None
                        else:
                             logger.warning("Fallback could not find starting '{' or '[' in the string.")
                             potential_json = None

                    except Exception as fallback_err: # Catch errors during the fallback logic itself
                        logger.error(f"Error during JSON fallback extraction logic: {fallback_err}", exc_info=True)
                        potential_json = None

                    # Try parsing the extracted substring if found
                    if potential_json:
                        logger.debug("Attempting to parse content found by fallback logic...")
                        try:
                            parsedData = json.loads(potential_json)
                            logger.info("Successfully parsed JSON using fallback extraction logic.")
                        except json.JSONDecodeError as inner_e:
                            # Parsing the extracted part also failed
                            errMsg = (f"Invalid JSON detected: {e.msg} (at char {e.pos}). "
                                      f"Attempting to parse extracted content also failed: {inner_e.msg} (at char {inner_e.pos}). "
                                      f"Check LLM response format.")
                            logger.error(errMsg, exc_info=False) # Log original and inner error details
                            # Optionally include a snippet of the failed string for debugging
                            snippet = structuredDataString[max(0, e.pos-15):e.pos+15]
                            logger.error(f"    Nearby text (original): ...{snippet}...")
                            snippet_inner = potential_json[max(0, inner_e.pos-15):inner_e.pos+15]
                            logger.error(f"    Nearby text (extracted): ...{snippet_inner}...")
                            raise ParsingError(errMsg) from inner_e
                    else:
                        # Fallback couldn't find markers or extract a substring
                        errMsg = (f"Invalid JSON detected: {e.msg} (at char {e.pos}). "
                                  f"Could not find valid JSON object/array markers using fallback logic. "
                                  f"Check LLM response format.")
                        logger.error(errMsg, exc_info=False)
                        snippet = structuredDataString[max(0, e.pos-15):e.pos+15]
                        logger.error(f"    Nearby text: ...{snippet}...")
                        raise ParsingError(errMsg) from e

            elif format == 'yaml':
                # YAML Parsing
                if not PYYAML_AVAILABLE or yaml is None:
                    errMsg = "Parsing format 'yaml' requested, but PyYAML library is not installed. Install it (`pip install pyyaml`)."
                    logger.error(errMsg)
                    raise ParsingError(errMsg)
                # Add try-except for yaml parsing errors
                try:
                    parsedData = yaml.safe_load(structuredDataString)
                except yaml.YAMLError as e:
                    errMsg = f"Invalid YAML detected: {e}. Check LLM response format."
                    if hasattr(e, 'problem_mark'):
                        errMsg += f" Error near line {e.problem_mark.line + 1}, column {e.problem_mark.column + 1}."
                    logger.error(errMsg, exc_info=False)
                    raise ParsingError(errMsg) from e
            else:
                raise NotImplementedError(f"Parsing for format '{format}' is not implemented.")

            # --- Structure and Value Validation ---
            if parsedData is None:
                # Handle cases where parsing results in None (e.g., empty YAML string)
                logger.warning(f"Parsing result for '{format}' was None (input might have been empty or only comments). Returning empty dictionary.")
                return {}
            if not isinstance(parsedData, dict):
                errMsg = f"Parsed data is not a dictionary as expected. Found type: {type(parsedData).__name__}"
                logger.error(errMsg)
                raise ParsingError(errMsg)

            validatedData: Dict[str, str] = {}
            for key, value in parsedData.items():
                # Validate Key (File Path)
                if not isinstance(key, str):
                    errMsg = f"Invalid structure: Dictionary key {repr(key)} (type: {type(key).__name__}) is not a string."
                    logger.error(errMsg)
                    raise ParsingError(errMsg)
                if not self._is_safe_relative_path(key):
                    # Error message generated within _is_safe_relative_path
                    errMsg = f"Invalid structure: Dictionary key '{key}' is not a safe relative path."
                    # Raise error here to stop processing
                    raise ParsingError(errMsg) # _is_safe_relative_path already logged details

                # Validate and Extract Value (File Content)
                file_content_str: Optional[str] = None
                if isinstance(value, str):
                    # Original expected format: value is the content string directly
                    file_content_str = value
                elif isinstance(value, dict) and 'content' in value and isinstance(value['content'], str):
                    # New format: value is dict with a 'content' string key
                    file_content_str = value['content']
                    logger.debug(f"Extracted content for '{key}' from nested dictionary.")
                    # Optionally log or use value.get('operation') here if needed
                else:
                    # Invalid value type
                    errMsg = f"Invalid structure: Value for key '{key}' is not a string or a dictionary with a 'content' string (type: {type(value).__name__})."
                    logger.error(errMsg)
                    raise ParsingError(errMsg)

                validatedData[key] = file_content_str # Store the extracted content string

            logger.info(f"Successfully parsed and validated '{format}' data. Found {len(validatedData)} file entries.")
            return validatedData

        # --- Exception Handling ---
        except (json.JSONDecodeError, yaml.YAMLError) as e: # Catch parsing errors again if missed during fallback/validation
            # This shouldn't be reached if the logic above is correct, but handle defensively.
            error_type = type(e).__name__
            errMsg = f"Invalid {format.upper()} detected during final check: {e}. Check LLM response format."
            logger.error(errMsg, exc_info=False) # Log less detail here as it should have been caught earlier
            raise ParsingError(errMsg) from e
        except NotImplementedError as e:
            logger.error(str(e))
            raise e # Re-raise
        except ParsingError as e:
            # Re-raise specific parsing errors from validation steps
            raise e
        except Exception as e:
            # Catch any other unexpected errors during parsing/validation
            errMsg = f"An unexpected error occurred during parsing/validation of {format} data: {e}"
            logger.error(errMsg, exc_info=True)
            raise ParsingError(errMsg) from e
    # --- END UPDATE ---

    def saveFilesToDisk(self: 'FileProcessor', outputDir: str, fileData: Dict[str, str]) -> List[str]:
        """
        Saves the file contents from the parsed dictionary to the specified output directory.
        Performs rigorous path validation before writing. Creates necessary subdirectories
        and overwrites existing files.

        Args:
            outputDir (str): The base directory (e.g., the cloned repo path) where files should be saved.
                             Must be an existing directory.
            fileData (Dict[str, str]): The dictionary mapping validated relative file paths to their content.

        Returns:
            List[str]: A list of the relative paths of the files that were successfully saved.

        Raises:
            FileProcessingError: If `outputDir` is not a valid directory, if any relative path
                                 fails safety checks during this stage, or if there are errors
                                 creating directories or writing files (e.g., permissions).
        """
        logger.info(f"Saving {len(fileData)} files to base directory: {outputDir}")
        savedFilesList: List[str] = []

        if not isinstance(outputDir, str) or not outputDir.strip():
            errMsg = "Output directory path must be a non-empty string."
            logger.error(errMsg)
            raise FileProcessingError(errMsg)
        outputDir = outputDir.strip()

        try:
            # Resolve symlinks etc. for the output directory path
            resolvedOutputDir = os.path.realpath(outputDir)
        except OSError as e:
            errMsg = f"Could not resolve real path for output directory '{outputDir}': {e}"
            logger.error(errMsg)
            raise FileProcessingError(errMsg) from e

        # Check if the resolved path exists and is actually a directory
        if not os.path.isdir(resolvedOutputDir):
            errMsg = f"Resolved output directory '{resolvedOutputDir}' (from '{outputDir}') does not exist or is not a directory."
            logger.error(errMsg)
            raise FileProcessingError(errMsg)

        if not fileData:
            logger.info("Received empty file data dictionary. No files to save.")
            return []

        for relativePath, content in fileData.items():
            # --- Final path validation just before writing ---
            # 1. Re-validate the relative path component itself (redundant if parseStructuredOutput is reliable, but safe)
            if not self._is_safe_relative_path(relativePath):
                # This indicates an internal issue if it wasn't caught during parsing.
                errMsg = f"Skipping file due to unsafe relative path discovered just before saving: '{relativePath}'"
                logger.critical(errMsg + ". This should have been caught during parsing.") # Log as critical
                raise FileProcessingError(errMsg) # Stop processing

            # 2. Construct the full path and perform critical safety check
            try:
                # Combine and normalize path using the *resolved* output directory
                # os.path.join is usually safe, but normpath cleans '..' etc.
                fullPath_normalized = os.path.normpath(os.path.join(resolvedOutputDir, relativePath))

                # Critical Check: Resolve the *candidate* full path and ensure it's still within the intended output directory.
                # This prevents issues if the relativePath contains tricky sequences like symlinks or components
                # that os.path.join/normpath might not fully mitigate in all edge cases across OSes.
                resolvedFullPath = os.path.realpath(fullPath_normalized)

                # Ensure the resolved path starts with the resolved output directory path.
                # Add os.sep to base path for reliable prefix checking (avoids matching /base/dir against /base/dir-other)
                base_check_path = os.path.join(resolvedOutputDir, '') # Ensures trailing separator

                if not resolvedFullPath.startswith(base_check_path):
                    context = f"resolves outside base directory ('{resolvedOutputDir}')"
                    errMsg = (f"Path validation failed for '{relativePath}'. "
                              f"Target '{resolvedFullPath}' {context}. Aborting save for safety.")
                    logger.critical(errMsg)
                    raise FileProcessingError(errMsg)

                # Also prevent writing directly *onto* the base directory itself (e.g., if relativePath was empty or '.')
                if resolvedFullPath == resolvedOutputDir:
                     errMsg = (f"Path validation failed for '{relativePath}'. "
                               f"Attempting to write directly onto the base directory '{resolvedOutputDir}'. Aborting save.")
                     logger.critical(errMsg)
                     raise FileProcessingError(errMsg)

            except OSError as e: # Catch errors during realpath resolution or checks
                errMsg = f"OS error resolving or checking final path for '{relativePath}' within '{resolvedOutputDir}': {e}"
                logger.error(errMsg)
                raise FileProcessingError(errMsg) from e
            except Exception as e: # Catch any other unexpected validation errors
                errMsg = f"Unexpected error validating final path for '{relativePath}': {e}"
                logger.error(errMsg, exc_info=True)
                raise FileProcessingError(errMsg) from e

            # --- Proceed to save ---
            logger.debug(f"Validated path. Preparing to save file: {resolvedFullPath}")
            try:
                # Get the directory part of the final path
                fileDir: str = os.path.dirname(resolvedFullPath)

                # Create necessary subdirectories only if needed (don't try to create the base dir itself)
                if fileDir != resolvedOutputDir and not os.path.isdir(fileDir):
                    os.makedirs(fileDir, exist_ok=True) # exist_ok=True prevents error if dir already exists (e.g., race condition)
                    logger.debug(f"Ensured directory exists: {fileDir}")

                # Write the file content (overwrite if exists) using UTF-8 encoding
                with open(resolvedFullPath, 'w', encoding='utf-8') as fileHandle:
                    fileHandle.write(content)

                savedFilesList.append(relativePath) # Append the original relative path
                logger.debug(f"Successfully wrote file: {resolvedFullPath} (relative: {relativePath})")

            except OSError as e:
                # Catch errors during makedirs or file writing (permissions, disk full, etc.)
                errMsg = f"OS error writing file '{resolvedFullPath}' (relative: '{relativePath}'): {e}"
                logger.error(errMsg, exc_info=True)
                # Stop on the first write error to prevent partial writes
                raise FileProcessingError(errMsg) from e
            except Exception as e:
                # Catch any other unexpected errors during file saving
                errMsg = f"An unexpected error occurred saving file '{resolvedFullPath}' (relative: '{relativePath}'): {e}"
                logger.error(errMsg, exc_info=True)
                # Stop on the first write error
                raise FileProcessingError(errMsg) from e

        logger.info(f"Successfully saved {len(savedFilesList)} files.")
        return savedFilesList

# --- END: core/file_processor.py ---

## core/github_handler.py ##

# Updated Codebase/core/github_handler.py
# --- START: core/github_handler.py ---
# core/github_handler.py
"""
Handles interactions with Git repositories, including cloning, pulling, listing files,
reading file content, staging, committing, and pushing changes.
Uses the GitPython library.

This module facilitates communication with local and remote Git repositories,
encapsulating operations like cloning, file access, and state modification.
Includes enhanced error handling and pre-checks for operations like pushing.
Adds progress reporting capability for clone operations.
"""
import git # Import the git library
import os
import logging
from typing import List, Optional, Tuple, Any, Dict # Use Tuple for branch status, Any for progress handler, ADDED Dict
# FIX: Import QObject, Signal, Slot explicitly
from PySide6.QtCore import QObject, Signal, Slot

# Relative import from the 'core' package for custom exceptions
from .exceptions import GitHubError

# Logger instance specific to this module for targeted logging
logger: logging.Logger = logging.getLogger(__name__)


# --- Signal Emitter Helper Class (for Composition) ---
class _SignalEmitter(QObject):
	"""Internal QObject solely for emitting signals from the progress handler."""
	# Signal format: progressUpdate(percentage, message)
	# Percentage: 0-100, or -1 for indeterminate stages
	# Message: Text description of the current stage/progress
	progressUpdate = Signal(int, str)

	def __init__(self: '_SignalEmitter', parent: Optional[QObject] = None) -> None:
		"""Initialise the signal emitter."""
		super().__init__(parent)

# --- Progress Handler Class ---
class GitProgressHandler(git.remote.RemoteProgress):
	"""
	Custom progress handler for GitPython operations (like clone).
	Inherits from RemoteProgress for GitPython integration and uses composition
	with a QObject (_SignalEmitter) to emit Qt signals for updating the GUI,
	avoiding multiple C-extension inheritance conflicts.
	"""

	# Keep a reference to the signal emitter
	# Corrected type hint for _emitter
	_emitter: Optional[_SignalEmitter]

	_last_percentage: Optional[int] = None
	# Using Dict type hint requires importing it from typing
	_stage_map: Dict[int, str] = {
		git.remote.RemoteProgress.BEGIN: "Connecting",
		git.remote.RemoteProgress.CHECKING_OUT: "Checking out files",
		git.remote.RemoteProgress.COMPRESSING: "Compressing objects",
		git.remote.RemoteProgress.COUNTING: "Counting objects",
		git.remote.RemoteProgress.END: "Finalising",
		git.remote.RemoteProgress.FINDING_SOURCES: "Finding sources",
		git.remote.RemoteProgress.RECEIVING: "Receiving objects",
		git.remote.RemoteProgress.RESOLVING: "Resolving deltas",
		git.remote.RemoteProgress.WRITING: "Writing objects",
		# Add pull stages if known/different, otherwise reuse generic ones
		# git.FetchInfo.HEAD_UPTODATE: "Checking status", # Example, might not be exact stage
	}

	def __init__(self: 'GitProgressHandler', parent_qobject: Optional[QObject] = None) -> None:
		"""
		Initialise GitProgressHandler.

		Args:
			parent_qobject (Optional[QObject]): An optional parent QObject for the internal signal emitter.
		"""
		# Initialise the RemoteProgress base class
		super().__init__()
		# Create and store the internal signal emitter
		self._emitter = _SignalEmitter(parent=parent_qobject)
		self._last_percentage = None

	# Getter for the actual signal (needed for connections)
	@property
	def progressUpdateSignal(self: 'GitProgressHandler') -> Signal:
		"""Provides access to the progressUpdate signal of the internal emitter."""
		if self._emitter:
			return self._emitter.progressUpdate
		# Return a dummy signal or raise error if emitter not initialised (shouldn't happen)
		# For simplicity, assume emitter is always created in __init__
		# If robustness is needed, handle self._emitter being None.
		raise RuntimeError("GitProgressHandler internal signal emitter not initialised.")

	# This method is called by GitPython, NOT decorated with @Slot
	def update(self: 'GitProgressHandler', op_code: int, cur_count: Any, max_count: Any = None, message: str = '') -> None:
		"""
		Callback method called by GitPython during remote operations (clone, fetch, pull).
		Processes the progress information and emits a signal via the internal emitter.

		Args:
			op_code (int): Code indicating the current operation stage (e.g., BEGIN, COUNTING).
			cur_count (Any): Current progress count (often float or int).
			max_count (Any, optional): Maximum progress count (often float or int). Defaults to None.
			message (str, optional): Additional progress message. Defaults to ''.
		"""
		stage_mask = op_code & git.remote.RemoteProgress.STAGE_MASK
		# Use specific op_code name if stage is 0 (often for messages)
		stage: str = self._stage_map.get(op_code if stage_mask == 0 else stage_mask, "Processing")
		# op_name: str = self._stage_map.get(op_code, "") # Get specific operation if no stage mask

		percentage: int = -1 # Default to indeterminate

		# Try converting counts to numbers for percentage calculation
		try:
			current = float(cur_count) if cur_count is not None else 0
			maximum = float(max_count) if max_count is not None else 0
			if maximum > 0:
				percentage = int((current / maximum) * 100)
			elif op_code & git.remote.RemoteProgress.BEGIN:
				percentage = 0
			elif op_code & git.remote.RemoteProgress.END:
				percentage = 100
		except (ValueError, TypeError):
			# If conversion fails, keep percentage indeterminate
			percentage = -1

		# Ensure percentage is within bounds or indeterminate
		if not (0 <= percentage <= 100):
			percentage = -1

		# Construct a meaningful status message
		status_message = f"{stage}: {message}".strip()
		if not message: # If no specific message, just use stage name
				status_message = stage

		# Only emit signal if percentage or message actually changes significantly
		# to avoid flooding the GUI event loop. Emit always for BEGIN/END.
		# Also emit if percentage is different from last emitted percentage
		# Only emit END once
		if op_code & git.remote.RemoteProgress.END and self._last_percentage == 100:
			return # Avoid duplicate END signals
		if (op_code & (git.remote.RemoteProgress.BEGIN | git.remote.RemoteProgress.END)) or \
		   (percentage != self._last_percentage):
			# Ensure percentage is clamped 0-100 for END signal consistency
			if op_code & git.remote.RemoteProgress.END:
				percentage = 100

			# Emit signal using the internal emitter
			if self._emitter:
				self._emitter.progressUpdate.emit(percentage, status_message)
			else:
				# Fallback or logging if emitter somehow isn't there
				logger.error("GitProgressHandler cannot emit signal: internal emitter not found.")

			self._last_percentage = percentage if not (op_code & git.remote.RemoteProgress.END) else None # Reset last % after END
			logger.debug(f"Git Progress: {percentage}% - {status_message}") # Optional debug log

# --- GitHub Handler Class ---
class GitHubHandler:
	"""
	Provides methods to interact with Git repositories locally and remotely.

	Encapsulates Git operations using the GitPython library, offering a
	structured interface for cloning, pulling, file access, and repository updates.
	Includes enhanced error handling for common Git issues and pre-checks.
	"""
	# No specific __init__ needed currently
	# def __init__(self: 'GitHubHandler') -> None:
	#     """Initialises the GitHubHandler."""
	#     logger.debug("GitHubHandler initialised.")


	def cloneRepository(
		self: 'GitHubHandler',
		repoUrlOrPath: str,
		localPath: str,
		authToken: Optional[str] = None, # authToken is informational only
		progress_handler: Optional[GitProgressHandler] = None # Add progress handler arg
	) -> git.Repo:
		"""
		Clones a Git repository from a URL or initialises from a local path.

		If `localPath` already exists and is a valid Git repository, it loads the
		existing repository. If the path exists but is not a repository or is
		empty, it attempts to clone into it. Relies on Git's configured credential
		management (helpers, SSH keys) for authentication. Provides progress updates
		via the optional `progress_handler`.

		Args:
			repoUrlOrPath (str): The URL of the repository to clone (e.g.,
								 'https://github.com/user/repo.git') or the path
								 to an existing local repository.
			localPath (str): The target local directory path where the repository
							 should be cloned or where it already exists.
			authToken (Optional[str]): Informational only. If provided for an HTTPS URL,
									   a warning is logged suggesting use of a credential
									   manager instead of direct token handling.
			progress_handler (Optional[GitProgressHandler]): An instance of GitProgressHandler
															 to receive progress updates.

		Returns:
			git.Repo: The Repo object representing the cloned or loaded repository.

		Raises:
			GitHubError: If cloning or loading fails due to various reasons,
						 including invalid URL/path, authentication issues (with
						 enhanced messaging), network problems, Git command errors,
						 or file system permission errors.
		"""
		logger.info(f"Attempting to clone/load repo '{repoUrlOrPath}' into '{localPath}'")

		try:
			# Case 1: Check if localPath is already a valid Git repository
			if os.path.isdir(localPath) and os.path.exists(os.path.join(localPath, '.git')):
				logger.info(f"'{localPath}' exists and appears to be a Git repository. Loading existing repo.")
				# Use progress_handler.update directly if available, otherwise emit via signal
				if progress_handler and hasattr(progress_handler, '_emitter'):
					progress_handler._emitter.progressUpdate.emit(0, "Loading existing repository...")
				try:
					repo: git.Repo = git.Repo(localPath)
					logger.info(f"Successfully loaded existing repository from '{localPath}'.")
					if progress_handler and hasattr(progress_handler, '_emitter'):
						progress_handler._emitter.progressUpdate.emit(50, "Fetching remote updates...")
					# Perform a fetch after loading to update remote refs (useful for push pre-check)
					try:
						logger.debug(f"Fetching updates from remotes for '{localPath}'...")
						for remote in repo.remotes:
							# Pass progress handler to fetch if needed (more complex setup)
							# Fetch with prune=True to remove remote-tracking branches that no longer exist on remote
							remote.fetch(prune=True, progress=progress_handler) # Pass progress
						logger.debug("Fetch successful.")
					except git.GitCommandError as fetch_err:
						# Log warning but don't fail the load operation
						logger.warning(f"Could not fetch updates after loading repo: {getattr(fetch_err, 'stderr', fetch_err)}")
					except Exception as fetch_err_generic:
						# Log warning but don't fail the load operation
						logger.warning(f"Unexpected error during fetch after loading repo: {fetch_err_generic}")

					if progress_handler and hasattr(progress_handler, '_emitter'):
						progress_handler._emitter.progressUpdate.emit(100, "Repository loaded.")
					return repo
				except git.InvalidGitRepositoryError as e:
					errMsg: str = f"Directory '{localPath}' exists but is not a valid Git repository: {e}"
					logger.error(errMsg)
					raise GitHubError(errMsg) from e
				except Exception as e: # Catch other potential git.Repo errors
					errMsg: str = f"Error loading existing repository from '{localPath}': {e}"
					logger.error(errMsg, exc_info=True)
					raise GitHubError(errMsg) from e

			# Case 2: localPath does not exist or is an empty directory - proceed with cloning
			# Check if the input was actually a local path that turned out *not* to be a repo
			# We infer this if repoUrlOrPath and localPath are the same *and* the previous check failed
			if repoUrlOrPath == localPath:
				# If the input path was the target path, and we determined it's not a valid repo, raise an error.
				errMsg = f"The specified local path '{localPath}' exists but is not a valid Git repository. Please select a valid repository or clone from a URL."
				logger.error(errMsg)
				raise GitHubError(errMsg)
			
			logger.info(f"Path '{localPath}' is not an existing valid repository. Proceeding with clone.")
			if progress_handler and hasattr(progress_handler, '_emitter'):
				progress_handler._emitter.progressUpdate.emit(0, "Preparing to clone...")
			# Ensure the parent directory exists before attempting to clone
			parentDir: str = os.path.dirname(localPath)
			if parentDir and not os.path.exists(parentDir):
				try:
					logger.debug(f"Creating parent directory: {parentDir}")
					os.makedirs(parentDir, exist_ok=True) # exist_ok=True prevents error if dir exists
				except OSError as e:
					errMsg = f"Failed to create parent directory '{parentDir}' for clone target '{localPath}': {e}"
					logger.error(errMsg)
					raise GitHubError(errMsg) from e

			cloneUrl: str = repoUrlOrPath

			# --- Authentication Warning/Info ---
			if authToken and cloneUrl.startswith("https://"):
				logger.warning("An auth token was provided, but direct token injection into HTTPS URLs is insecure and disabled.")
				logger.warning("Cloning will rely on Git's credential manager (e.g., git-credential-manager, osxkeychain).")
				logger.warning("Ensure a credential helper is configured if authentication is required.")
			elif cloneUrl.startswith("git@"):
				logger.info("Cloning via SSH protocol. Ensure SSH key is configured and accessible (e.g., via ssh-agent).")
			else: # http or other protocols
				logger.info(f"Cloning via {cloneUrl.split(':')[0]} protocol. Ensure Git credentials/config are appropriate.")


			logger.info(f"Cloning '{repoUrlOrPath}'...") # Log original URL for clarity

			# --- Execute Clone with Progress ---
			repo: git.Repo = git.Repo.clone_from(
				url=cloneUrl,
				to_path=localPath,
				progress=progress_handler # Pass progress handler here
			)
			logger.info(f"Repository successfully cloned into '{localPath}'.")
			# Progress handler should emit 100% / END signal
			return repo

		except git.GitCommandError as e:
			# Provide more specific feedback based on stderr content
			stderrOutput: str = getattr(e, 'stderr', "No stderr output.").strip()
			# Enhanced check for authentication failure
			if "Authentication failed" in stderrOutput or "could not read Username" in stderrOutput or "Permission denied" in stderrOutput:
				errMsg: str = f"Authentication failed for '{repoUrlOrPath}'. "
				if repoUrlOrPath.startswith("https://"):
					errMsg += "Ensure the repository is public, or check Git's credential manager configuration (e.g., git-credential-manager) and ensure valid credentials (like a PAT) are stored."
				elif repoUrlOrPath.startswith("git@"):
					errMsg += "Check your SSH key setup (key exists, correct permissions, added to ssh-agent, registered with Git host)."
				else: # Other protocols
					errMsg += "Check relevant credentials or network configuration."
				logger.error(errMsg)
				raise GitHubError(errMsg) from e
			elif "repository not found" in stderrOutput or "does not exist" in stderrOutput:
				errMsg: str = f"Repository '{repoUrlOrPath}' not found or access denied. Verify the URL and your permissions."
				logger.error(errMsg)
				raise GitHubError(errMsg) from e
			elif "already exists and is not an empty directory" in stderrOutput:
				# This error might occur if Case 1 check failed unexpectedly or race condition
				errMsg: str = f"Target directory '{localPath}' already exists and is not empty or not a valid Git repository. Please check the path or clear the directory if appropriate."
				logger.error(errMsg)
				raise GitHubError(errMsg) from e
			else:
				# Generic Git command error
				errMsg: str = f"Git command failed during clone/load: {e.command} - Status: {e.status}\nStderr: {stderrOutput}"
				logger.error(errMsg, exc_info=False) # Log less detail for common git errors
				raise GitHubError(errMsg) from e
		except Exception as e:
			# Catch other potential errors (network issues, invalid paths etc.)
			errMsg: str = f"An unexpected error occurred during clone/load: {e}"
			logger.error(errMsg, exc_info=True) # Log full trace for unexpected
			raise GitHubError(errMsg) from e

	def pullRepository(
		self: 'GitHubHandler',
		repoPath: str,
		remoteName: str = 'origin',
		branchName: str = 'main',
		progress_handler: Optional[GitProgressHandler] = None
	) -> Tuple[str, bool]:
		"""
		Pulls changes from the specified remote and branch into the local repository.

		Args:
			repoPath (str): The path to the local Git repository.
			remoteName (str): The name of the remote to pull from. Defaults to 'origin'.
			branchName (str): The name of the branch to pull. Defaults to 'main'.
			progress_handler (Optional[GitProgressHandler]): Handler for progress updates.

		Returns:
			Tuple[str, bool]: (message, had_conflicts)
							  A status message indicating the outcome (e.g., "Already up to date", "Pulled new commits").
							  A boolean indicating if conflicts likely occurred (True if repo is dirty after pull).

		Raises:
			GitHubError: If the repository is invalid, the remote/branch doesn't exist,
						 pulling fails due to network issues, authentication, or other Git errors.
		"""
		logger.info(f"Attempting to pull '{remoteName}/{branchName}' into '{repoPath}'")
		try:
			repo: git.Repo = git.Repo(repoPath)

			# Ensure local branch matches the one we intend to pull into
			# Handle detached HEAD state
			try:
				active_branch_name = repo.active_branch.name
			except TypeError as e:
				if "HEAD is a detached symbolic reference" in str(e):
					errMsg = f"Repository at '{repoPath}' is in a detached HEAD state. Cannot pull automatically. Please checkout a branch first (e.g., 'git checkout {branchName}')."
					logger.error(errMsg)
					raise GitHubError(errMsg) from e
				else: # Other unexpected TypeError
					errMsg = f"Could not determine active branch in '{repoPath}': {e}"
					logger.error(errMsg, exc_info=True)
					raise GitHubError(errMsg) from e

			if active_branch_name != branchName:
				logger.warning(f"Current active branch '{active_branch_name}' differs from target pull branch '{branchName}'. Pulling into '{branchName}' anyway.")
				# Consider checking out branchName first? For now, proceed.

			# Check if repository is dirty *before* pulling
			if self.isDirty(repoPath):
				errMsg = f"Repository '{repoPath}' has uncommitted changes. Please commit or stash them before pulling."
				logger.error(errMsg)
				raise GitHubError(errMsg)

			# Get the remote
			try:
				remote: git.Remote = repo.remote(name=remoteName)
			except ValueError:
				errMsg = f"Remote '{remoteName}' does not exist in the repository at '{repoPath}'. Cannot pull."
				logger.error(errMsg)
				raise GitHubError(errMsg)

			# Execute pull
			logger.debug(f"Executing pull from {remoteName}/{branchName}...")
			fetch_info_list: List[git.FetchInfo] = remote.pull(refspec=branchName, progress=progress_handler)

			# Analyse FetchInfo results (pull is essentially fetch + merge)
			status_messages: List[str] = []
			new_commits_pulled = False
			errors_found = False
			for info in fetch_info_list:
				# Simplified status interpretation
				if info.flags & git.FetchInfo.ERROR:
					errors_found = True
					status_messages.append(f"Error pulling {info.name or 'ref'}: {info.note or 'Unknown error'}")
				elif info.flags & git.FetchInfo.REJECTED:
					errors_found = True # Treat rejection as an error state for pulling
					status_messages.append(f"Pull rejected {info.name or 'ref'}: {info.note or 'Unknown reason'}")
				elif info.flags & git.FetchInfo.HEAD_UPTODATE:
					status_messages.append(f"Branch '{info.name or branchName}' already up-to-date.")
				elif info.flags & (git.FetchInfo.NEW_TAG | git.FetchInfo.NEW_HEAD | git.FetchInfo.FORCED_UPDATE | git.FetchInfo.FAST_FORWARD):
					new_commits_pulled = True
					status_messages.append(f"Pulled changes for '{info.name or branchName}'.") # Use branchName if info.name is None
				# Add other flags if needed, e.g., DELETED
				# else: # General status if flags are unexpected or 0
				#     status_messages.append(f"Pull status for '{info.name or 'ref'}': Flags={info.flags}, Note: {info.note}")

			# Consolidate messages
			if not status_messages:
				# If list is empty, it might still be okay (e.g., fetching branch already present)
				# Check if repo state suggests success or if fetch_info_list was truly empty
				final_message = "Pull completed. Repository likely up-to-date." # Assume okay if no errors/updates reported
			else:
				final_message = " ".join(status_messages)

			if errors_found:
				logger.error(f"Pull operation encountered errors: {final_message}")
				# Raise error if significant issues detected
				raise GitHubError(f"Pull operation failed: {final_message}")

			logger.info(f"Pull operation finished. Status: {final_message}")

			# Check dirty status *after* pulling to detect potential merge conflicts
			repo_is_dirty_after_pull = self.isDirty(repoPath)
			if repo_is_dirty_after_pull:
				logger.warning("Repository is dirty after pulling. Merge conflicts likely occurred. Manual resolution required.")
				final_message += " WARNING: Conflicts likely occurred, manual resolution needed."

			if progress_handler and hasattr(progress_handler, '_emitter'):
				progress_handler._emitter.progressUpdate.emit(100, "Pull complete.")
			return final_message, repo_is_dirty_after_pull

		except git.InvalidGitRepositoryError:
			errMsg = f"'{repoPath}' is not a valid Git repository."
			logger.error(errMsg)
			raise GitHubError(errMsg) from None
		except git.GitCommandError as e:
			stderrOutput: str = getattr(e, 'stderr', "No stderr output.").strip()
			# Check for specific pull-related errors
			if "You have unstaged changes" in stderrOutput or "Your local changes would be overwritten by merge" in stderrOutput:
				errMsg = f"Pull aborted: Repository has uncommitted changes that would be overwritten. Please commit or stash them first." # Simplified message
			elif "Authentication failed" in stderrOutput or "Permission denied" in stderrOutput:
				errMsg = f"Authentication failed during pull from '{remoteName}'. Check credentials/SSH keys."
			elif "could not resolve host" in stderrOutput.lower():
				errMsg = f"Network error during pull: Could not resolve host '{remoteName}'."
			elif "Connection timed out" in stderrOutput:
				errMsg = f"Network error during pull: Connection timed out."
			elif "fatal: refusing to merge unrelated histories" in stderrOutput:
				errMsg = "Pull failed: Refusing to merge unrelated histories. Ensure branches have common ancestry or use '--allow-unrelated-histories' manually if intended."
			elif "couldn't find remote ref" in stderrOutput:
				errMsg = f"Pull failed: Remote branch '{branchName}' likely does not exist on remote '{remoteName}'."
			else:
				errMsg = f"Git command failed during pull: {e.command} - Status: {e.status}\nStderr: {stderrOutput}"
			logger.error(errMsg, exc_info=False)
			raise GitHubError(errMsg) from e
		except GitHubError as e: # Re-raise GitHubErrors (e.g., dirty repo before pull)
			raise e
		except Exception as e:
			errMsg = f"An unexpected error occurred during pull: {e}"
			logger.error(errMsg, exc_info=True)
			raise GitHubError(errMsg) from e

	def listFiles(self: 'GitHubHandler', repoPath: str, excludeGitDir: bool = True) -> List[str]:
		"""
		Lists all files tracked by Git within the local repository.

		Uses the `git ls-files` command for efficiency, returning paths relative
		to the repository root.

		Args:
			repoPath (str): The file system path to the root of the local Git repository.
			excludeGitDir (bool): Whether to explicitly filter out any paths starting
								  with '.git/'. Defaults to True.

		Returns:
			List[str]: A list of relative file paths tracked by Git.

		Raises:
			GitHubError: If the `repoPath` is not a valid Git repository or if the
						 `git ls-files` command fails.
		"""
		logger.debug(f"Listing files in repository: {repoPath}")
		try:
			# Ensure the path points to a valid repository
			repo: git.Repo = git.Repo(repoPath)
			gitCmd: git.Git = repo.git
			# Execute 'git ls-files' to get tracked files
			trackedFilesStr: str = gitCmd.ls_files()
			# Split the output into a list of file paths
			fileList: List[str] = trackedFilesStr.splitlines()

			# Filter out '.git/' directory contents if requested
			if excludeGitDir:
				# Although ls-files usually doesn't list .git contents, filter just in case
				# Normalise separators for consistent check
				git_dir_prefix_unix = ".git/"
				git_dir_prefix_win = ".git\\"
				fileList = [f for f in fileList if not (f.startswith(git_dir_prefix_unix) or f.startswith(git_dir_prefix_win))]

			logger.info(f"Found {len(fileList)} tracked files in '{repoPath}'.")
			return fileList
		except git.InvalidGitRepositoryError:
			errMsg: str = f"'{repoPath}' is not a valid Git repository."
			logger.error(errMsg)
			raise GitHubError(errMsg) from None
		except git.GitCommandError as e:
			stderrOutput: str = getattr(e, 'stderr', "No stderr output.").strip()
			errMsg: str = f"Git command 'ls-files' failed in '{repoPath}': {stderrOutput}"
			logger.error(errMsg, exc_info=False)
			raise GitHubError(errMsg) from e
		except Exception as e:
			errMsg: str = f"An unexpected error occurred listing files in '{repoPath}': {e}"
			logger.error(errMsg, exc_info=True)
			raise GitHubError(errMsg) from e

	def readFileContent(self: 'GitHubHandler', repoPath: str, filePath: str) -> str:
		"""
		Reads the content of a specific file within the local repository.

		Constructs the full path and reads the file, attempting UTF-8 decoding.
		Includes path validation to prevent access outside the repository root.

		Args:
			repoPath (str): The path to the local Git repository root.
			filePath (str): The relative path of the file within the repository
							(e.g., 'src/main.py').

		Returns:
			str: The decoded content of the file as a string.

		Raises:
			GitHubError: If the repository path is invalid, the file does not exist,
						 the path attempts traversal, there's an error reading the
						 file (e.g., permissions), or if the file cannot be decoded
						 using UTF-8 (indicating it might be binary or use a
						 different encoding).
		"""
		# Construct the absolute path to the file
		fullPath: str = os.path.normpath(os.path.join(repoPath, filePath))
		logger.debug(f"Reading file content from: {fullPath}")

		# --- Path Validation ---
		try:
			# Resolve symbolic links and normalize before checking common prefix
			resolvedRepoPath = os.path.realpath(repoPath)
			resolvedFullPath = os.path.realpath(fullPath)

			# Check if the resolved full path is within the resolved repository path
			common_prefix = os.path.commonpath([resolvedRepoPath, resolvedFullPath])
			# Enhanced check: ensure resolved path starts with repo path + separator (or is identical)
			# Handle case where repo path might not have trailing separator
			if common_prefix != resolvedRepoPath or not (resolvedFullPath == resolvedRepoPath or resolvedFullPath.startswith(resolvedRepoPath + os.sep)):
				errMsg = f"Invalid file path '{filePath}' attempts to access outside repository root '{repoPath}' after path resolution."
				logger.error(errMsg)
				raise GitHubError(errMsg)
		except OSError as e: # Catch potential errors during realpath resolution
			errMsg = f"Error resolving file path '{fullPath}' or repo path '{repoPath}': {e}"
			logger.error(errMsg)
			raise GitHubError(errMsg) from e
		except Exception as e: # Catch unexpected errors during path checks
			errMsg = f"Unexpected error validating path for '{filePath}': {e}"
			logger.error(errMsg, exc_info=True)
			raise GitHubError(errMsg) from e


		# Check for file existence and type before attempting to open
		if not os.path.exists(fullPath):
			errMsg: str = f"File not found at calculated path: '{fullPath}' (relative: '{filePath}')"
			logger.error(errMsg)
			raise GitHubError(errMsg)
		if not os.path.isfile(fullPath):
			errMsg: str = f"Path exists but is not a file: '{fullPath}' (relative: '{filePath}')"
			logger.error(errMsg)
			raise GitHubError(errMsg)

		try:
			# Read the file content, trying UTF-8 first
			with open(fullPath, 'r', encoding='utf-8', errors='strict') as fileHandle:
				content: str = fileHandle.read()
			logger.debug(f"Successfully read content from '{filePath}'. Length: {len(content)}")
			return content
		except UnicodeDecodeError as e:
			errMsg: str = f"Could not decode file '{filePath}' using UTF-8. It might be binary or use a different encoding. Error: {e}"
			logger.error(errMsg)
			# Raise error indicating likely non-text file
			raise GitHubError(errMsg) from e
		except FileNotFoundError:
			# Defensive check, should be caught by os.path.exists earlier
			errMsg: str = f"File unexpectedly not found during read: '{fullPath}'"
			logger.error(errMsg)
			raise GitHubError(errMsg)
		except IOError as e:
			# Handles permission errors, etc.
			errMsg: str = f"IO error reading file '{filePath}': {e}"
			logger.error(errMsg, exc_info=True)
			raise GitHubError(errMsg) from e
		except Exception as e:
			errMsg: str = f"An unexpected error occurred reading file '{filePath}': {e}"
			logger.error(errMsg, exc_info=True)
			raise GitHubError(errMsg) from e

	def isDirty(self: 'GitHubHandler', repoPath: str) -> bool:
		"""
		Checks if the repository working directory has any uncommitted changes
		(staged or unstaged) or untracked files.

		Uses `git status --porcelain` for a comprehensive check.

		Args:
			repoPath (str): The path to the local Git repository.

		Returns:
			bool: True if there are uncommitted changes or untracked files,
				  False otherwise.

		Raises:
			GitHubError: If the `repoPath` is not a valid Git repository or if the
						 `git status` command fails.
		"""
		logger.debug(f"Checking repository status (isDirty) for: {repoPath}")
		try:
			repo: git.Repo = git.Repo(repoPath)
			gitCmd: git.Git = repo.git
			# Execute 'git status --porcelain'
			# Empty output indicates a clean working directory and index
			statusOutput: str = gitCmd.status(porcelain=True)
			is_dirty = bool(statusOutput) # True if the string is not empty
			logger.info(f"Repository dirty status for '{repoPath}': {is_dirty}")
			if is_dirty:
				# Log first few lines of status for context if dirty
				status_lines = statusOutput.splitlines()
				logger.debug(f"Porcelain status output (first 5 lines):\n" + "\n".join(status_lines[:5]))
			return is_dirty
		except git.InvalidGitRepositoryError:
			errMsg = f"'{repoPath}' is not a valid Git repository."
			logger.error(errMsg)
			raise GitHubError(errMsg) from None
		except git.GitCommandError as e:
			stderrOutput: str = getattr(e, 'stderr', "No stderr output.").strip()
			errMsg = f"Git command 'status' failed in '{repoPath}': {stderrOutput}"
			logger.error(errMsg, exc_info=False)
			raise GitHubError(errMsg) from e
		except Exception as e:
			errMsg = f"An unexpected error occurred checking repository status in '{repoPath}': {e}"
			logger.error(errMsg, exc_info=True)
			raise GitHubError(errMsg) from e

	def _check_branch_status(self: 'GitHubHandler', repo: git.Repo, remoteName: str, branchName: str) -> Tuple[bool, str]:
		"""
		Internal helper to check if the local branch is behind or diverged from its remote tracking branch.
		Performs a 'git fetch' first.

		Args:
			repo (git.Repo): The repository object.
			remoteName (str): The name of the remote.
			branchName (str): The name of the local branch.

		Returns:
			Tuple[bool, str]: (is_behind_or_diverged_or_error, message)
							  True if behind, diverged, or an error occurred checking.
							  False if up-to-date or ahead.
							  Message provides details.
		"""
		try:
			logger.info(f"Checking status of branch '{branchName}' against remote '{remoteName}'...")
			# Ensure local branch exists
			local_branch = next((b for b in repo.branches if b.name == branchName), None)
			if not local_branch:
				return True, f"Local branch '{branchName}' does not exist."

			# Ensure remote exists
			try:
				remote = repo.remote(name=remoteName)
			except ValueError:
				return True, f"Remote '{remoteName}' does not exist."

			# Fetch latest updates from the remote
			logger.debug(f"Fetching from remote '{remoteName}'...")
			try:
				# TODO: Add progress reporting for fetch if desired/possible
				remote.fetch(prune=True) # Consider adding progress=progress_handler if passed down
			except git.GitCommandError as fetch_err:
				stderrOutput = getattr(fetch_err, 'stderr', 'N/A').strip()
				if "Authentication failed" in stderrOutput or "Permission denied" in stderrOutput:
					errMsg = f"Authentication failed fetching from remote '{remoteName}'. Cannot check branch status."
				elif "could not resolve host" in stderrOutput.lower():
					errMsg = f"Network error fetching from remote '{remoteName}'. Cannot check branch status."
				else:
					errMsg = f"Could not fetch from remote '{remoteName}'. Push aborted to prevent potential issues. Error: {stderrOutput}"
				logger.warning(errMsg)
				return True, errMsg
			except Exception as fetch_exc: # Catch other potential fetch errors
				errMsg = f"Unexpected error fetching from remote '{remoteName}': {fetch_exc}. Cannot check branch status."
				logger.warning(errMsg, exc_info=True)
				return True, errMsg


			# Find the remote tracking branch
			tracking_branch = local_branch.tracking_branch()
			if not tracking_branch:
				# Branch might be local only or tracking not set up correctly.
				# Allow push attempt, remote will reject if needed.
				logger.warning(f"Local branch '{branchName}' is not tracking a remote branch on '{remoteName}'. Push will be attempted.")
				return False, f"Branch '{branchName}' not tracking remote. Push will be attempted."
			if not tracking_branch.is_valid():
				# Tracking branch points to a ref that no longer exists (e.g., remote branch deleted)
				logger.warning(f"Remote tracking branch '{tracking_branch.path}' for local branch '{branchName}' is invalid (likely deleted). Push will be attempted.")
				return False, f"Remote tracking branch for '{branchName}' is invalid. Push will be attempted."


			# Compare commit hashes
			local_commit = local_branch.commit
			remote_commit = tracking_branch.commit

			if local_commit == remote_commit:
				logger.info(f"Branch '{branchName}' is up-to-date with '{tracking_branch.path}'.")
				return False, f"Branch '{branchName}' is up-to-date."
			elif repo.is_ancestor(local_commit, remote_commit):
				# Remote has commits not in local -> behind
				logger.warning(f"Local branch '{branchName}' is behind remote tracking branch '{tracking_branch.path}'.")
				return True, f"Local branch '{branchName}' is behind remote. Please pull changes before pushing."
			elif repo.is_ancestor(remote_commit, local_commit):
				# Local has commits not in remote -> ahead (safe to push)
				logger.info(f"Local branch '{branchName}' is ahead of remote tracking branch '{tracking_branch.path}'.")
				return False, f"Branch '{branchName}' is ahead of remote."
			else:
				# Histories have diverged
				logger.warning(f"Local branch '{branchName}' has diverged from remote tracking branch '{tracking_branch.path}'.")
				return True, f"Local branch '{branchName}' has diverged from remote. Please pull and resolve conflicts before pushing."

		except git.GitCommandError as e:
			stderr = getattr(e, 'stderr', 'N/A')
			logger.error(f"Git command error during branch status check: {stderr}")
			return True, f"Error checking branch status: {stderr}" # Assume problematic if check fails
		except Exception as e:
			logger.error(f"Unexpected error during branch status check: {e}", exc_info=True)
			return True, f"Unexpected error checking branch status: {e}" # Assume problematic


	def updateRepo(
		self: 'GitHubHandler',
		repoPath: str,
		commitMessage: str,
		push: bool = True,
		remoteName: str = 'origin',
		branchName: str = 'main',
		progress_handler: Optional[GitProgressHandler] = None # For push progress (if implemented)
	) -> str:
		"""
		Stages all changes, commits them, and optionally pushes to the remote
		after checking if the local branch is behind its remote counterpart.

		Checks for changes using `isDirty()`. If changes exist, stages all
		modifications and new files, commits using the provided message. If `push`
		is True, it first fetches the remote and checks if the local branch (`branchName`)
		is behind or has diverged from its tracking branch on `remoteName`. If it is
		behind/diverged, it raises a GitHubError prompting the user to pull.
		Otherwise, it attempts the push, relying on Git's credential management.

		Args:
			repoPath (str): The path to the local Git repository.
			commitMessage (str): The message to use for the commit.
			push (bool): If True, attempts to check remote status and push the commit.
						 Defaults to True.
			remoteName (str): The name of the Git remote to check against and push to.
							  Defaults to 'origin'.
			branchName (str): The name of the local branch to commit to and push from.
							  Defaults to 'main'.
			progress_handler (Optional[GitProgressHandler]): Progress handler for push (Limited support in GitPython).

		Returns:
			str: A success message indicating the outcome (e.g., "No changes detected.",
				 "Changes committed locally.", "Changes committed and pushed...").

		Raises:
			GitHubError: If staging, committing, or pushing fails, or if the push
						 pre-check determines the local branch is behind/diverged.
						 Provides specific messages for common issues.
		"""
		logger.info(f"Starting update process for repository: {repoPath}")
		try:
			repo: git.Repo = git.Repo(repoPath)
			gitCmd: git.Git = repo.git

			# 1. Check for changes using the dedicated method
			if not self.isDirty(repoPath):
				logger.info("No changes detected in the repository. Nothing to commit or push.")
				return "No changes detected."

			# 2. Stage all changes (git add -A)
			logger.info("Staging all changes (including new/deleted files)...")
			gitCmd.add(A=True) # Use -A to stage all changes (modified, new, deleted)
			logger.debug("Changes staged successfully.")

			# 3. Commit changes
			logger.info(f"Committing changes with message: '{commitMessage}'")
			repo.index.commit(commitMessage)
			logger.info("Commit successful.")

			# 4. Push changes (optional, with pre-check)
			if push:
				# --- Pre-push Check ---
				if progress_handler and hasattr(progress_handler, '_emitter'):
					progress_handler._emitter.progressUpdate.emit(-1, f"Checking status vs {remoteName}...")
				check_failed_or_behind, status_message = self._check_branch_status(repo, remoteName, branchName)
				if check_failed_or_behind:
					# If branch is behind, diverged, or status check failed, raise error before push attempt
					logger.error(f"Pre-push check failed: {status_message}")
					# Reset index to before the commit if push is aborted by pre-check
					logger.warning("Resetting index to HEAD~1 due to failed pre-push check...")
					try:
						repo.index.reset("HEAD~1", head=True) # Reset index and HEAD
						logger.info("Successfully reset commit due to failed pre-push check.")
					except git.GitCommandError as reset_err:
						logger.error(f"Failed to automatically reset commit after failed pre-push check: {reset_err}")
						# Still raise the original error, but add a note about the failed reset
						raise GitHubError(f"Push aborted. {status_message} (Failed to auto-reset local commit)") from reset_err
					raise GitHubError(f"Push aborted. {status_message} (Local commit has been reset)")
				else:
					logger.info(f"Pre-push check passed: {status_message}")

				# --- Proceed with Push ---
				logger.info(f"Attempting to push branch '{branchName}' to remote '{remoteName}'...")
				if progress_handler and hasattr(progress_handler, '_emitter'):
					progress_handler._emitter.progressUpdate.emit(0, f"Pushing to {remoteName}...")
				try:
					remote: git.Remote = repo.remote(name=remoteName)
				except ValueError:
					errMsg = f"Remote '{remoteName}' does not exist in the repository at '{repoPath}'. Cannot push."
					logger.error(errMsg)
					raise GitHubError(errMsg)

				# Authentication Info/Warning
				if remote.url.startswith("https://"):
					logger.info("Pushing via HTTPS. Ensure Git credential helper is configured.")
				elif remote.url.startswith("git@"):
					logger.info("Pushing via SSH. Ensure SSH key is configured.")
				else:
					logger.info(f"Pushing via {remote.url.split(':')[0]} protocol. Ensure credentials configured.")

				# Specify the refspec: local_branch:remote_branch
				refspec: str = f'{branchName}:{branchName}'
				logger.debug(f"Executing push with refspec: {refspec}")
				# Note: GitPython's push progress is less granular than clone.
				# The progress_handler might only get limited updates here.
				# Catch GitCommandError here for detailed push failure analysis
				try:
					pushInfoList: List[git.PushInfo] = remote.push(refspec=refspec, progress=progress_handler)
				except git.GitCommandError as push_error:
					stderrOutput = getattr(push_error, 'stderr', "No stderr output.").strip()
					logger.error(f"Git command 'push' failed. Stderr: {stderrOutput}", exc_info=False)
					# Analyse stderr for common push failures
					if "Authentication failed" in stderrOutput or "Permission denied" in stderrOutput:
						errMsg = f"Authentication failed during push to '{remoteName}'. Check credentials/SSH keys."
					elif "Updates were rejected because the remote contains work that you do" in stderrOutput:
						errMsg = f"Push rejected. Remote branch '{remoteName}/{branchName}' has changes not present locally. Please pull changes before pushing."
					elif "src refspec" in stderrOutput and "does not match any" in stderrOutput:
						errMsg = f"Push failed: Local branch '{branchName}' or specified refspec does not exist or match."
					elif "repository not found" in stderrOutput:
						errMsg = f"Push failed: Remote repository '{remote.url}' not found or access denied."
					elif "Connection timed out" in stderrOutput or "Could not resolve host" in stderrOutput:
						errMsg = f"Network error during push: {stderrOutput}"
					else: # Generic push error
						errMsg = f"Push to remote '{remoteName}' failed. Git error: {stderrOutput}"
					raise GitHubError(errMsg) from push_error


				# Check push results for non-fatal errors reported by GitPython (less common than command errors)
				pushSucceeded = True
				errorMessages: List[str] = []
				pushSummary = ""
				for info in pushInfoList:
					# Build summary regardless of error for logging
					local_ref_name = info.local_ref.name if info.local_ref else 'N/A'
					remote_ref_str = info.remote_ref_string or 'N/A'
					summary_note = info.summary.strip() if info.summary else 'No summary'
					pushSummary += f"[{local_ref_name} -> {remote_ref_str}: {summary_note}] "

					# Check flags for various error conditions reported by PushInfo
					if info.flags & git.PushInfo.ERROR:
						pushSucceeded = False
						errMsg = f"Push error reported by GitPython for ref '{remote_ref_str}': {summary_note}"
						errorMessages.append(errMsg)
					elif info.flags & (git.PushInfo.REJECTED | git.PushInfo.REMOTE_REJECTED):
						# Should ideally be caught by command error or pre-check, but check flags just in case
						pushSucceeded = False
						reason = summary_note or "Likely requires pulling changes first"
						errMsg = f"Push rejected for ref '{remote_ref_str}'. Reason: {reason}"
						errorMessages.append(errMsg)

				if not pushSucceeded:
					# Combine error messages and raise
					fullErrorMsg = "Push operation failed after command execution.\nDetails:\n" + "\n".join(errorMessages)
					logger.error(fullErrorMsg)
					if progress_handler and hasattr(progress_handler, '_emitter'):
						progress_handler._emitter.progressUpdate.emit(100, "Push failed.")
					raise GitHubError(fullErrorMsg)

				logger.info(f"Changes successfully pushed to '{remoteName}/{branchName}'. Summary: {pushSummary.strip()}")
				if progress_handler and hasattr(progress_handler, '_emitter'):
					progress_handler._emitter.progressUpdate.emit(100, "Push complete.")
				successMsg = f"Changes committed and pushed to '{remoteName}/{branchName}'."
			else:
				logger.info("Skipping push step as requested.")
				successMsg = "Changes committed locally."

			return successMsg

		except git.InvalidGitRepositoryError:
			errMsg = f"'{repoPath}' is not a valid Git repository."
			logger.error(errMsg)
			raise GitHubError(errMsg) from None
		except git.GitCommandError as e:
			# Catch errors during staging/commit phase if not push error
			stderrOutput = getattr(e, 'stderr', "No stderr output.").strip()
			if "nothing to commit" in stderrOutput:
				# Should be caught by isDirty, but handle defensively
				logger.warning(f"Git command '{e.command}' reported 'nothing to commit'. Status: {e.status}. Stderr: {stderrOutput}")
				if not self.isDirty(repoPath): # Double check dirty status
					return "No changes needed committing."
				else: # Should not happen if isDirty was true
					errMsg = f"Git reported 'nothing to commit' but repository seems dirty. Staging/Commit failed? Command: {e.command}. Stderr: {stderrOutput}"
			elif "Changes not staged for commit" in stderrOutput:
				errMsg = f"Commit failed: No changes were staged. Staging might have failed. Stderr: {stderrOutput}"
			else: # Generic error during add/commit
				errMsg = f"Git command failed during update: {e.command} - Status: {e.status}\nStderr: {stderrOutput}"
			logger.error(errMsg, exc_info=False)
			raise GitHubError(errMsg) from e
		except GitHubError as e: # Re-raise specific GitHubErrors from push flag checking or pre-check
			raise e
		except Exception as e:
			errMsg = f"An unexpected error occurred during repository update: {e}"
			logger.error(errMsg, exc_info=True)
			raise GitHubError(errMsg) from e

# --- END: core/github_handler.py ---

## core/llm_interface.py ##

"""
Handles interaction with the Large Language Model (LLM) API.
Includes building prompts with token-based truncation (preferred) or
character-based truncation (fallback) and querying the API
(e.g., Google Gemini) with configurable safety settings and retry logic.
Includes logic for building a correction prompt.
"""
import logging
import time  # For retry delay

# Google API imports
import google.generativeai as genai
from google.generativeai.types import (
    GenerationConfig,
    ContentDict,
    PartDict,
    GenerateContentResponse,
    BlockedPromptException,
    StopCandidateException
)
from google.generativeai.types.safety_types import (
    HarmCategory,
    HarmBlockThreshold
)
from google.api_core import exceptions as google_exceptions

# Python standard library imports
from typing import Dict, Optional, Any, List, Tuple, Union

# Local imports
from .exceptions import LLMError, ConfigurationError
from .config_manager import ConfigManager

logger: logging.Logger = logging.getLogger(__name__)

# Constants for retry logic
MAX_RETRIES = 1  # Number of retries (1 means try original + 1 retry = 2 attempts total)
RETRY_DELAY_SECONDS = 2  # Delay between retries

# Mappings from config string to enums
HARM_CATEGORY_MAP = {
    "HARM_CATEGORY_HARASSMENT": HarmCategory.HARM_CATEGORY_HARASSMENT,
    "HARM_CATEGORY_HATE_SPEECH": HarmCategory.HARM_CATEGORY_HATE_SPEECH,
    "HARM_CATEGORY_SEXUALLY_EXPLICIT": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
    "HARM_CATEGORY_DANGEROUS_CONTENT": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
}

HARM_THRESHOLD_MAP = {
    "BLOCK_NONE": HarmBlockThreshold.BLOCK_NONE,
    "BLOCK_LOW_AND_ABOVE": HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
    "BLOCK_MEDIUM_AND_ABOVE": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    "BLOCK_ONLY_HIGH": HarmBlockThreshold.BLOCK_ONLY_HIGH,
}


class LLMInterface:
    """
    Provides methods to build prompts and interact with an LLM API.
    Includes configuration for generation parameters, safety settings,
    token/character prompt truncation, and retry logic.
    """
    _configManager: ConfigManager  # Type hint for clarity
    _model_instance_cache: Dict[str, genai.GenerativeModel] = {}  # Cache models per name
    _api_configured: bool = False  # Track if API key has been configured in this instance

    def __init__(self: 'LLMInterface', configManager: Optional[ConfigManager] = None) -> None:
        """ Initialises the LLMInterface. """
        self._configManager = configManager if configManager is not None else ConfigManager()
        self._model_instance_cache = {}  # Clear cache on init
        self._api_configured = False  # Reset flag on init
        logger.debug("LLMInterface initialised.")

    def _configure_api_key(self: 'LLMInterface') -> None:
        """Configures the genai API key if not already done."""
        if self._api_configured:
            return

        try:
            apiKey = self._configManager.getEnvVar('GEMINI_API_KEY', required=True)
            genai.configure(api_key=apiKey)
            self._api_configured = True
            logger.debug("Configured google-generativeai API key.")
        except ConfigurationError as e:
            logger.error(f"API Key configuration failed: {e}")
            raise e

    def _get_model_instance(self: 'LLMInterface', modelName: str, configure_api: bool = True) -> Optional[genai.GenerativeModel]:
        """ Instantiates or retrieves a cached GenerativeModel instance. """
        try:
            if configure_api:
                self._configure_api_key()
            if modelName in self._model_instance_cache:
                return self._model_instance_cache[modelName]
            try:
                model = genai.GenerativeModel(modelName)
                self._model_instance_cache[modelName] = model
                logger.info(f"Instantiated GenerativeModel: '{modelName}'")
                return model
            except ValueError as e:
                errMsg = f"Failed to instantiate GenerativeModel '{modelName}': {e}"
                logger.error(errMsg)
                raise LLMError(errMsg) from e
        except ConfigurationError as e:
            raise e
        except Exception as e:
            errMsg = f"Failed to instantiate GenerativeModel '{modelName}': {e}"
            logger.error(errMsg, exc_info=True)
            raise LLMError(errMsg) from e

    def _count_tokens(self: 'LLMInterface', modelName: str, content: str | List[str | PartDict]) -> Optional[int]:
        """ Counts tokens for the given content using the specified model. """
        if not content:
            logger.debug(
                f"Content provided to _count_tokens for model '{modelName}' "
                "is empty. Returning 0 tokens."
            )
            return 0
        
        try:
            model = self._get_model_instance(modelName, configure_api=True)
            if not model:
                logger.error(f"Model instance '{modelName}' unavailable for token counting.")
                return None
            
            response = model.count_tokens(content)
            return response.total_tokens
            
        except ConfigurationError as e:
            logger.error(f"Configuration error during token counting setup: {e}")
            return None
            
        except google_exceptions.PermissionDenied as e:
            logger.error(
                f"Permission denied counting tokens for model '{modelName}'. "
                f"Check API key validity/permissions: {e}",
                exc_info=False
            )
            return None
            
        except google_exceptions.GoogleAPIError as e:
            logger.error(
                f"API error counting tokens for model '{modelName}': {e}",
                exc_info=False
            )
            return None
            
        except ValueError as e:
            logger.error(
                f"Invalid value error counting tokens for model '{modelName}': {e}",
                exc_info=False
            )
            # Special handling for empty content error
            if "content' argument must not be empty" in str(e):
                logger.warning(
                    "Caught empty content ValueError in _count_tokens despite check; "
                    "returning 0."
                )
                return 0
            return None
            
        except Exception as e:
            logger.error(
                f"Unexpected error counting tokens for model '{modelName}': {e}",
                exc_info=True
            )
            return None

    def _truncate_content_by_tokens(self: 'LLMInterface', modelName: str, content: str, max_tokens: int) -> Tuple[str, Optional[int], int]:
        """ Truncates content to fit within a maximum token limit using binary search. """
        initial_tokens = self._count_tokens(modelName, content)
        if initial_tokens is None:
            logger.warning(f"Token counting failed for content (length {len(content)}). Cannot perform token-based truncation.")
            return content, None, 0
        if initial_tokens <= max_tokens:
            return content, initial_tokens, 0
        logger.warning(f"Content (length {len(content)}, tokens ~{initial_tokens}) exceeds token limit ({max_tokens}). Truncating...")
        low, high, best_len, best_token_count = 0, len(content), 0, Optional[int]
        max_iterations, iteration, token_counting_failed_during_search = 20, 0, False
        while low <= high and iteration < max_iterations:
            iteration += 1
            mid = (low + high) // 2
            if mid == 0:
                break
            truncated_substr = content[:mid]
            if not truncated_substr:
                current_tokens = 0
            else:
                current_tokens = self._count_tokens(modelName, truncated_substr)
            if current_tokens is None:
                logger.error("Token counting failed during truncation search. Stopping search.")
                token_counting_failed_during_search = True
                break
            if current_tokens <= max_tokens:
                if mid > best_len:
                    best_len, best_token_count = mid, current_tokens
                low = mid + 1
            else:
                high = mid - 1
        if iteration >= max_iterations:
            logger.warning("Truncation search reached max iterations. Using best length found.")
        if token_counting_failed_during_search:
            if best_len > 0:
                omitted = len(content) - best_len
                logger.warning(f"Falling back to truncated content with length {best_len} (~{best_token_count} tokens) due to token counting error during search.")
                return content[:best_len], best_token_count, omitted
            else:
                logger.error("Could not find any valid truncation point before token counting failed during search.")
                return "", None, len(content)
        if best_len == 0 and initial_tokens > max_tokens:
            logger.error(f"Could not truncate content below the token limit of {max_tokens}. Returning empty string.")
            return "", None, len(content)
        omitted_chars = len(content) - best_len
        truncated_result = content[:best_len]
        if omitted_chars > 0:
            logger.warning(f"Truncated content to {best_len} characters (~{best_token_count} tokens) to meet limit of {max_tokens} tokens.")
        return truncated_result, best_token_count, omitted_chars

    def _load_safety_settings(self: 'LLMInterface') -> List[Dict[str, Union[HarmCategory, HarmBlockThreshold]]]:
        """ Loads safety settings from config, returning List[Dict] for API. """
        safety_settings: List[Dict[str, Union[HarmCategory, HarmBlockThreshold]]] = []
        config_keys = [
            'HarmCategoryHarassmentThreshold',
            'HarmCategoryHateSpeechThreshold',
            'HarmCategorySexuallyExplicitThreshold',
            'HarmCategoryDangerousContentThreshold'
        ]
        harm_category_name_map = {
            'HarmCategoryHarassmentThreshold': "HARM_CATEGORY_HARASSMENT",
            'HarmCategoryHateSpeechThreshold': "HARM_CATEGORY_HATE_SPEECH",
            'HarmCategorySexuallyExplicitThreshold': "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            'HarmCategoryDangerousContentThreshold': "HARM_CATEGORY_DANGEROUS_CONTENT"
        }
        for config_key in config_keys:
            try:
                threshold_str = self._configManager.getConfigValue('LLM', config_key, required=False)
                if threshold_str is not None and threshold_str.strip():
                    harm_category_str = harm_category_name_map.get(config_key)
                    category_enum = HARM_CATEGORY_MAP.get(harm_category_str)
                    if category_enum is None:
                        logger.warning(f"Invalid harm category name '{harm_category_str}' derived from config key '{config_key}'. Skipping.")
                        continue
                    threshold_enum = HARM_THRESHOLD_MAP.get(threshold_str.strip().upper())
                    if threshold_enum is None:
                        logger.warning(f"Invalid safety threshold value '{threshold_str}' for '{config_key}'. Must be one of {list(HARM_THRESHOLD_MAP.keys())}. Skipping.")
                        continue
                    setting_dict: Dict[str, Union[HarmCategory, HarmBlockThreshold]] = {
                        "category": category_enum,
                        "threshold": threshold_enum
                    }
                    safety_settings.append(setting_dict)
                    logger.debug(f"Loaded safety setting: {harm_category_str} = {threshold_str}")
                else:
                    logger.debug(f"Safety setting '{config_key}' not found or empty in config. Using API default for this category.")
            except ConfigurationError as e:
                logger.warning(f"Error loading configuration for safety setting '{config_key}': {e}. Skipping.")
            except Exception as e:
                logger.error(f"Error processing safety setting dictionary for {config_key} with threshold '{threshold_str}': {e}", exc_info=True)
        if not safety_settings:
            logger.info("No valid safety settings found in configuration. Using Google Gemini API defaults.")
        else:
            logger.info(f"Loaded {len(safety_settings)} safety settings from configuration.")
        return safety_settings

    def buildPrompt(self: 'LLMInterface', instruction: str, fileContents: Dict[str, str]) -> str:
        """ Constructs the main prompt including instructions, context, format specs, and rules. """
        logger.debug(f"Building LLM prompt. Instruction length: {len(instruction)}, Files: {len(fileContents)}")
        truncation_applied = False
        overall_truncation_type = ""
        truncation_details = []
        token_counting_failed_overall = False
        try:
            # Configuration loading
            modelName = self._configManager.getConfigValue('General', 'DefaultLlmModel', fallback='gemini-1.5-flash-latest')
            if not isinstance(modelName, str) or not modelName.strip():
                modelName = 'gemini-1.5-flash-latest'
            max_tokens_per_file_config = self._configManager.getConfigValueInt('LLM', 'MaxTokensPerFileInPrompt', fallback=None)
            max_chars_per_file_config = self._configManager.getConfigValueInt('LLM', 'MaxCharsPerFileInPrompt', fallback=None)
            max_tokens_per_file = max_tokens_per_file_config if max_tokens_per_file_config is not None and max_tokens_per_file_config > 0 else 0
            max_chars_per_file = max_chars_per_file_config if max_chars_per_file_config is not None and max_chars_per_file_config > 0 else 0
            use_token_truncation = max_tokens_per_file > 0
            use_char_truncation = max_chars_per_file > 0
            if use_token_truncation:
                logger.debug(f"Token-based truncation enabled (MaxTokensPerFileInPrompt={max_tokens_per_file}). Checking API key...")
                self._get_model_instance(modelName, configure_api=True)
            elif use_char_truncation:
                logger.debug(f"Character-based truncation enabled (MaxCharsPerFileInPrompt={max_chars_per_file}). Token truncation disabled.")
            else:
                logger.debug("Both token and character truncation disabled.")
            output_format = self._configManager.getConfigValue('General', 'ExpectedOutputFormat', fallback='json')
            if not isinstance(output_format, str) or not output_format.strip():
                output_format = 'json'
            output_format_upper = output_format.upper()
        except (ConfigurationError, LLMError) as e:
            logger.error(f"Setup error preparing for prompt build: {e}")
            raise e
        except Exception as e:
            logger.error(f"Unexpected error reading configuration for prompt build: {e}", exc_info=True)
            raise ConfigurationError(f"Unexpected error reading configuration: {e}") from e

        promptLines: List[str] = []
        # User Instruction
        promptLines.append("## User Instruction:")
        promptLines.append(instruction)
        promptLines.append("\n")
        # File Context with Truncation
        promptLines.append("## Code Context:")
        if fileContents:
            promptLines.append("The user instruction applies to the following file(s):")
            for filePath, content in fileContents.items():
                promptLines.append(f"--- START FILE: {filePath} ---")
                final_content = content
                omitted_count = 0
                applied_trunc_type = ""
                final_tokens: Optional[int] = None
                token_count_info = ""
                file_token_counting_failed = False
                if use_token_truncation:
                    truncated_tuple = self._truncate_content_by_tokens(modelName, content, max_tokens_per_file)
                    final_content, final_tokens, omitted_chars = truncated_tuple
                    if final_tokens is None:
                        file_token_counting_failed = True
                        token_counting_failed_overall = True
                        token_count_info = " (Token count unavailable)"
                    else:
                        token_count_info = f" (~{final_tokens} tokens)"
                    if omitted_chars > 0:
                        truncation_applied = True
                        applied_trunc_type = "token"
                        omitted_count = omitted_chars
                        truncation_details.append((filePath, applied_trunc_type, omitted_count))
                    if not overall_truncation_type:
                        overall_truncation_type = "token"
                    elif overall_truncation_type == "character":
                        overall_truncation_type = "mixed"
                should_apply_char_trunc = (not use_token_truncation or file_token_counting_failed) and use_char_truncation and len(final_content) > max_chars_per_file
                if should_apply_char_trunc:
                    original_len_before_char_trunc = len(final_content)
                    final_content = final_content[:max_chars_per_file]
                    omitted_count = original_len_before_char_trunc - max_chars_per_file
                    applied_trunc_type = "character"
                    truncation_applied = True
                    logger.warning(f"Applied fallback character truncation to '{filePath}' (omitted {omitted_count} chars).")
                    token_count_info = ""
                    existing_detail_index = next((i for i, d in enumerate(truncation_details) if d[0] == filePath), -1)
                    if existing_detail_index != -1:
                        truncation_details[existing_detail_index] = (filePath, applied_trunc_type, omitted_count)
                    else:
                        truncation_details.append((filePath, applied_trunc_type, omitted_count))
                    if not overall_truncation_type:
                        overall_truncation_type = "character"
                    elif overall_truncation_type == "token":
                        overall_truncation_type = "mixed"
                promptLines.append(final_content)
                if applied_trunc_type:
                    unit = "characters"
                    promptLines.append(f"\n... [TRUNCATED by {applied_trunc_type} limit - {omitted_count} {unit} omitted] ...")
                promptLines.append(f"--- END FILE: {filePath} ---{token_count_info}")
                promptLines.append("")
        else:
            promptLines.append("No specific file context was provided.")
            promptLines.append("\n")

        # Output Format Specification (Strengthened rules)
        promptLines.append("## Required Output Format:")
        promptLines.append(f"Based *only* on the user instruction and the provided file contexts, generate the necessary code modifications.")
        promptLines.append(f"CRITICAL: Provide the **complete, updated content** for **all modified or newly created files** as a single, syntactically perfect {output_format_upper} object.")
        promptLines.append(f"CRITICAL: This {output_format_upper} object MUST be enclosed within a SINGLE markdown code block using the tag '```{output_format}'.")
        promptLines.append(f"The {output_format_upper} object MUST map the relative file path (as a string key) to the full updated file content (as a string value).")
        promptLines.append(f"\nExample {output_format_upper} structure:")
        promptLines.append(f"```{output_format}")
        promptLines.append("{")
        promptLines.append("  \"path/to/updated_file1.py\": \"# Updated Python code\\nprint('Hello')\",")
        promptLines.append("  \"path/to/new_file.txt\": \"This is a new file created by the LLM.\",")
        promptLines.append("  \"another/path/service.yaml\": \"apiVersion: v1\\nkind: Service\\nmetadata:\\n  name: updated-service\\n...\"")
        promptLines.append("}")
        promptLines.append("```")
        promptLines.append("\n**VERY Important Rules:**")
        promptLines.append(f"* **Self-Correction:** Before outputting, double-check that the generated {output_format_upper} object is 100% valid according to {output_format_upper} syntax rules (commas, quotes, brackets, braces).")
        promptLines.append("* Only include files that require modification or are newly created based *directly* on the instruction.")
        promptLines.append("* If a file needs changes, include its *entire* final content in the value, not just the changed lines.")
        promptLines.append(f"* **CRITICAL:** Ensure the {output_format_upper} is perfectly valid and enclosed in **one** markdown code block (```{output_format} ... ```).")
        promptLines.append(f"* If **no files** need modification or creation based on the instruction, return ONLY an empty {output_format_upper} object: `{{}}` within the code block.")
        promptLines.append(f"* **CRITICAL:** All string values within the {output_format_upper}, especially code content, MUST have special characters (like quotes `\"`, backslashes `\\\\`, newlines `\\n`, etc.) correctly escaped according to {output_format_upper} rules.")
        promptLines.append(f"* **CRITICAL:** The final output MUST contain ONLY the single markdown code block with the {output_format_upper} object. Absolutely NO text, explanations, apologies, or any other content before or after the code block.")

        # Truncation Note
        if truncation_applied:
            if overall_truncation_type == "token":
                limit_note = f"token limit (~{max_tokens_per_file} tokens)"
            elif overall_truncation_type == "character":
                limit_note = f"character limit ({max_chars_per_file} chars)"
            elif overall_truncation_type == "mixed":
                limit_note = f"token (~{max_tokens_per_file}) or character ({max_chars_per_file}) limit"
            else:
                limit_note = "configured limit"
            if token_counting_failed_overall and "token" in limit_note:
                limit_note += " (token counting may have failed for some files)"
            promptLines.append("\n* Note: Content for some files provided above may have been truncated due to the " + limit_note + ".")
            promptLines.append("  Files truncated:")
            for fname, ttype, omitted in truncation_details:
                unit = "chars"
                promptLines.append(f"    - {fname} (by {ttype}, {omitted} {unit} omitted)")

        fullPrompt: str = "\n".join(promptLines)
        logger.debug(f"Generated prompt length (characters): {len(fullPrompt)}")
        return fullPrompt

    def build_correction_prompt(
        self: 'LLMInterface',
        original_bad_output: str,
        original_instruction: str,
        expected_format: str
    ) -> str:
        """
        Constructs a prompt asking the LLM to correct its previous invalid output.

        Args:
            original_bad_output (str): The previous, invalid response from the LLM.
            original_instruction (str): The original user instruction (for context).
            expected_format (str): The required output format (e.g., 'json', 'yaml').

        Returns:
            str: The correction prompt.
        """
        logger.debug("Building correction prompt.")
        output_format_upper = expected_format.upper()
        promptLines: List[str] = []

        promptLines.append(f"Your previous response did not adhere to the required {output_format_upper} format or contained syntax errors.")
        promptLines.append("CRITICAL: Please analyse your previous output below, identify the errors, and provide a corrected response.")
        promptLines.append(f"The corrected response MUST be a single, syntactically perfect {output_format_upper} object, mapping file paths to their full content.")
        promptLines.append(f"This {output_format_upper} object MUST be enclosed within a SINGLE markdown code block (```{expected_format} ... ```).")
        promptLines.append("Ensure all rules regarding structure, escaping, and content from the original request are followed.")
        promptLines.append("Do NOT include any explanations or text outside the final code block.")

        promptLines.append("\n## Original User Instruction (for context):")
        promptLines.append(original_instruction)

        promptLines.append("\n## Previous Incorrect Output (analyse and fix this):")
        # Include the previous bad output verbatim, maybe within its own block for clarity?
        # Putting it raw might be better for the LLM to see exactly what it produced.
        promptLines.append(original_bad_output)

        promptLines.append(f"\n## Corrected Output (Provide ONLY the valid ```{expected_format} ... ``` block below):")

        fullPrompt: str = "\n".join(promptLines)
        logger.debug(f"Generated correction prompt length (characters): {len(fullPrompt)}")
        return fullPrompt

    def queryLlmApi(
        self: 'LLMInterface',
        prompt: str,
        modelName: Optional[str] = None,
        override_temperature: Optional[float] = None
    ) -> str:
        """
        Sends the prompt to the specified LLM API (Google Gemini) and returns the response.
        
        Args:
            prompt (str): The fully constructed prompt to send.
            modelName (Optional[str]): The specific LLM model to use (e.g., "gemini-pro").
                                   If None, the default from config is used.
            override_temperature (Optional[float]): If provided, uses this temperature instead
                                                of the value from config.
        
        Returns:
            str: The text response received from the LLM.
        
        Raises:
            ConfigurationError: If the API key is missing or other configuration is invalid.
            LLMError: If there are issues communicating with the API.
        """
        try:
            resolved_model_name = modelName or self._configManager.getConfigValue(
                'General',
                'DefaultLlmModel',
                fallback='gemini-1.5-flash-latest'
            )
            
            if not isinstance(resolved_model_name, str) or not resolved_model_name.strip():
                resolved_model_name = 'gemini-1.5-flash-latest'
            
            model = self._get_model_instance(resolved_model_name, configure_api=True)
            if not model:
                raise LLMError(f"Failed to get model instance for '{resolved_model_name}'")
            
            logger.debug(f"Using model instance: '{resolved_model_name}'")

            # Handle Temperature Override
            if override_temperature is not None:
                temperature = override_temperature
                logger.info(f"Using overridden temperature: {temperature}")
            else:
                temp_config = self._configManager.getConfigValueFloat(
                    'LLM',
                    'Temperature',
                    fallback=None
                )
                temperature = temp_config if temp_config is not None else 0.7

            max_tokens_config = self._configManager.getConfigValueInt('LLM', 'MaxOutputTokens', fallback=None)
            max_output_tokens = max_tokens_config if max_tokens_config is not None else 8192
            safety_settings: List[Dict[str, Union[HarmCategory, HarmBlockThreshold]]] = self._load_safety_settings()
            if not (0.0 <= temperature <= 1.0):
                temperature = max(0.0, min(1.0, temperature))
            if max_output_tokens is not None and max_output_tokens <= 0:
                max_output_tokens = None
        except (ConfigurationError, LLMError) as e:
            logger.error(f"Setup error preparing for LLM query: {e}")
            raise e
        except Exception as e:
            logger.error(f"Unexpected error reading configuration for LLM query: {e}", exc_info=True)
            raise ConfigurationError(f"Unexpected error reading configuration: {e}") from e

        logger.info(f"Querying LLM model '{resolved_model_name}'...")
        last_exception: Optional[Exception] = None

        for attempt in range(MAX_RETRIES + 1):
            try:
                gen_config_args = {'temperature': temperature}
                if max_output_tokens is not None:
                    gen_config_args['max_output_tokens'] = max_output_tokens
                generation_config = GenerationConfig(**gen_config_args)
                logger.debug(f"Sending prompt (length chars: {len(prompt)}) to model '{resolved_model_name}' (Attempt {attempt + 1}/{MAX_RETRIES + 1})...")
                logger.debug(f"Using GenerationConfig: {gen_config_args}")  # Log effective config
                logger.debug(f"Using SafetySettings: {safety_settings if safety_settings else 'API Defaults'}")
                response: GenerateContentResponse = model.generate_content(
                    prompt,
                    generation_config=generation_config,
                    safety_settings=safety_settings,
                    request_options={'timeout': 300}
                )
                llmOutput: str = response.text  # This raises exceptions if blocked/stopped
                if not llmOutput.strip():
                    errMsg = "LLM returned an empty or whitespace-only response despite finishing normally."
                    logger.error(errMsg)
                    raise LLMError(errMsg)
                logger.info(f"LLM query successful on attempt {attempt + 1}. Response length: {len(llmOutput)}")
                return llmOutput
            except ConfigurationError as e:
                raise e  # Propagate config errors immediately
            except BlockedPromptException as e:  # Handle prompt safety blocks (non-retryable)
                errMsg = f"LLM query blocked due to safety settings in the prompt."
                prompt_feedback_details = ""
                if hasattr(e, 'response') and hasattr(e.response, 'prompt_feedback'):
                    pf = e.response.prompt_feedback
                    if pf:
                        reason = getattr(pf, 'block_reason_message', '')
                        reason_enum = getattr(pf, 'block_reason', None)
                        if not reason and reason_enum:
                            reason = getattr(reason_enum, 'name', 'UNKNOWN')
                        prompt_feedback_details += f" Reason: {reason if reason else 'Not Specified'}."
                        if pf.safety_ratings:
                            prompt_feedback_details += " SafetyRatings:"
                            for rating in pf.safety_ratings:
                                cat_name = getattr(rating.category, 'name', 'UNKNOWN')
                                prob_name = getattr(rating.probability, 'name', 'UNKNOWN')
                                prompt_feedback_details += f" {cat_name}={prob_name}"
                logger.error(errMsg + prompt_feedback_details)
                raise LLMError(errMsg + " Adjust safety settings or prompt content.") from e
            except StopCandidateException as e:  # Handle candidate blocks/stops (non-retryable)
                finish_reason_name = "UNKNOWN"
                candidate = None
                if hasattr(e, 'args') and e.args:
                    resp_or_candidate = e.args[0]
                    if isinstance(resp_or_candidate, GenerateContentResponse):
                        candidate = resp_or_candidate.candidates[0] if resp_or_candidate.candidates else None
                    elif hasattr(resp_or_candidate, 'finish_reason'):
                        candidate = resp_or_candidate
                if candidate and hasattr(candidate, 'finish_reason'):
                    try:
                        finish_reason_name = candidate.finish_reason.name
                    except AttributeError:
                        finish_reason_name = str(candidate.finish_reason)
                errMsg = f"LLM generation stopped unexpectedly. Reason: {finish_reason_name}."
                logger.error(errMsg)
                safety_details = ""
                if candidate and hasattr(candidate, 'safety_ratings') and candidate.safety_ratings:
                    safety_details += " Candidate Safety:"
                    for rating in candidate.safety_ratings:
                        cat_name = getattr(rating.category, 'name', 'UNKNOWN')
                        prob_name = getattr(rating.probability, 'name', 'UNKNOWN')
                        safety_details += f" {cat_name}={prob_name}"
                    logger.error(safety_details)
                finalErrMsg = errMsg
                if finish_reason_name == "SAFETY":
                    finalErrMsg += " Generation blocked due to safety settings." + safety_details + " Adjust safety settings or prompt content."
                elif finish_reason_name == "MAX_TOKENS":
                    finalErrMsg += " Maximum output tokens reached."
                elif finish_reason_name == "RECITATION":
                    finalErrMsg += " Response blocked due to recitation policy."
                elif finish_reason_name == "OTHER":
                    finalErrMsg += " Generation stopped for an unspecified reason by the API."
                raise LLMError(finalErrMsg) from e
            except google_exceptions.PermissionDenied as e:
                errMsg = f"LLM API key is likely invalid or lacks permissions: {e}"
                logger.error(errMsg, exc_info=False)
                raise LLMError(errMsg) from e  # Non-retryable
            except google_exceptions.InvalidArgument as e:  # Non-retryable
                if "API key not valid" in str(e):
                    errMsg = f"LLM API key not valid. Please pass a valid API key via GEMINI_API_KEY environment variable."
                    logger.error(errMsg)
                    raise ConfigurationError(errMsg) from e
                else:
                    errMsg = f"LLM API query failed (Invalid Argument - check model name/API parameters?): {e}"
                    logger.error(errMsg, exc_info=False)
                    raise LLMError(errMsg) from e
            except google_exceptions.GoogleAPIError as e:
                errorType = type(e).__name__
                logger.warning(f"LLM API query attempt {attempt + 1} failed ({errorType}): {e}", exc_info=False)
                last_exception = e  # Potentially retryable
            except Exception as e:
                errorType = type(e).__name__
                logger.warning(f"LLM API query attempt {attempt + 1} failed ({errorType}): {e}", exc_info=False)
                last_exception = e  # Potentially retryable

            if last_exception and attempt < MAX_RETRIES:
                logger.info(f"Retrying in {RETRY_DELAY_SECONDS} seconds...")
                time.sleep(RETRY_DELAY_SECONDS)
                last_exception = None
            elif last_exception:
                break  # Exit loop if last attempt failed

        if last_exception:
            errorType = type(last_exception).__name__
            finalErrMsg = f"LLM API query failed after {MAX_RETRIES + 1} attempts. Last error ({errorType}): {last_exception}"
            logger.error(finalErrMsg, exc_info=bool(last_exception))
        else:
            finalErrMsg = f"LLM API query failed after {MAX_RETRIES + 1} attempts for an unexpected reason (no final exception recorded)."
            logger.error(finalErrMsg)
        raise LLMError(finalErrMsg) from last_exception

## core/__init__.py ##

#### Other Files ####

## config.ini ##

[General]
defaultclonedir = ./cloned_repos
defaultllmmodel = gemini-2.5-pro-exp-03-25 # Or gemini-pro, etc.
expectedoutputformat = json
lastrepopath = /home/david/devs/ColonelCode

[LLM]
temperature = 0.7
maxoutputtokens = 65536
harmcategoryharassmentthreshold = BLOCK_NONE
harmcategoryhatespeechthreshold = BLOCK_NONE
harmcategorysexuallyexplicitthreshold = BLOCK_NONE
harmcategorydangerouscontentthreshold = BLOCK_NONE
maxtokensperfileinprompt = 65536 # Example: Target token limit
maxcharsperfileinprompt = 65536 # Example: Fallback limit of 10k chars

[Logging]
fileloglevel = DEBUG
logfilename = app_log.log
logdirectory = logs
guiloglevel = DEBUG
guilogformat = %(asctime)s - %(levelname)s - %(message)s
guilogdateformat = %H:%M:%S

[GitHub]
defaultremotename = origin
defaultbranchname = main
defaultcommitmessage = LLM Auto-Update via ColonelCode

[GUI]



## requirements.txt ##

# Updated Codebase/requirements.txt
# --- START: requirements.txt ---
PySide6==6.6.0
GitPython==3.1.30
# Updated google-generativeai version
google-generativeai==0.7.1
python-dotenv==1.0.0
PyYAML==6.0.1
# Add pyflakes for Python syntax checking
pyflakes==3.2.1
# --- END: requirements.txt ---

===== Folder Structure =====

ColonelCode/
    config.ini
    .env
    main.py
    .env.example
    requirements.txt
    .gitignore
    ROADMAP.html
    tests/
        test_file_processor.py
        test_config_manager.py
        test_llm_interface.py
        test_github_handler.py
        test_integration.py
        __init__.py
    utils/
        logger_setup.py
        __init__.py
    resources/
        __init__.py
    gui/
        threads.py
        gui_utils.py
        main_window.py
        __init__.py
        widgets/
            __init__.py
    docs/
        __init__.py
    Codebase/
    core/
        config_manager.py
        exceptions.py
        file_processor.py
        github_handler.py
        llm_interface.py
        __init__.py
